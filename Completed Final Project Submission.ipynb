{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f6c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tensorflow import keras\n",
    "from sklearn import tree\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c235962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   gender               100000 non-null  object \n",
      " 1   age                  100000 non-null  float64\n",
      " 2   hypertension         100000 non-null  int64  \n",
      " 3   heart_disease        100000 non-null  int64  \n",
      " 4   smoking_history      100000 non-null  object \n",
      " 5   bmi                  100000 non-null  float64\n",
      " 6   HbA1c_level          100000 non-null  float64\n",
      " 7   blood_glucose_level  100000 non-null  int64  \n",
      " 8   diabetes             100000 non-null  int64  \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b970b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.2</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>17.37</td>\n",
       "      <td>6.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>former</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Female</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0      Female  80.0             0              1           never  25.19   \n",
       "1      Female  54.0             0              0         No Info  27.32   \n",
       "2        Male  28.0             0              0           never  27.32   \n",
       "3      Female  36.0             0              0         current  23.45   \n",
       "4        Male  76.0             1              1         current  20.14   \n",
       "...       ...   ...           ...            ...             ...    ...   \n",
       "99995  Female  80.0             0              0         No Info  27.32   \n",
       "99996  Female   2.0             0              0         No Info  17.37   \n",
       "99997    Male  66.0             0              0          former  27.83   \n",
       "99998  Female  24.0             0              0           never  35.42   \n",
       "99999  Female  57.0             0              0         current  22.43   \n",
       "\n",
       "       HbA1c_level  blood_glucose_level  diabetes  \n",
       "0              6.6                  140         0  \n",
       "1              6.6                   80         0  \n",
       "2              5.7                  158         0  \n",
       "3              5.0                  155         0  \n",
       "4              4.8                  155         0  \n",
       "...            ...                  ...       ...  \n",
       "99995          6.2                   90         0  \n",
       "99996          6.5                  100         0  \n",
       "99997          5.7                  155         0  \n",
       "99998          4.0                  100         0  \n",
       "99999          6.6                   90         0  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a8957",
   "metadata": {},
   "source": [
    "## Data cleaning:\n",
    "- Removal of gender \"other\" and smoking \"no info\" due to lack of clarity on actual values (e.g. transgender, decline to state, etc).  Entries would likely not provide insight for feature correlation to category outcome.\n",
    "- Conversion of gender and smoking history to numeric values using dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a660fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 64184 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   gender               64184 non-null  int64  \n",
      " 1   age                  64184 non-null  float64\n",
      " 2   hypertension         64184 non-null  int64  \n",
      " 3   heart_disease        64184 non-null  int64  \n",
      " 4   smoking_history      64184 non-null  int64  \n",
      " 5   bmi                  64184 non-null  float64\n",
      " 6   HbA1c_level          64184 non-null  float64\n",
      " 7   blood_glucose_level  64184 non-null  int64  \n",
      " 8   diabetes             64184 non-null  int64  \n",
      "dtypes: float64(3), int64(6)\n",
      "memory usage: 4.9 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99992</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.34</td>\n",
       "      <td>6.5</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99993</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.69</td>\n",
       "      <td>3.5</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64184 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease  smoking_history    bmi  \\\n",
       "0           1  80.0             0              1                0  25.19   \n",
       "2           0  28.0             0              0                0  27.32   \n",
       "3           1  36.0             0              0                1  23.45   \n",
       "4           0  76.0             1              1                1  20.14   \n",
       "5           1  20.0             0              0                0  27.32   \n",
       "...       ...   ...           ...            ...              ...    ...   \n",
       "99992       1  26.0             0              0                0  34.34   \n",
       "99993       1  40.0             0              0                0  40.69   \n",
       "99997       0  66.0             0              0                3  27.83   \n",
       "99998       1  24.0             0              0                0  35.42   \n",
       "99999       1  57.0             0              0                1  22.43   \n",
       "\n",
       "       HbA1c_level  blood_glucose_level  diabetes  \n",
       "0              6.6                  140         0  \n",
       "2              5.7                  158         0  \n",
       "3              5.0                  155         0  \n",
       "4              4.8                  155         0  \n",
       "5              6.6                   85         0  \n",
       "...            ...                  ...       ...  \n",
       "99992          6.5                  160         0  \n",
       "99993          3.5                  155         0  \n",
       "99997          5.7                  155         0  \n",
       "99998          4.0                  100         0  \n",
       "99999          6.6                   90         0  \n",
       "\n",
       "[64184 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataValDict = {'gender': {'Male': 0, 'Female': 1, 'Other': 3}, 'smoking_history': {'never': 0, 'current': 1, 'ever': 2, 'former': 3, 'not current': 4}}\n",
    "\n",
    "#Original file is saved as original data.  Df will be 'cleaned' file.\n",
    "df = data[data['gender'] != 'Other']\n",
    "df = data[data['smoking_history'] != 'No Info']\n",
    "\n",
    "df = df.replace(dataValDict)\n",
    "df['gender'] = pd.to_numeric(df['gender'])\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee9dec",
   "metadata": {},
   "source": [
    "## Training and Test set creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d6a106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41428, 8), (17756, 8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split features from (diabetes) label\n",
    "\n",
    "features = ['gender','age','hypertension','heart_disease','smoking_history', 'bmi','HbA1c_level','blood_glucose_level']\n",
    "\n",
    "df_check_ensemble = df.sample(5000)\n",
    "df = df.drop(df_check_ensemble.index)\n",
    "\n",
    "\n",
    "X = df.loc[:, features]\n",
    "y = df.loc[:, ['diabetes']]\n",
    "\n",
    "X_check_ensemble = df_check_ensemble.loc[:, features]\n",
    "y_check_ensemble = df_check_ensemble.loc[:, ['diabetes']]\n",
    "#Data will be shuffled before split by default. No stratification. Test size = 30% of set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size = .70)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8b3f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create np array versions of test and train data\n",
    "X_trn_np = X_train.to_numpy() \n",
    "X_tst_np = X_test.to_numpy() \n",
    "y_trn_np = y_train.to_numpy() \n",
    "y_tst_np = y_test.to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9980ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "746/746 [==============================] - 4s 2ms/step - loss: 0.1929 - accuracy: 0.9211 - val_loss: 0.0485 - val_accuracy: 0.9404 - lr: 0.0010\n",
      "Epoch 2/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0483 - accuracy: 0.9363 - val_loss: 0.0508 - val_accuracy: 0.9394 - lr: 0.0010\n",
      "Epoch 3/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0439 - accuracy: 0.9401 - val_loss: 0.0376 - val_accuracy: 0.9457 - lr: 0.0010\n",
      "Epoch 4/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0418 - accuracy: 0.9434 - val_loss: 0.0392 - val_accuracy: 0.9418 - lr: 0.0010\n",
      "Epoch 5/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0410 - accuracy: 0.9447 - val_loss: 0.0371 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 6/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0407 - accuracy: 0.9434 - val_loss: 0.0367 - val_accuracy: 0.9471 - lr: 0.0010\n",
      "Epoch 7/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0403 - accuracy: 0.9449 - val_loss: 0.0352 - val_accuracy: 0.9491 - lr: 0.0010\n",
      "Epoch 8/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0401 - accuracy: 0.9454 - val_loss: 0.0346 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 9/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0388 - accuracy: 0.9460 - val_loss: 0.0351 - val_accuracy: 0.9469 - lr: 0.0010\n",
      "Epoch 10/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0391 - accuracy: 0.9450 - val_loss: 0.0371 - val_accuracy: 0.9483 - lr: 0.0010\n",
      "Epoch 11/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0388 - accuracy: 0.9453 - val_loss: 0.0331 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 12/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0390 - accuracy: 0.9468 - val_loss: 0.0388 - val_accuracy: 0.9551 - lr: 0.0010\n",
      "Epoch 13/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0386 - accuracy: 0.9479 - val_loss: 0.0379 - val_accuracy: 0.9602 - lr: 0.0010\n",
      "Epoch 14/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0385 - accuracy: 0.9468 - val_loss: 0.0342 - val_accuracy: 0.9517 - lr: 0.0010\n",
      "Epoch 15/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0382 - accuracy: 0.9471 - val_loss: 0.0348 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 16/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0376 - accuracy: 0.9482 - val_loss: 0.0338 - val_accuracy: 0.9532 - lr: 0.0010\n",
      "Epoch 17/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0362 - accuracy: 0.9493 - val_loss: 0.0321 - val_accuracy: 0.9534 - lr: 5.0000e-04\n",
      "Epoch 18/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0359 - accuracy: 0.9481 - val_loss: 0.0316 - val_accuracy: 0.9541 - lr: 5.0000e-04\n",
      "Epoch 19/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0359 - accuracy: 0.9489 - val_loss: 0.0316 - val_accuracy: 0.9551 - lr: 5.0000e-04\n",
      "Epoch 20/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0354 - accuracy: 0.9498 - val_loss: 0.0319 - val_accuracy: 0.9537 - lr: 5.0000e-04\n",
      "Epoch 21/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0356 - accuracy: 0.9486 - val_loss: 0.0330 - val_accuracy: 0.9500 - lr: 5.0000e-04\n",
      "Epoch 22/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0353 - accuracy: 0.9487 - val_loss: 0.0322 - val_accuracy: 0.9515 - lr: 5.0000e-04\n",
      "Epoch 23/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0353 - accuracy: 0.9493 - val_loss: 0.0320 - val_accuracy: 0.9570 - lr: 5.0000e-04\n",
      "Epoch 24/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0342 - accuracy: 0.9503 - val_loss: 0.0309 - val_accuracy: 0.9546 - lr: 2.5000e-04\n",
      "Epoch 25/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0344 - accuracy: 0.9504 - val_loss: 0.0308 - val_accuracy: 0.9553 - lr: 2.5000e-04\n",
      "Epoch 26/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0343 - accuracy: 0.9503 - val_loss: 0.0312 - val_accuracy: 0.9524 - lr: 2.5000e-04\n",
      "Epoch 27/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0337 - accuracy: 0.9516 - val_loss: 0.0305 - val_accuracy: 0.9578 - lr: 2.5000e-04\n",
      "Epoch 28/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0340 - accuracy: 0.9504 - val_loss: 0.0322 - val_accuracy: 0.9493 - lr: 2.5000e-04\n",
      "Epoch 29/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0344 - accuracy: 0.9500 - val_loss: 0.0313 - val_accuracy: 0.9524 - lr: 2.5000e-04\n",
      "Epoch 30/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0341 - accuracy: 0.9511 - val_loss: 0.0317 - val_accuracy: 0.9515 - lr: 2.5000e-04\n",
      "Epoch 31/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0336 - accuracy: 0.9511 - val_loss: 0.0307 - val_accuracy: 0.9551 - lr: 2.5000e-04\n",
      "Epoch 32/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0342 - accuracy: 0.9509 - val_loss: 0.0309 - val_accuracy: 0.9553 - lr: 2.5000e-04\n",
      "Epoch 33/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0333 - accuracy: 0.9519 - val_loss: 0.0304 - val_accuracy: 0.9566 - lr: 1.2500e-04\n",
      "Epoch 34/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0331 - accuracy: 0.9516 - val_loss: 0.0308 - val_accuracy: 0.9541 - lr: 1.2500e-04\n",
      "Epoch 35/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0334 - accuracy: 0.9513 - val_loss: 0.0303 - val_accuracy: 0.9556 - lr: 1.2500e-04\n",
      "Epoch 36/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0329 - accuracy: 0.9525 - val_loss: 0.0301 - val_accuracy: 0.9570 - lr: 1.2500e-04\n",
      "Epoch 37/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0328 - accuracy: 0.9530 - val_loss: 0.0311 - val_accuracy: 0.9529 - lr: 1.2500e-04\n",
      "Epoch 38/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0334 - accuracy: 0.9513 - val_loss: 0.0302 - val_accuracy: 0.9573 - lr: 1.2500e-04\n",
      "Epoch 39/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0333 - accuracy: 0.9512 - val_loss: 0.0305 - val_accuracy: 0.9556 - lr: 1.2500e-04\n",
      "Epoch 40/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0331 - accuracy: 0.9520 - val_loss: 0.0304 - val_accuracy: 0.9553 - lr: 1.2500e-04\n",
      "Epoch 41/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0330 - accuracy: 0.9519 - val_loss: 0.0306 - val_accuracy: 0.9549 - lr: 1.2500e-04\n",
      "Epoch 42/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0329 - accuracy: 0.9521 - val_loss: 0.0303 - val_accuracy: 0.9551 - lr: 6.2500e-05\n",
      "Epoch 43/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0328 - accuracy: 0.9522 - val_loss: 0.0309 - val_accuracy: 0.9520 - lr: 6.2500e-05\n",
      "Epoch 44/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9526 - val_loss: 0.0308 - val_accuracy: 0.9549 - lr: 6.2500e-05\n",
      "Epoch 45/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0327 - accuracy: 0.9519 - val_loss: 0.0306 - val_accuracy: 0.9541 - lr: 6.2500e-05\n",
      "Epoch 46/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9520 - val_loss: 0.0304 - val_accuracy: 0.9541 - lr: 6.2500e-05\n",
      "Epoch 47/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9531 - val_loss: 0.0301 - val_accuracy: 0.9553 - lr: 3.1250e-05\n",
      "Epoch 48/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9524 - val_loss: 0.0301 - val_accuracy: 0.9551 - lr: 3.1250e-05\n",
      "Epoch 49/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0327 - accuracy: 0.9516 - val_loss: 0.0302 - val_accuracy: 0.9541 - lr: 3.1250e-05\n",
      "Epoch 50/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0320 - accuracy: 0.9529 - val_loss: 0.0301 - val_accuracy: 0.9553 - lr: 3.1250e-05\n",
      "Epoch 51/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9525 - val_loss: 0.0301 - val_accuracy: 0.9544 - lr: 3.1250e-05\n",
      "Epoch 52/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0321 - accuracy: 0.9529 - val_loss: 0.0301 - val_accuracy: 0.9549 - lr: 1.5625e-05\n",
      "Epoch 53/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0318 - accuracy: 0.9534 - val_loss: 0.0298 - val_accuracy: 0.9563 - lr: 1.5625e-05\n",
      "Epoch 54/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9520 - val_loss: 0.0299 - val_accuracy: 0.9551 - lr: 1.5625e-05\n",
      "Epoch 55/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0320 - accuracy: 0.9537 - val_loss: 0.0299 - val_accuracy: 0.9556 - lr: 1.5625e-05\n",
      "Epoch 56/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9526 - val_loss: 0.0299 - val_accuracy: 0.9558 - lr: 1.5625e-05\n",
      "Epoch 57/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9535 - val_loss: 0.0299 - val_accuracy: 0.9558 - lr: 1.5625e-05\n",
      "Epoch 58/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9517 - val_loss: 0.0300 - val_accuracy: 0.9544 - lr: 1.5625e-05\n",
      "Epoch 59/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9526 - val_loss: 0.0300 - val_accuracy: 0.9546 - lr: 7.8125e-06\n",
      "Epoch 60/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0316 - accuracy: 0.9536 - val_loss: 0.0299 - val_accuracy: 0.9558 - lr: 7.8125e-06\n",
      "Epoch 61/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0321 - accuracy: 0.9530 - val_loss: 0.0298 - val_accuracy: 0.9563 - lr: 7.8125e-06\n",
      "Epoch 62/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9524 - val_loss: 0.0299 - val_accuracy: 0.9558 - lr: 7.8125e-06\n",
      "Epoch 63/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0321 - accuracy: 0.9533 - val_loss: 0.0297 - val_accuracy: 0.9568 - lr: 7.8125e-06\n",
      "Epoch 64/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9528 - val_loss: 0.0300 - val_accuracy: 0.9546 - lr: 3.9063e-06\n",
      "Epoch 65/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0319 - accuracy: 0.9528 - val_loss: 0.0299 - val_accuracy: 0.9551 - lr: 3.9063e-06\n",
      "Epoch 66/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0319 - accuracy: 0.9535 - val_loss: 0.0300 - val_accuracy: 0.9546 - lr: 3.9063e-06\n",
      "Epoch 67/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0319 - accuracy: 0.9536 - val_loss: 0.0299 - val_accuracy: 0.9553 - lr: 3.9063e-06\n",
      "Epoch 68/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0321 - accuracy: 0.9526 - val_loss: 0.0300 - val_accuracy: 0.9549 - lr: 3.9063e-06\n",
      "Epoch 69/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0320 - accuracy: 0.9526 - val_loss: 0.0300 - val_accuracy: 0.9546 - lr: 1.9531e-06\n",
      "Epoch 70/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0319 - accuracy: 0.9532 - val_loss: 0.0298 - val_accuracy: 0.9556 - lr: 1.9531e-06\n",
      "Epoch 71/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9524 - val_loss: 0.0299 - val_accuracy: 0.9553 - lr: 1.9531e-06\n",
      "Epoch 72/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0316 - accuracy: 0.9532 - val_loss: 0.0300 - val_accuracy: 0.9551 - lr: 1.9531e-06\n",
      "Epoch 73/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9525 - val_loss: 0.0300 - val_accuracy: 0.9544 - lr: 1.9531e-06\n",
      "Epoch 74/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9524 - val_loss: 0.0299 - val_accuracy: 0.9553 - lr: 9.7656e-07\n",
      "Epoch 75/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0318 - accuracy: 0.9528 - val_loss: 0.0299 - val_accuracy: 0.9553 - lr: 9.7656e-07\n",
      "Epoch 76/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9526 - val_loss: 0.0300 - val_accuracy: 0.9549 - lr: 9.7656e-07\n",
      "Epoch 77/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0318 - accuracy: 0.9525 - val_loss: 0.0298 - val_accuracy: 0.9556 - lr: 9.7656e-07\n",
      "Epoch 78/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0320 - accuracy: 0.9527 - val_loss: 0.0300 - val_accuracy: 0.9549 - lr: 9.7656e-07\n",
      "Epoch 79/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0317 - accuracy: 0.9538 - val_loss: 0.0300 - val_accuracy: 0.9546 - lr: 4.8828e-07\n",
      "Epoch 80/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0318 - accuracy: 0.9530 - val_loss: 0.0298 - val_accuracy: 0.9556 - lr: 4.8828e-07\n",
      "Epoch 81/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0319 - accuracy: 0.9536 - val_loss: 0.0298 - val_accuracy: 0.9561 - lr: 4.8828e-07\n",
      "Epoch 82/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0321 - accuracy: 0.9530 - val_loss: 0.0298 - val_accuracy: 0.9558 - lr: 4.8828e-07\n",
      "Epoch 83/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0316 - accuracy: 0.9537 - val_loss: 0.0298 - val_accuracy: 0.9551 - lr: 4.8828e-07\n",
      "Epoch 84/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0320 - accuracy: 0.9532 - val_loss: 0.0299 - val_accuracy: 0.9551 - lr: 2.4414e-07\n",
      "Epoch 85/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0320 - accuracy: 0.9527 - val_loss: 0.0299 - val_accuracy: 0.9551 - lr: 2.4414e-07\n",
      "Epoch 86/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9525 - val_loss: 0.0298 - val_accuracy: 0.9558 - lr: 2.4414e-07\n",
      "Epoch 87/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0319 - accuracy: 0.9529 - val_loss: 0.0299 - val_accuracy: 0.9553 - lr: 2.4414e-07\n",
      "Epoch 88/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9532 - val_loss: 0.0300 - val_accuracy: 0.9549 - lr: 2.4414e-07\n",
      "17756/17756 [==============================] - 13s 711us/step - loss: 0.0306 - accuracy: 0.9538\n",
      "0.9538184404373169\n"
     ]
    }
   ],
   "source": [
    "#LOAD NEXT CELL INSTEAD, LOADS PRE-TRAINED NEURAL NET\n",
    "#This neural network can take up to 5 minutes or more to train depending on hardware\n",
    "\n",
    "activation_type = 'relu'\n",
    "\n",
    "NNModel = keras.Sequential([\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(128, activation=activation_type, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(128, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(64, activation=activation_type),\n",
    "    keras.layers.Dense(64, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(32, activation=activation_type),\n",
    "    keras.layers.Dense(32, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(32, activation=activation_type, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(32, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(16, activation=activation_type, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(16, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(8, activation=activation_type, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(8, activation=activation_type),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "#Start with moderate level of learning rate which we will adjust later\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#Use Binary Focal Crossentropy instead of Binary Crossentropy as the prevalence of diabetes vs. not having diabetes is not symmetrical\n",
    "NNModel.compile(optimizer=optimizer, loss=keras.losses.BinaryFocalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "#Add two callbacks, the first ends training early if 25 epocsh go by without improvement on the validation set\n",
    "#The second callback adjusts the learning rate if 5 epochs go by without improvement on the validation set\n",
    "callbacks = []\n",
    "callbacks.append(keras.callbacks.EarlyStopping(monitor='val_loss', patience=25))\n",
    "callbacks.append(keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5))\n",
    "\n",
    "#Train over 250 epochs (maximum), using a moderate batch size to improve training times\n",
    "NNModel.fit(X_train, y_train, epochs=250, batch_size=50, validation_split=0.1, callbacks=callbacks)\n",
    "\n",
    "evaluation = NNModel.evaluate(X_test, y_test, batch_size = 1)\n",
    "print(evaluation[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33cf5523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555/555 [==============================] - 1s 699us/step\n",
      "157/157 [==============================] - 0s 682us/step\n",
      "[[0.03864835]\n",
      " [0.02355906]\n",
      " [0.01146456]\n",
      " ...\n",
      " [0.02021408]\n",
      " [0.02610912]\n",
      " [0.132201  ]]\n"
     ]
    }
   ],
   "source": [
    "#NNModel.save('DanielNeuralNetworkModel.keras')\n",
    "#loaded_NNmodel = keras.models.load_model('DanielNeuralNetworkModel.keras')\n",
    "loaded_NNmodel = NNModel\n",
    "\n",
    "NN_predictions = loaded_NNmodel.predict(([X_test]))\n",
    "NN_probabilities = 1 / (1 + np.exp(-NN_predictions))\n",
    "NN_check_class_predictions = [1 if prob >= 0.5 else 0 for prob in NN_probabilities]\n",
    "\n",
    "\n",
    "NN_accuracy = []\n",
    "NN_f1 = []\n",
    "NN_precision = []\n",
    "NN_recall = []\n",
    "\n",
    "NN_accuracy.append(accuracy_score(y_test, NN_check_class_predictions))\n",
    "NN_f1.append(f1_score(y_test, NN_check_class_predictions))\n",
    "NN_precision.append(precision_score(y_test, NN_check_class_predictions))\n",
    "NN_recall.append(recall_score(y_test, NN_check_class_predictions))\n",
    "\n",
    "\n",
    "NN_check_predictions = loaded_NNmodel.predict(([X_check_ensemble]))\n",
    "NN_check_probabilities = 1 / (1 + np.exp(-NN_check_predictions))\n",
    "\n",
    "print(NN_check_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d13b3ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9528046857400315\n"
     ]
    }
   ],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = .3)\n",
    "MLPmodel = MLPClassifier()\n",
    "cv = cross_val_score(MLPmodel, X_train, y_train, cv=5)\n",
    "MLPmodel.fit(X_train, y_train)\n",
    "test_accuracy = MLPmodel.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b813a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "[CV] END activation=identity, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=200, solver=sgd; total time=  10.8s\n",
      "[CV] END activation=identity, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=200, solver=sgd; total time=  11.7s\n",
      "[CV] END activation=identity, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=200, solver=sgd; total time=  10.5s\n",
      "[CV] END activation=identity, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=200, solver=sgd; total time=  15.3s\n",
      "[CV] END activation=identity, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=200, solver=sgd; total time=   7.1s\n",
      "[CV] END activation=identity, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=200, solver=adam; total time=   7.5s\n"
     ]
    }
   ],
   "source": [
    "#This MLP grid search may take up to 5 minutes or more to train depending on hardware\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'solver' : ['sgd', 'adam'],\n",
    "    'activation' : ['identity', 'logistic', 'relu'],\n",
    "    'max_iter': [200, 500, 1000],\n",
    "    'learning_rate': ['constant','invscaling','adaptive']}\n",
    "grid_search = GridSearchCV(MLPmodel, param_grid, cv=5, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "best_mlp = grid_search.best_estimator_\n",
    "gridmodel_acc = best_mlp.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a101dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.956127506195089\n"
     ]
    }
   ],
   "source": [
    "tuned_MLP_model = MLPClassifier(activation = 'logistic', hidden_layer_sizes = (100,50), learning_rate = 'adaptive', max_iter = 1000, solver = 'adam')\n",
    "cv = cross_val_score(tuned_MLP_model, X_train, y_train, cv=5)\n",
    "tuned_MLP_model.fit(X_train, y_train)\n",
    "#MLP_accuracy = tuned_MLP_model.score(X_test, y_test)\n",
    "\n",
    "#print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.49156666e-05 8.87727865e-04 3.23733334e-03 ... 4.74847329e-02\n",
      " 1.23492626e-03 9.89251299e-01]\n"
     ]
    }
   ],
   "source": [
    "y_pred_MLP = tuned_MLP_model.predict(X_test)\n",
    "\n",
    "MLP_accuracy = (accuracy_score(y_test, y_pred_MLP))\n",
    "MLP_f1 = (f1_score(y_test, y_pred_MLP))\n",
    "MLP_precision = (precision_score(y_test, y_pred_MLP))\n",
    "MLP_recall = (recall_score(y_test, y_pred_MLP))\n",
    "\n",
    "MLP_check_probabilities = (tuned_MLP_model.predict_proba(X_check_ensemble))[:,1]\n",
    "print(MLP_check_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24a5881f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m logistic_model \u001b[39m=\u001b[39m LogisticRegression()\n\u001b[0;32m     60\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(logistic_model, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     63\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Hyperparameters:\u001b[39m\u001b[39m\"\u001b[39m, grid_search\u001b[39m.\u001b[39mbest_params_)\n\u001b[0;32m     64\u001b[0m best_logistic \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    734\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1302\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1300\u001b[0m     n_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1302\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, prefer\u001b[39m=\u001b[39;49mprefer)(\n\u001b[0;32m   1303\u001b[0m     path_func(\n\u001b[0;32m   1304\u001b[0m         X,\n\u001b[0;32m   1305\u001b[0m         y,\n\u001b[0;32m   1306\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[0;32m   1307\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[0;32m   1308\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[0;32m   1309\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[0;32m   1310\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m   1311\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1312\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[0;32m   1313\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[0;32m   1314\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m   1315\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m   1316\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1317\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[0;32m   1318\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[0;32m   1319\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[0;32m   1320\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[0;32m   1321\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1322\u001b[0m         n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[0;32m   1323\u001b[0m     )\n\u001b[0;32m   1324\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[0;32m   1325\u001b[0m )\n\u001b[0;32m   1327\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1328\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:533\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    530\u001b[0m         alpha \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m l1_ratio)\n\u001b[0;32m    531\u001b[0m         beta \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m l1_ratio\n\u001b[1;32m--> 533\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[39m=\u001b[39m sag_solver(\n\u001b[0;32m    534\u001b[0m         X,\n\u001b[0;32m    535\u001b[0m         target,\n\u001b[0;32m    536\u001b[0m         sample_weight,\n\u001b[0;32m    537\u001b[0m         loss,\n\u001b[0;32m    538\u001b[0m         alpha,\n\u001b[0;32m    539\u001b[0m         beta,\n\u001b[0;32m    540\u001b[0m         max_iter,\n\u001b[0;32m    541\u001b[0m         tol,\n\u001b[0;32m    542\u001b[0m         verbose,\n\u001b[0;32m    543\u001b[0m         random_state,\n\u001b[0;32m    544\u001b[0m         \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    545\u001b[0m         max_squared_sum,\n\u001b[0;32m    546\u001b[0m         warm_start_sag,\n\u001b[0;32m    547\u001b[0m         is_saga\u001b[39m=\u001b[39;49m(solver \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    548\u001b[0m     )\n\u001b[0;32m    550\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    551\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    552\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msolver must be one of \u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    553\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}, got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m solver\n\u001b[0;32m    554\u001b[0m     )\n",
      "File \u001b[1;32mf:\\Workspace\\School Projects UCR\\PHYS 243\\UCRvenv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:325\u001b[0m, in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mZeroDivisionError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCurrent sag implementation does not handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    324\u001b[0m sag \u001b[39m=\u001b[39m sag64 \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat64 \u001b[39melse\u001b[39;00m sag32\n\u001b[1;32m--> 325\u001b[0m num_seen, n_iter_ \u001b[39m=\u001b[39m sag(\n\u001b[0;32m    326\u001b[0m     dataset,\n\u001b[0;32m    327\u001b[0m     coef_init,\n\u001b[0;32m    328\u001b[0m     intercept_init,\n\u001b[0;32m    329\u001b[0m     n_samples,\n\u001b[0;32m    330\u001b[0m     n_features,\n\u001b[0;32m    331\u001b[0m     n_classes,\n\u001b[0;32m    332\u001b[0m     tol,\n\u001b[0;32m    333\u001b[0m     max_iter,\n\u001b[0;32m    334\u001b[0m     loss,\n\u001b[0;32m    335\u001b[0m     step_size,\n\u001b[0;32m    336\u001b[0m     alpha_scaled,\n\u001b[0;32m    337\u001b[0m     beta_scaled,\n\u001b[0;32m    338\u001b[0m     sum_gradient_init,\n\u001b[0;32m    339\u001b[0m     gradient_memory_init,\n\u001b[0;32m    340\u001b[0m     seen_init,\n\u001b[0;32m    341\u001b[0m     num_seen_init,\n\u001b[0;32m    342\u001b[0m     fit_intercept,\n\u001b[0;32m    343\u001b[0m     intercept_sum_gradient,\n\u001b[0;32m    344\u001b[0m     intercept_decay,\n\u001b[0;32m    345\u001b[0m     is_saga,\n\u001b[0;32m    346\u001b[0m     verbose,\n\u001b[0;32m    347\u001b[0m )\n\u001b[0;32m    349\u001b[0m \u001b[39mif\u001b[39;00m n_iter_ \u001b[39m==\u001b[39m max_iter:\n\u001b[0;32m    350\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    351\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    352\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    353\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#These Logistic Regression grid search may take up to 5 minutes or more to train depending on hardware\n",
    "param_grid = [\n",
    "    # For sag solver \n",
    "    {\n",
    "        'penalty': ['l2'],  \n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['sag'],\n",
    "        'max_iter': [1000, 1500],\n",
    "        'multi_class': ['ovr', 'multinomial'],\n",
    "        'tol': [0.01, 0.1]}, \n",
    "\n",
    "    # Penalty is None\n",
    "    {\n",
    "        'penalty': [None], \n",
    "        'C': [1], \n",
    "        'solver': ['sag', 'saga', 'newton-cg', 'lbfgs'],\n",
    "        'max_iter': [1000, 1500],\n",
    "        'multi_class': ['ovr', 'multinomial'],\n",
    "        'tol': [0.01, 0.1]},\n",
    "\n",
    "    # For saga solver \n",
    "    {\n",
    "        'penalty': ['l1', 'l2'], \n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['saga'],\n",
    "        'max_iter': [1000, 1500],\n",
    "        'multi_class': ['ovr', 'multinomial'],\n",
    "        'tol': [0.01, 0.1]},\n",
    "\n",
    "    # For saga solver with elasticnet penalty\n",
    "    {\n",
    "        'penalty': ['elasticnet'],\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['saga'],\n",
    "        'max_iter': [1000, 1500],\n",
    "        'multi_class': ['ovr', 'multinomial'],\n",
    "        'tol': [0.01, 0.1],\n",
    "        'l1_ratio': [0.1, 0.5, 0.9],\n",
    "        'tol': [0.01, 0.1]},  \n",
    "\n",
    "    # For liblinear solver\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['liblinear'],\n",
    "        'max_iter': [500, 750, 1000, 1500],\n",
    "        'multi_class': ['ovr'],\n",
    "        'tol': [0.01, 0.1]},\n",
    "\n",
    "    # For lbfgs solver\n",
    "    {\n",
    "        'penalty': ['l2'],\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['lbfgs'],\n",
    "        'max_iter': [500, 750, 1000, 1500],\n",
    "        'multi_class': ['ovr', 'multinomial'],\n",
    "        'tol': [0.01, 0.1]}    \n",
    "    ]\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "grid_search = GridSearchCV(logistic_model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "best_logistic = grid_search.best_estimator_\n",
    "\n",
    "test_accuracy = best_logistic.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85d5d29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9488060373958098\n",
      "Coefficients: [[-2.81140241e-01  4.71522568e-02  7.26288347e-01  6.09541362e-01\n",
      "  -1.52536906e-03  8.67666155e-02  2.25611170e+00  3.26779085e-02]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initializing and training the Logistic Regression model\n",
    "tuned_LR_model = LogisticRegression(C = 0.1, max_iter= 1000, multi_class= 'ovr', penalty= 'l2', solver= 'lbfgs', tol= 0.01)\n",
    "cv_scores = cross_val_score(tuned_LR_model, X_train, y_train, cv=5)\n",
    "tuned_LR_model.fit(X_train, y_train)\n",
    "LR_test_accuracy = tuned_LR_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", LR_test_accuracy)\n",
    "print('Coefficients:', tuned_LR_model.coef_)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(tuned_LR_model, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "y_prob = tuned_LR_model.predict_proba(X_test)\n",
    "plt.hist(y_prob[:,1], bins=10)\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted probability of diabetes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5fe498b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.36628593e-04 4.66816208e-03 1.00471500e-03 6.57768072e-03\n",
      " 6.07530779e-03 3.03883702e-02 1.39874725e-01 3.33766606e-04\n",
      " 1.60914760e-04 7.45182383e-01 2.79676404e-02 9.98356501e-01]\n"
     ]
    }
   ],
   "source": [
    "y_pred_LR = tuned_LR_model.predict(X_test)\n",
    "\n",
    "LR_accuracy = accuracy_score(y_test, y_pred_LR)\n",
    "LR_f1 = f1_score(y_test, y_pred_LR)\n",
    "LR_precision = precision_score(y_test, y_pred_LR)\n",
    "LR_recall = recall_score(y_test, y_pred_LR)\n",
    "\n",
    "LR_check_probabilities = tuned_LR_model.predict_proba(X_check_ensemble)[:,1]\n",
    "print(LR_check_probabilities[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73c567a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9609146204100023\n",
      "[[15733    68]\n",
      " [  626  1329]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAHcCAYAAAD1DfFtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABhpklEQVR4nO3dd1gUx/8H8PeBcCBILwcRlWABFBWxYQQbESMascaS2IgmBmM3SizRRMXeYiGmqDGaGBvxixUligV7b6gRWxRQERBU2s3vD39sPEEF7lZOfb987nm82dnZ2eXKh8/MLAohhAARERGRHjMo7Q4QERERvQwDFiIiItJ7DFiIiIhI7zFgISIiIr3HgIWIiIj0HgMWIiIi0nsMWIiIiEjvMWAhIiIivceAhYiIiPTeaxmwTJgwAQqFokT7VqpUCW3atNFxj14fy5Ytg0KhwNWrV0u7KzrXtGlTNG3atLS78cr17t0blSpVKu1u0CuUkZGBTz/9FCqVCgqFAkOGDNH5MSpVqoTevXvrvN3XlTbfO6QbpR6w5H+B5j9MTEzg7OyMwMBAzJ8/Hw8ePCjtLr7Qw4cPMWHCBOzateuVH3vXrl0a106pVMLR0RFNmzbFlClTcOfOnVfepzfZs6/VMmXK4J133kHv3r3x77//lnb39Maz1+npx+jRo0u7e4WaMmUKIiMji7VPeno6Jk6ciFq1asHc3BympqaoUaMGRo0ahVu3bsnT0f83ZcoULFu2DAMGDMCKFSvwySefyHq8V+np18/evXsLbBdCwMXFBQqFosS/fJbk502lr0xpdyDft99+C1dXV+Tk5CAxMRG7du3CkCFDMHv2bGzcuBE1a9aU6o4dO1ZvPvgePnyIiRMnAkCp/XY/aNAg1KtXD3l5ebhz5w7279+Pb775BrNnz8aff/6J5s2bS3U/+eQTdO3aFUqlslT6Kqft27e/kuPkv1YfP36MAwcOYNmyZdi7dy/OnDkDExOTV9KH10H+dXpajRo1Sqk3LzZlyhR06tQJwcHBRap/5coVBAQE4Pr16+jcuTP69+8PY2NjnDp1Cj///DM2bNiAixcvytbfmJgYNGzYEN98841sx4iPj4eBQen9TmtiYoJVq1ahcePGGuW7d+/GzZs3tfoMK+7PG9Cv7523ld4ELB988AHq1q0rPQ8LC0NMTAzatGmDDz/8EOfPn4epqSkAoEyZMihTRm+6Xur8/PzQqVMnjbKTJ0+iZcuW6NixI86dOwcnJycAgKGhIQwNDUujm7IzNjZ+Jcd5+rX66aefws7ODtOmTcPGjRvRpUuXV9KH18Gz72ldyczMhJmZmc7bLarc3Fx06NABSUlJ2LVrV4Ev1MmTJ2PatGmy9iE5ORmenp6yHqO0f6lp3bo11qxZg/nz52t83q9atQo+Pj64e/fuK+lH/uuN3zulr9SHhF6kefPmGDduHK5du4bffvtNKi9sLHHp0qVo3rw5HBwcoFQq4enpicWLFz+37e3bt6N27dowMTGBp6cn1q9fX6BOamoqhgwZAhcXFyiVSlSuXBnTpk2DWq0GAFy9ehX29vYAgIkTJ0ppzAkTJkhtXLhwAZ06dYKNjQ1MTExQt25dbNy4UeM4OTk5mDhxIqpUqQITExPY2tqicePGiI6OLvY1y1erVi3MnTsXqampWLBggVRe2ByWv/76C0FBQXB2doZSqYSbmxu+++475OXlFWh34cKFePfdd2Fqaor69etjz549BeaO5A9V/fnnn5g8eTLKly8PExMTtGjRApcvXy7Q5po1a+Dj4wNTU1PY2dnh448/LjDEkpiYiD59+qB8+fJQKpVwcnJCu3btNM6jsDks33//PapXr46yZcvC2toadevWxapVqzTqXLhwAdevXy/CVS2cn58fAOCff/6RyrKzszF+/Hj4+PjA0tISZmZm8PPzw99//62x79WrV6FQKDBz5kwsWbIEbm5uUCqVqFevHg4fPlzgWJGRkahRowZMTExQo0YNbNiwodA+ZWZmYvjw4dJrt1q1apg5cyae/ePsCoUCAwcOxJo1a+Dp6QlTU1P4+vri9OnTAIAffvgBlStXhomJCZo2barTuU8xMTHw8/ODmZkZrKys0K5dO5w/f16jTv57/dy5c+jevTusra01AoTffvtNeu3Y2Niga9euuHHjhkYbly5dQseOHaFSqWBiYoLy5cuja9euSEtLk65BZmYmli9fLr2HXzR3Y926dTh58iTGjBlTIFgBAAsLC0yePFmjrCiv8d69e8Pc3Bz//vsvgoODYW5uDnt7e4wYMUJ6L+a/txISErBp0yapv1evXn3u/LT8fZ4etn7ZNQEKn8Ny5coVdO7cGTY2NihbtiwaNmyITZs2FXq8or7/n6dbt264d++exudgdnY21q5di+7duxe6z8yZM9GoUSPY2trC1NQUPj4+WLt2rUadF/28X/R6e/Z7Z+nSpVAoFPjll1802p8yZQoUCgU2b95c5HOlIhKlbOnSpQKAOHz4cKHbb9y4IQCITp06SWXffPONeLbr9erVE7179xZz5swR33//vWjZsqUAIBYsWKBRr2LFiqJq1arCyspKjB49WsyePVt4eXkJAwMDsX37dqleZmamqFmzprC1tRVff/21iIiIED179hQKhUIMHjxYCCFERkaGWLx4sQAg2rdvL1asWCFWrFghTp48KYQQ4syZM8LS0lJ4enqKadOmiQULFgh/f3+hUCjE+vXrpWN9/fXXQqFQiH79+okff/xRzJo1S3Tr1k1MnTr1hdfu77//FgDEmjVrCt2enZ0tTE1NRd26dQtc74SEBKksODhYdOnSRcyYMUMsXrxYdO7cWQAQI0aM0Ghv0aJFAoDw8/MT8+fPF8OGDRM2NjbCzc1NNGnSpEC/vL29hY+Pj5gzZ46YMGGCKFu2rKhfv75Gm/n9qVevnpgzZ44YPXq0MDU1FZUqVRL379+X6jVq1EhYWlqKsWPHip9++klMmTJFNGvWTOzevVuq06RJE41+LFmyRHrt/PDDD2LevHkiJCREDBo0SKMPADT2e57nvVYXLFggAIjFixdLZXfu3BFOTk5i2LBhYvHixWL69OmiWrVqwsjISBw/flyql5CQIF2rypUri2nTponp06cLOzs7Ub58eZGdnS3V3bZtmzAwMBA1atQQs2fPFmPGjBGWlpaievXqomLFilI9tVotmjdvLhQKhfj000/FggULRNu2bQUAMWTIkALnXrNmTeHi4iKmTp0qpk6dKiwtLUWFChXEggULhKenp5g1a5YYO3asMDY2Fs2aNSvyddqxY4e4c+eOxiNfdHS0KFOmjKhataqYPn26mDhxorCzsxPW1tYar83897qnp6do166dWLRokVi4cKEQQohJkyYJhUIhPvroI7Fo0SKpjadfO1lZWcLV1VU4OzuLSZMmiZ9++klMnDhR1KtXT1y9elUIIcSKFSuEUqkUfn5+0nt4//79zz2/7t27CwDi+vXrL70WT1+Pl73Ge/XqJUxMTET16tVF3759xeLFi0XHjh0FALFo0SIhhBCJiYlixYoVws7OTtSuXVvqb0ZGRqHvbSH+ez/+/fffRb4mQjz5rOzVq5f0PDExUTg6Oopy5cqJMWPGiNmzZ4tatWoJAwMDjc+z4rz/X3S9Dh8+LBo1aiQ++eQTaVtkZKQwMDAQ//77r6hYsaIICgrS2Ld8+fLiiy++EAsWLBCzZ88W9evXFwBEVFSUVOdFP+8Xvd4K+95p06aNsLS0lF4Lp06dEsbGxiIkJOSl50nFp/cBixBCWFpaCm9vb+l5YS+chw8fFtgvMDBQvPvuuxplFStWFADEunXrpLK0tDTh5OSkcYzvvvtOmJmZiYsXL2rsP3r0aGFoaCi9QO/cuSMAiG+++abA8Vu0aCG8vLzE48ePpTK1Wi0aNWokqlSpIpXVqlWrwBuvKF4WsOS3bW1tLT0v7EOtsGv32WefibJly0p9z8rKEra2tqJevXoiJydHqrds2bICX/j5/fLw8BBZWVlS+bx58wQAcfr0aSHEk4DKwcFB1KhRQzx69EiqFxUVJQCI8ePHCyGEuH//vgAgZsyY8cLr8WzA0q5dO1G9evUX7iNE8QOW/C/iGzduiLVr1wp7e3uhVCrFjRs3pLq5ubka555/Ho6OjqJv375SWX7AYmtrK1JSUqTyv/76SwAQ//vf/6Sy2rVrCycnJ5GamiqVbd++XQDQCFgiIyMFADFp0iSN43fq1EkoFApx+fJljXNXKpUar4cffvhBABAqlUqkp6dL5WFhYYV+IT7vOhX2ePpcHBwcxL1796SykydPCgMDA9GzZ0+pLP+93q1bN41jXL16VRgaGorJkydrlJ8+fVqUKVNGKj9+/PhL3yNCCGFmZqbx5fwi3t7ewtLSskh1i/oaF+JJwAJAfPvttwWO5+Pjo1FW2Jd1UQOWol6TZwOWIUOGCABiz549UtmDBw+Eq6urqFSpksjLy9M43sve/8/z9HfCggULRLly5aTPqM6dO0tBc2HX4NnPsuzsbFGjRg3RvHlzjfLn/byf93p7etvTbt++LWxsbMT7778vsrKyhLe3t6hQoYJIS0t74TlSyej1kFA+c3Pzl64Wyp/fAgBpaWm4e/cumjRpgitXrmikOQHA2dkZ7du3l55bWFigZ8+eOH78OBITEwE8SeH6+fnB2toad+/elR4BAQHIy8tDbGzsC/uTkpKCmJgYdOnSBQ8ePJD2v3fvHgIDA3Hp0iUpJWxlZYWzZ8/i0qVLxbouRVHca5ffVz8/Pzx8+BAXLlwAABw5cgT37t1Dv379NMZxe/ToAWtr60Lb7dOnj8a8kvyhkytXrkhtJicn44svvtCYrBoUFAR3d3cp1WxqagpjY2Ps2rUL9+/fL/K5W1lZ4ebNm4UOrTxNCFGsVV4BAQGwt7eHi4sLOnXqBDMzM2zcuBHly5eX6hgaGkrnrlarkZKSgtzcXNStWxfHjh0r0OZHH32kcR2fvVa3b9/GiRMn0KtXL1haWkr13n///QJzGTZv3gxDQ0MMGjRIo3z48OEQQmDLli0a5S1atNBYFt2gQQMAQMeOHVGuXLkC5fl9epmFCxciOjpa4/H0ufTu3Rs2NjZS/Zo1a+L9998vNJX++eefazxfv3491Go1unTpovH+VKlUqFKlijT0ln+ttm3bhocPHxap3y+Tnp6ucV1epKiv8ac9e65+fn5FvuZFUdJrsnnzZtSvX19jGMzc3Bz9+/fH1atXce7cOY36L3v/F0WXLl3w6NEjREVF4cGDB4iKinrucBCg+Vl2//59pKWlwc/Pr9D33Is8+zN4HpVKJb3O/fz8cOLECfzyyy+wsLAo1vGoaF6LgCUjI+OlHxD79u1DQECANB5ub2+Pr7/+GgAKBCyVK1cuMAematWqACCN/166dAlbt26Fvb29xiMgIADAk0lvL3L58mUIITBu3LgCbeTP7M9v49tvv0VqaiqqVq0KLy8vjBw5EqdOnSrClXm5oly7s2fPon379rC0tISFhQXs7e3x8ccfA/jv2l27dg3Ak2v3tDJlyjz3HiAVKlTQeJ7/hZwfdOS3Wa1atQL7uru7S9uVSiWmTZuGLVu2wNHREf7+/pg+fboUXD7PqFGjYG5ujvr166NKlSoIDQ3Fvn37XrhPUeR/QK1duxatW7fG3bt3C52guHz5ctSsWVOal2Rvb49NmzYVeD0CRb9WVapUKbDvs9fv2rVrcHZ2LvBz9/Dw0GjrecfO/0JzcXEptLyoQWP9+vUREBCg8Xj6+IX93D08PHD37l1kZmZqlD+72ujSpUsQQqBKlSoF3l/nz5+X3luurq4YNmwYfvrpJ9jZ2SEwMBALFy4s9GdQVBYWFkW+3UJRX+P5TExMpHlx+aytrYsVqL9MSa/JtWvXnvszy9/+tJe9posi/zN31apVWL9+PfLy8gosMHhaVFQUGjZsCBMTE9jY2MDe3h6LFy8u9s/72dfbi3Tt2hVBQUE4dOgQ+vXrhxYtWhTrWFR0ej/l+ebNm0hLSyvwRfm0f/75By1atIC7uztmz54NFxcXGBsbY/PmzZgzZ440SbY41Go13n//fXz11VeFbs8PcF60PwCMGDECgYGBhdbJPyd/f3/8888/+Ouvv7B9+3b89NNPmDNnDiIiIvDpp58Wu+/5cnJycPHixRcuJU1NTUWTJk1gYWGBb7/9Fm5ubjAxMcGxY8cwatSoEl27fM9bjSSemfhZFEOGDEHbtm0RGRmJbdu2Ydy4cQgPD0dMTAy8vb0L3cfDwwPx8fGIiorC1q1bsW7dOixatAjjx4+XlqKXRP369aXVL8HBwWjcuDG6d++O+Ph4mJubA3gyGbR3794IDg7GyJEj4eDgAENDQ4SHh2tMzs2ny2tVXM87dmn26VlP/+YMPHl/KRQKbNmypdB+5v8cAGDWrFno3bu39P4aNGgQwsPDceDAAY2sWFG5u7vj+PHjuHHjRoGgTlvarOB73k3NCps8r+trUhhdvX66d++Ofv36ITExER988AGsrKwKrbdnzx58+OGH8Pf3x6JFi+Dk5AQjIyMsXbq0wET7l3n29fYi9+7dw5EjRwAA586dg1qtLtXl4G8yvQ9YVqxYAQDP/dIHgP/973/IysrCxo0bNaL6Z1dk5MvPfjz9Bs+/Z0J+tsDNzQ0ZGRnSb4XP87wPiXfffRcAYGRk9NI2AMDGxgZ9+vRBnz59kJGRAX9/f0yYMEGrgGXt2rV49OjRC6/drl27cO/ePaxfvx7+/v5SeUJCgka9ihUrAnhy7Zo1ayaV5+bm4urVqxr3ySmq/Dbj4+M17hWTX5a/PZ+bmxuGDx+O4cOH49KlS6hduzZmzZqlsYLsWWZmZvjoo4/w0UcfITs7Gx06dMDkyZMRFhamk3um5AchzZo1w4IFC6T7NKxduxbvvvsu1q9fr/EaKel9M/KvRWHDhvHx8QXq7tixAw8ePNDIsuQP7z17XV+1p3/uz7pw4QLs7OxeumzZzc0NQgi4urq+9JcHAPDy8oKXlxfGjh2L/fv347333kNERAQmTZoE4Pnv48K0bdsWv//+O3777TeEhYW9sG5xX+PayM9gpKamapQ/m/nI97Jr8qyKFSs+92eWv10O7du3x2effYYDBw5g9erVz623bt06mJiYYNu2bRoZz6VLlxaoq8s71oaGhuLBgwcIDw9HWFgY5s6di2HDhumsffqPXoeBMTEx+O677+Dq6ooePXo8t15+JP905J6WllboCxUAbt26pbEcND09Hb/++itq164NlUoF4MnYaVxcHLZt21Zg/9TUVOTm5gIAypYtK5U9zcHBAU2bNsUPP/yA27dvF2jj6bvQ3rt3T2Obubk5KleujKysrOee88ucPHkSQ4YMgbW1NUJDQ59br7Brl52djUWLFmnUq1u3LmxtbfHjjz9K5w4AK1euLHG6um7dunBwcEBERITGuW7ZsgXnz59HUFAQgCc353v8+LHGvm5ubihXrtwLr9Gz19XY2Bienp4QQiAnJ0cq13ZZc9OmTVG/fn3MnTtX6mdh1/XgwYOIi4sr0TGcnJxQu3ZtLF++XCO9HR0dXWDuQOvWrZGXl6exnB0A5syZA4VCgQ8++KBEfdCVp8/l6ffNmTNnsH37drRu3fqlbXTo0AGGhoaYOHFigd/YhRDSzz49PV3j9Qo8+aI2MDDQeO2YmZkVeA8/T6dOneDl5YXJkycX+vN88OABxowZA6Dor3FdcHNzAwCN+XV5eXlYsmSJRr2iXpNntW7dGocOHdI458zMTCxZsgSVKlWS7b4w5ubmWLx4MSZMmIC2bds+t56hoSEUCoVGRunq1auF3tG2OD/vF1m7di1Wr16NqVOnYvTo0ejatSvGjh0r600D32Z6k2HZsmULLly4gNzcXCQlJSEmJgbR0dGoWLEiNm7c+MLfhlu2bAljY2O0bdsWn332GTIyMvDjjz/CwcGh0GChatWqCAkJweHDh+Ho6IhffvkFSUlJGgHOyJEjsXHjRrRp0wa9e/eGj48PMjMzcfr0aaxduxZXr16FnZ0dTE1N4enpidWrV6Nq1aqwsbFBjRo1UKNGDSxcuBCNGzeGl5cX+vXrh3fffRdJSUmIi4vDzZs3cfLkSQCAp6cnmjZtCh8fH9jY2ODIkSNYu3YtBg4cWKRrt2fPHjx+/Bh5eXm4d+8e9u3bh40bN8LS0hIbNmyQgrDCNGrUCNbW1ujVqxcGDRoEhUKBFStWFPgSMDY2xoQJE/Dll1+iefPm6NKli3TvBzc3txL9xmJkZIRp06ahT58+aNKkCbp164akpCTMmzcPlSpVwtChQwE8yX61aNECXbp0gaenJ8qUKYMNGzYgKSkJXbt2fW77LVu2hEqlwnvvvQdHR0ecP38eCxYsQFBQkEbmwcPDA02aNNHqzyuMHDkSnTt3xrJly/D555+jTZs2WL9+Pdq3b4+goCAkJCQgIiICnp6eyMjIKNExwsPDERQUhMaNG6Nv375ISUmR7jPzdJtt27ZFs2bNMGbMGFy9ehW1atXC9u3b8ddff2HIkCHSF1tpmjFjBj744AP4+voiJCQEjx49wvfffw9LS0uN+xg9j5ubGyZNmoSwsDBcvXoVwcHBKFeuHBISErBhwwb0798fI0aMQExMDAYOHIjOnTujatWqyM3NxYoVK2BoaIiOHTtK7fn4+GDHjh2YPXs2nJ2d4erqKk0yfpaRkRHWr1+PgIAA+Pv7o0uXLnjvvfdgZGSEs2fPYtWqVbC2tsbkyZOL/BrXherVq6Nhw4YICwtDSkoKbGxs8McffxQITop6TZ41evRo/P777/jggw8waNAg2NjYYPny5UhISMC6detkHQbp1avXS+sEBQVh9uzZaNWqFbp3747k5GQsXLgQlStXLjAnsDg/7+dJTk7GgAED0KxZM+mzesGCBfj777/Ru3dv7N27l0NDuvbK1yU949klkMbGxkKlUon3339fzJs3T2NZZb7Clpdt3LhR1KxZU5iYmIhKlSqJadOmiV9++aXAMr/8pXDbtm0TNWvWFEqlUri7uxe6xO/BgwciLCxMVK5cWRgbGws7OzvRqFEjMXPmTI37Y+zfv1/4+PgIY2PjAkuc//nnH9GzZ0+hUqmEkZGReOedd0SbNm3E2rVrpTqTJk0S9evXF1ZWVsLU1FS4u7uLyZMnaxyjMPnLB/MfRkZGwt7eXvj7+4vJkyeL5OTk517vp6/Jvn37RMOGDYWpqalwdnYWX331ldi2bZvGUsh88+fPFxUrVhRKpVLUr19f7Nu3T/j4+IhWrVoV6Nez1zR/Ce/SpUs1ylevXi28vb2FUqkUNjY2okePHuLmzZvS9rt374rQ0FDh7u4uzMzMhKWlpWjQoIH4888/Ndp5dlnzDz/8IPz9/YWtra1QKpXCzc1NjBw5ssCSQ2h5HxYhhMjLyxNubm7Czc1N5ObmCrVaLaZMmSJdK29vbxEVFSV69eqlsQQ5/5oUtmT72deSEEKsW7dOeHh4CKVSKTw9PcX69esLtCnEk9fu0KFDhbOzszAyMhJVqlQRM2bMEGq1usAxQkNDNcqe16eiLKN/2XV62o4dO8R7770nTE1NhYWFhWjbtq04d+6cRp389/rT93B52rp160Tjxo2FmZmZMDMzE+7u7iI0NFTEx8cLIYS4cuWK6Nu3r3BzcxMmJibCxsZGNGvWTOzYsUOjnQsXLgh/f39hamoqABRpifP9+/fF+PHjhZeXlyhbtqwwMTERNWrUEGFhYeL27dsadV/2GhfiybJmMzOzAscp7POusCW9Qjz5vAkICBBKpVI4OjqKr7/+WkRHR2u8l4t6TZ5d1pzffqdOnYSVlZUwMTER9evX17jHiRDFf/8/q6ivn8Kuwc8//yyqVKkifa4vXbq00Ov3vJ/3i15vz7bToUMHUa5cOY171wjx3y0Jpk2b9sL+U/EphCiFGXT0xlCr1bC3t0eHDh3w448/lnZ3iIjoDcV8FRXZ48ePCwwV/frrr0hJSSm1P/xIRERvB2ZYqMh27dqFoUOHonPnzrC1tcWxY8fw888/w8PDA0ePHn1lf3yQiIjePnoz6Zb0X6VKleDi4oL58+dLk/p69uyJqVOnMlghIiJZMcNCREREeo9zWIiIiEjvMWAhIiIivceAhYiIiPQeAxYiIiLSewxYiIiISO8xYCEiIiK9x4CFiIiI9B4DFiIiItJ7DFiIiIhI7zFgISIiIr3HgIWIiIj0HgMWIiIi0nsMWIiIiEjvMWAhIiIivceAhYiIiPQeAxYiIiLSewxYiIiISO8xYCEiIiK9x4CFiIiI9B4DFiIiItJ7DFiIiIhI7zFgISIiIr3HgIWIiIj0HgMWIiIi0ntlSrsDsji7rrR7QKSXYmxrlXYXiPROc1Vl+Q+iq++l6h11085riBkWIiIi0ntvZoaFiIhIj4i8PJ20o9BJK68nBixERERyy8st7R689hiwEBERyUyodROwvM0ZFs5hISIiIr3HDAsREZHcdDSH5W3GgIWIiEhmgnNYtMYhISIiItJ7zLAQERHJjRkWrTFgISIikpmuVgm9zTgkRERERHqPGRYiIiK5cZWQ1hiwEBERyYyrhLTHISEiIiLSe8ywEBERyY0ZFq0xYCEiIpKZUHMOi7YYsBAREcmMc1i0xzksREREpPeYYSEiIpIbMyxaY8BCREQkM85h0R6HhIiIiEjvMcNCREQkNw4JaY0BCxERkcy4Skh7HBIiIiIivccMCxERkdyYYdEaAxYiIiKZcZWQ9jgkRERERHqPGRYiIiK5cUhIawxYiIiIZCbyOCSkLQYsREREMuOyZu1xDgsRERHpPWZYiIiI5KZmhkVbDFiIiIhkxjks2uOQEBEREek9ZliIiIjkxgyL1hiwEBERyYyrhLTHISEiIqI3VGxsLNq2bQtnZ2coFApERkY+t+7nn38OhUKBuXPnapSnpKSgR48esLCwgJWVFUJCQpCRkaFR59SpU/Dz84OJiQlcXFwwffr0Au2vWbMG7u7uMDExgZeXFzZv3lysc2HAQkREJLe8PN08iikzMxO1atXCwoULX1hvw4YNOHDgAJydnQts69GjB86ePYvo6GhERUUhNjYW/fv3l7anp6ejZcuWqFixIo4ePYoZM2ZgwoQJWLJkiVRn//796NatG0JCQnD8+HEEBwcjODgYZ86cKfK5KIQQosi1Xxdn15V2D4j0UoxtrdLuApHeaa6qLPsx0qa30Uk7ll9FlXhfhUKBDRs2IDg4WKP833//RYMGDbBt2zYEBQVhyJAhGDJkCADg/Pnz8PT0xOHDh1G3bl0AwNatW9G6dWvcvHkTzs7OWLx4McaMGYPExEQYGxsDAEaPHo3IyEhcuHABAPDRRx8hMzMTUVH/9b9hw4aoXbs2IiIiitR/ZliIiIheE1lZWUhPT9d4ZGVllbg9tVqNTz75BCNHjkT16tULbI+Li4OVlZUUrABAQEAADAwMcPDgQamOv7+/FKwAQGBgIOLj43H//n2pTkBAgEbbgYGBiIuLK3JfGbAQERHJTKjzdPIIDw+HpaWlxiM8PLzE/Zo2bRrKlCmDQYMGFbo9MTERDg4OGmVlypSBjY0NEhMTpTqOjo4adfKfv6xO/vai4CohIiIiueloWXNYWBiGDRumUaZUKkvU1tGjRzFv3jwcO3YMCoVCF92TFQMWIiIimenqTrdKpbLEAcqz9uzZg+TkZFSoUEEqy8vLw/DhwzF37lxcvXoVKpUKycnJGvvl5uYiJSUFKpUKAKBSqZCUlKRRJ//5y+rkby8KDgkRERG9hT755BOcOnUKJ06ckB7Ozs4YOXIktm3bBgDw9fVFamoqjh49Ku0XExMDtVqNBg0aSHViY2ORk5Mj1YmOjka1atVgbW0t1dm5c6fG8aOjo+Hr61vk/jLDQkREJDORpy6V42ZkZODy5cvS84SEBJw4cQI2NjaoUKECbG1tNeobGRlBpVKhWrVqAAAPDw+0atUK/fr1Q0REBHJycjBw4EB07dpVWgLdvXt3TJw4ESEhIRg1ahTOnDmDefPmYc6cOVK7gwcPRpMmTTBr1iwEBQXhjz/+wJEjRzSWPr8MMyxERERyy1Pr5lFMR44cgbe3N7y9vQEAw4YNg7e3N8aPH1/kNlauXAl3d3e0aNECrVu3RuPGjTUCDUtLS2zfvh0JCQnw8fHB8OHDMX78eI17tTRq1AirVq3CkiVLUKtWLaxduxaRkZGoUaNGkfvB+7AQvUV4Hxaigl7FfVhSxjbRSTs2k3brpJ3XEYeEiIiIZKarSbdvMwYsREREMhN5b95gxqvGOSxERESk95hhISIikllprRJ6kzBgISIikhkDFu1xSIiIiIj0HjMsREREMhNqTrrVFgMWIiIimXGVkPYYsBAREclM8DYsWuMcFiIiItJ7zLAQERHJjENC2mPAQkREJDM1VzVrjUNCREREpPeYYSEiIpIZJ91qjwELERGRzBiwaI9DQkRERKT3mGEhIiKSGSfdao8BCxERkcw4JKQ9DgkRERGR3mOGhYiISGZqtaK0u/DaY8BCREQkM85h0R4DFiIiIplxDov2OIeFiIiI9B4zLERERDLjHBbtMWAhIiKSmZpDQlrjkBARERHpPWZYiIiIZMYhIe0xYCEiIpKZYMCiNQ4JERERkd5jhoWIiEhmvHGc9hiwEBERyYxzWLTHISEiIiLSe8ywEBERyYwZFu0xYCEiIpJZHgMWrTFgISIikhkzLNrjHBYiIiLSewxYiIiIZKYWCp08iis2NhZt27aFs7MzFAoFIiMjpW05OTkYNWoUvLy8YGZmBmdnZ/Ts2RO3bt3SaCMlJQU9evSAhYUFrKysEBISgoyMDI06p06dgp+fH0xMTODi4oLp06cX6MuaNWvg7u4OExMTeHl5YfPmzcU6FwYsREREMlOrdfMorszMTNSqVQsLFy4ssO3hw4c4duwYxo0bh2PHjmH9+vWIj4/Hhx9+qFGvR48eOHv2LKKjoxEVFYXY2Fj0799f2p6eno6WLVuiYsWKOHr0KGbMmIEJEyZgyZIlUp39+/ejW7duCAkJwfHjxxEcHIzg4GCcOXOmyOeiEEKI4l8CPXd2XWn3gEgvxdjWKu0uEOmd5qrKsh9j73t+Ommn8b49Jd5XoVBgw4YNCA4Ofm6dw4cPo379+rh27RoqVKiA8+fPw9PTE4cPH0bdunUBAFu3bkXr1q1x8+ZNODs7Y/HixRgzZgwSExNhbGwMABg9ejQiIyNx4cIFAMBHH32EzMxMREVFScdq2LAhateujYiIiCL1n5Nu3zKHzybg57/24Mw//+LO/QdYOOpjBDTwfOE+2Tm5WPhnDDbuPoE7qQ/gYF0OX3Rpjk4t6srWz4NnrmDq0s24dCMJTnaWGNCpGTo09ym07pL1uzHrt23oGdQIY0LayNYnouJKvXMXG35YirMHjyL7cRbs33FCz9FDUdG9CgDg8cNHiFyyDCf3xiEz7QFsnRzRrOOH8G/XupR7TrqWV4LhnMJkZWUhKytLo0ypVEKpVOqk/bS0NCgUClhZWQEA4uLiYGVlJQUrABAQEAADAwMcPHgQ7du3R1xcHPz9/aVgBQACAwMxbdo03L9/H9bW1oiLi8OwYcM0jhUYGKgxRPUyDFjeMg+zslGtkgodm/tg4PSVRdpn8MzfcS81A5NDO6CCky3u3H8AtbrkibmbyffR4vMZiF8/pdDtN5JS8Nnk5ejasgFmDu2CuFP/YOyiDbC3Lgc/76oadU9duok/th9CtYqqEveHSA6ZDx5gxsCRqFa7JgZOnwhzK0sk37yFsuXMpTrrFv6I+OOn0GfMCNiqHHHu8DH8MXcRLO1sUOu9hqXYe9I1Xa0SCg8Px8SJEzXKvvnmG0yYMEHrth8/foxRo0ahW7dusLCwAAAkJibCwcFBo16ZMmVgY2ODxMREqY6rq6tGHUdHR2mbtbU1EhMTpbKn6+S3URQMWN4yTepUQ5M61YpcP/bYRRw+m4Adi0fAqlxZAEB5B+sC9dZEH8YvG/fiZvJ9vONghU9aN0KPD0r2gfvHtkMo72CN0X2e/JbpVt4BR89fxbL/7dMIWDIfZWHk3NWYNKA9Fq/9u0THIpLL9lVrYW1vj55hQ6UyOyfNwPqfsxfQMLAFqnrXBAD4ffgB9vxvC66ev8iAhQoVFhZWIFOhi+xKTk4OunTpAiEEFi9erHV7cijVgOXu3bv45ZdfEBcXJ0VZKpUKjRo1Qu/evWFvb1+a3SMAMYfPo0bld/BTZCz+2n0CZZVGaF7PA4O7vQ8TpREAYOPuE5j3xw6M79cWHq7OOJ9wC+MWbUBZE2O0b1an2Mc8cfE6fGtqjik3rl0VU5ZGaZR9++NGNPFxR6NalRmwkN45te8gPOvXwY/jp+DiyTOwsrNFk+AgNG7bSqrjVt0dp/YdRKPW78PSzhYXj59C8o1b6Dyw+O8b0m+6GhLS5fBPvvxg5dq1a4iJiZGyK8CT7+Tk5GSN+rm5uUhJSYFKpZLqJCUladTJf/6yOvnbi6LUVgkdPnwYVatWxfz582FpaQl/f3/4+/vD0tIS8+fPh7u7O44cOVJa3aP/dyMpBUfPX8Ol60lYOKoHvu7bBtvizmDikr+kOt+v3oHRvVujZcMacHG0QcuGNdCr7XtYvf1QiY559/4D2FmZa5TZWZkj42EWHmflAAA27T2Jc1duYfjHLUt+ckQyuns7EbF/bYZ9+XcwaMZ38G/XGn/O/wFxW3dIdboMHgBVpQoI69QLA1u0w4KvxqPrkAGoUqtGKfac5FBay5pfJj9YuXTpEnbs2AFbW1uN7b6+vkhNTcXRo0elspiYGKjVajRo0ECqExsbi5ycHKlOdHQ0qlWrBmtra6nOzp07NdqOjo6Gr69vkftaahmWL7/8Ep07d0ZERAQUCs0fghACn3/+Ob788kvExcW9sJ1CJyBl50BpbKTzPr+NhBBQKICZQz5COTMTAMDoPq0xaMbv+KZ/O6iFwPXEFIxZuB7jFm+Q9svNU6Nc2f9+CwgaPBe37qRKbQKAd/cJ0nYfj0r4aVzvIvXp9t1UTP45Cr9805c/Z9JbQi1QsVplBPfvBQBwqeqGWwnXsOevLfBtFQAA2LV+IxLOXcCAKeNho3LA5ZNn8MfcxbC0s4FHXe/S7D69ITIyMnD58mXpeUJCAk6cOAEbGxs4OTmhU6dOOHbsGKKiopCXlyeNdtjY2MDY2BgeHh5o1aoV+vXrh4iICOTk5GDgwIHo2rUrnJ2dAQDdu3fHxIkTERISglGjRuHMmTOYN28e5syZIx138ODBaNKkCWbNmoWgoCD88ccfOHLkiMbS55cptYDl5MmTWLZsWYFgBXiy9Gro0KHw9n75G7bQCUgDOmNC6Ec66+vbzN66HBxtLKRgBXgyp0QIgcR7aTD//6DkuwHtUauqi8a+Bgb//WyXjOmF3LwnNxFISknDJ+N+QuSsL6XtJsb/vRTtrMvhbqrmTYnupmbAvKwSJkojnD1xC/fSMtFhxH/3FchTq3H43FWs3HIAp1d/C0ND3mKISpelrTVUlSpolKkquuB47H4AQHZWFv768Vd8NmkMvHzrAwDKu7nixuUr2LF6PQOWN4yuhoSK68iRI2jWrJn0PH/+S69evTBhwgRs3LgRAFC7dm2N/f7++280bdoUALBy5UoMHDgQLVq0gIGBATp27Ij58+dLdS0tLbF9+3aEhobCx8cHdnZ2GD9+vMa9Who1aoRVq1Zh7Nix+Prrr1GlShVERkaiRo2iZxNLLWBRqVQ4dOgQ3N3dC91+6NChAjOKC1PoBKR/inf3PHq+Ou4VsXX/GWQ+yoKZ6ZPgJOHWXRgYKKCytYSJ0ggONha4kZSCD5vUfm477zw1UTc/mKjoZFto3dpVKyD2WLxG2f5Tl1C76pMP/4Y13fC/OYM0toctWId3y9ujX7A/gxXSC+/W8ETS9X81ypJv/gtbxydz8/Jy85CXmwuFQvP1amBgAKHFKjzST3ml9CNt2rQpXnS7taLcis3GxgarVq16YZ2aNWtiz54X3yOmc+fO6Ny580uP9zylFrCMGDEC/fv3x9GjR9GiRQspOElKSsLOnTvx448/YubMmS9tp9AJSBwmeK7MR1m4nnhPen4zOQXnE27B0rwsnO2tMOu3bUi6l47pg5+8qNr41cKiNX8jbME6DOraAvfTH2LG8i3o2NxHmnQ76KMWmPRzFMqZmcDPuyqyc3Jx5vK/SM98hD4fNi52H7sG1sfKLXGY/uuT4xw4fQVb9p3BD2N6AgDMTZWo+swy5rImxrAyL1ugnKi0tOgcjBmhI7BlxWr4NPPD1fMXsfd/W9FjxJPMoqlZWVSp7YX1Eb/AWGkMG5UDLp04jYPbYtAx9NNS7j3pmhzzT942pRawhIaGws7ODnPmzMGiRYuQl5cHADA0NISPjw+WLVuGLl26lFb33lhn/vkXPcf/JD0PX/okG9W+WR1M/bIT7tx/gNt3U6XtZqZK/PJNH0z6KQodRy6CVbmy+KCRF4Z0f1+q0/n9ejBRGuHnv/Zg+vItKGtijKoVHNGrzXsl6qOLow1+GNML4Us34deo/VDZWmLSF+0L3IOFSJ9V8qiKzyeNReSSZdj86++wUzmi88D+qP/+f+n5kPFf4a8ly/HLpJl4mP4ANioHfPhpT944jqgQenFr/pycHNy9excAYGdnByMjLTMkvDU/UaF4a36igl7Frfk31AnQSTvtj+14eaU3lF7cOM7IyAhOTk6l3Q0iIiJZlNYcljcJZycSERGR3tOLDAsREdGbLA+cdKstBixEREQy45CQ9jgkRERERHqPGRYiIiKZ5ZV2B94ADFiIiIhkxoBFexwSIiIiIr3HDAsREZHMuEpIewxYiIiIZJZX+jeVf+0xYCEiIpIZ57Boj3NYiIiISO8xw0JERCQzZli0x4CFiIhIZgxYtMchISIiItJ7zLAQERHJLA9cJaQtBixEREQy45CQ9jgkRERERHqPGRYiIiKZ8cZx2mPAQkREJDMOCWmPQ0JERESk95hhISIikhlXCWmPAQsREZHMGLBojwELERGRzDiHRXucw0JERER6jxkWIiIimXFZs/YYsBAREcmMc1i0xyEhIiIi0nvMsBAREcmMGRbtMWAhIiKSmZpzWLTGISEiIiLSe8ywEBERyYxDQtpjwEJERCQzBiza45AQERHRGyo2NhZt27aFs7MzFAoFIiMjNbYLITB+/Hg4OTnB1NQUAQEBuHTpkkadlJQU9OjRAxYWFrCyskJISAgyMjI06pw6dQp+fn4wMTGBi4sLpk+fXqAva9asgbu7O0xMTODl5YXNmzcX61wYsBAREcksTwidPIorMzMTtWrVwsKFCwvdPn36dMyfPx8RERE4ePAgzMzMEBgYiMePH0t1evTogbNnzyI6OhpRUVGIjY1F//79pe3p6elo2bIlKlasiKNHj2LGjBmYMGEClixZItXZv38/unXrhpCQEBw/fhzBwcEIDg7GmTNninwuCiHewKnLZ9eVdg+I9FKMba3S7gKR3mmuqiz7MfpV99VJOz+ejSvxvgqFAhs2bEBwcDCAJ9kVZ2dnDB8+HCNGjAAApKWlwdHREcuWLUPXrl1x/vx5eHp64vDhw6hbty4AYOvWrWjdujVu3rwJZ2dnLF68GGPGjEFiYiKMjY0BAKNHj0ZkZCQuXLgAAPjoo4+QmZmJqKgoqT8NGzZE7dq1ERERUaT+M8NCREQkM7UQOnlkZWUhPT1d45GVlVWiPiUkJCAxMREBAQFSmaWlJRo0aIC4uCeBUVxcHKysrKRgBQACAgJgYGCAgwcPSnX8/f2lYAUAAgMDER8fj/v370t1nj5Ofp384xQFAxYiIqLXRHh4OCwtLTUe4eHhJWorMTERAODo6KhR7ujoKG1LTEyEg4ODxvYyZcrAxsZGo05hbTx9jOfVyd9eFFwlREREJDNdrRIKCwvDsGHDNMqUSqVO2tZ3DFiIiIhkpquARalU6ixAUalUAICkpCQ4OTlJ5UlJSahdu7ZUJzk5WWO/3NxcpKSkSPurVCokJSVp1Ml//rI6+duLgkNCREREbyFXV1eoVCrs3LlTKktPT8fBgwfh6/tkkrCvry9SU1Nx9OhRqU5MTAzUajUaNGgg1YmNjUVOTo5UJzo6GtWqVYO1tbVU5+nj5NfJP05RMGAhIiKSma4m3RZXRkYGTpw4gRMnTgB4MtH2xIkTuH79OhQKBYYMGYJJkyZh48aNOH36NHr27AlnZ2dpJZGHhwdatWqFfv364dChQ9i3bx8GDhyIrl27wtnZGQDQvXt3GBsbIyQkBGfPnsXq1asxb948jaGrwYMHY+vWrZg1axYuXLiACRMm4MiRIxg4cGCRz4VDQkRERDIrrTvdHjlyBM2aNZOe5wcRvXr1wrJly/DVV18hMzMT/fv3R2pqKho3boytW7fCxMRE2mflypUYOHAgWrRoAQMDA3Ts2BHz58+XtltaWmL79u0IDQ2Fj48P7OzsMH78eI17tTRq1AirVq3C2LFj8fXXX6NKlSqIjIxEjRo1inwuvA8L0VuE92EhKuhV3Ielq0fdl1cqgj/OH9FJO68jZliIiIhkVpK71JImBixEREQyU/OPH2qNAQsREZHMmGHRHlcJERERkd5jhoWIiEhmJVmSTJoYsBAREcmstJY1v0k4JERERER6jxkWIiIimamFurS78NpjwEJERCQzLmvWHoeEiIiISO8xw0JERCQz3odFewxYiIiIZMYhIe1xSIiIiIj0HjMsREREMuON47THgIWIiEhmXNSsPQYsREREMmOGRXucw0JERER6jxkWIiIimXGVkPYYsBAREcmMQ0La45AQERER6T1mWIiIiGTGISHtMWAhIiKSGQMW7XFIiIiIiPQeMyxEREQyUzPBorUiBSwbN24scoMffvhhiTtDRET0JuKQkPaKFLAEBwcXqTGFQoG8vDxt+kNERERUQJECFrWafwWBiIiopJhh0R7nsBAREcmM943TXokClszMTOzevRvXr19Hdna2xrZBgwbppGNERERvCmZYtFfsgOX48eNo3bo1Hj58iMzMTNjY2ODu3bsoW7YsHBwcGLAQERGRzhX7PixDhw5F27Ztcf/+fZiamuLAgQO4du0afHx8MHPmTDn6SERE9FoTOnq8zYodsJw4cQLDhw+HgYEBDA0NkZWVBRcXF0yfPh1ff/21HH0kIiJ6rakhdPJ4mxU7YDEyMoKBwZPdHBwccP36dQCApaUlbty4odveEREREaEEc1i8vb1x+PBhVKlSBU2aNMH48eNx9+5drFixAjVq1JCjj0RERK+1tzs3ohvFzrBMmTIFTk5OAIDJkyfD2toaAwYMwJ07d7BkyRKdd5CIiOh1xzks2it2hqVu3brS/x0cHLB161addoiIiIjoWfxrzURERDIrjUm3eXl5GDduHFxdXWFqago3Nzd89913EE/dxU4IgfHjx8PJyQmmpqYICAjApUuXNNpJSUlBjx49YGFhASsrK4SEhCAjI0OjzqlTp+Dn5wcTExNpIY6uFTvD4urqCoVC8dztV65c0apDREREb5rSGM6ZNm0aFi9ejOXLl6N69eo4cuQI+vTpA0tLS+meadOnT8f8+fOxfPlyuLq6Yty4cQgMDMS5c+dgYmICAOjRowdu376N6Oho5OTkoE+fPujfvz9WrVoFAEhPT0fLli0REBCAiIgInD59Gn379oWVlRX69++vs/MpdsAyZMgQjec5OTk4fvw4tm7dipEjR+qqX0RERKSF/fv3o127dggKCgIAVKpUCb///jsOHToE4El2Ze7cuRg7dizatWsHAPj111/h6OiIyMhIdO3aFefPn8fWrVtx+PBhaUrI999/j9atW2PmzJlwdnbGypUrkZ2djV9++QXGxsaoXr06Tpw4gdmzZ5duwDJ48OBCyxcuXIgjR45o3SEiIqI3TWlkWBo1aoQlS5bg4sWLqFq1Kk6ePIm9e/di9uzZAICEhAQkJiYiICBA2sfS0hINGjRAXFwcunbtiri4OFhZWWnMXw0ICICBgQEOHjyI9u3bIy4uDv7+/jA2NpbqBAYGYtq0abh//z6sra11cj46m8PywQcfYN26dbpqjoiI6I2hq1VCWVlZSE9P13hkZWUVeszRo0eja9eucHd3h5GREby9vTFkyBD06NEDAJCYmAgAcHR01NjP0dFR2paYmAgHBweN7WXKlIGNjY1GncLaePoYuqCzgGXt2rWwsbHRVXNERERvDF0FLOHh4bC0tNR4hIeHF3rMP//8EytXrsSqVatw7NgxLF++HDNnzsTy5ctlPVe5lOjGcU9PuhVCIDExEXfu3MGiRYt02jkiIiL6T1hYGIYNG6ZRplQqC607cuRIKcsCAF5eXrh27RrCw8PRq1cvqFQqAEBSUpJ0f7X857Vr1wYAqFQqJCcna7Sbm5uLlJQUaX+VSoWkpCSNOvnP8+voQrEDlnbt2mkELAYGBrC3t0fTpk3h7u6us45pY6XCo7S7QKSXrl7MeHklordMc919p8pOqVQ+N0B51sOHD6U/pZPP0NAQarUawJNVvyqVCjt37pQClPT0dBw8eBADBgwAAPj6+iI1NRVHjx6Fj48PACAmJgZqtRoNGjSQ6owZMwY5OTkwMjICAERHR6NatWo6m78ClCBgmTBhgs4OTkRE9HZ4/u1A5NK2bVtMnjwZFSpUQPXq1XH8+HHMnj0bffv2fdIjhQJDhgzBpEmTUKVKFWlZs7OzM4KDgwEAHh4eaNWqFfr164eIiAjk5ORg4MCB6Nq1K5ydnQEA3bt3x8SJExESEoJRo0bhzJkzmDdvHubMmaPT8yl2wGJoaIjbt28XmIRz7949ODg4IC8vT2edIyIiopL5/vvvMW7cOHzxxRdITk6Gs7MzPvvsM4wfP16q89VXXyEzMxP9+/dHamoqGjdujK1bt0r3YAGAlStXYuDAgWjRogUMDAzQsWNHzJ8/X9puaWmJ7du3IzQ0FD4+PrCzs8P48eN1uqQZABTi6VveFYGBgUGhs4Zv3boFNzc3PHr0SKcdLImV586VdheI9NLVu9ml3QUivTPGv7bsx6hU0VUn7Vy9lqCTdl5HRc6w5EdTCoUCP/30E8zNzaVteXl5iI2N1Zs5LERERPrl1Q8JvWmKHLDkj0UJIRAREQFDQ0Npm7GxMSpVqoSIiAjd95CIiIjeekUOWBISnqShmjVrhvXr1+t05i8REdEbjQkWrRV70u3ff/8tRz+IiIjeYDq7T+tbq9hXsGPHjpg2bVqB8unTp6Nz58466RQRERHR04odsMTGxqJ169YFyj/44APExsbqpFNERERvEoWO/r3Nij0klJGRofEXGfMZGRkhPT1dJ50iIiJ6oyje7mBDF4qdYfHy8sLq1asLlP/xxx/w9PTUSaeIiIjeJMywaK/YGZZx48ahQ4cO+Oeff9C8eXMAwM6dO7Fq1SqsXbtW5x0kIiIiKnbA0rZtW0RGRmLKlClYu3YtTE1NUatWLcTExMDGxkaOPhIREb3muEpIW8UOWAAgKCgIQUFBAJ78Zcfff/8dI0aMwNGjR/m3hIiIiJ6h4BwWrZU45IuNjUWvXr3g7OyMWbNmoXnz5jhw4IAu+0ZEREQEoJgZlsTERCxbtgw///wz0tPT0aVLF2RlZSEyMpITbomIiJ5HwSEhbRX5CrZt2xbVqlXDqVOnMHfuXNy6dQvff/+9nH0jIiJ6IyhgoJPH26zIGZYtW7Zg0KBBGDBgAKpUqSJnn4iIiIg0FDlc27t3Lx48eAAfHx80aNAACxYswN27d+XsGxER0RtBoVDo5PE2K3LA0rBhQ/z444+4ffs2PvvsM/zxxx9wdnaGWq1GdHQ0Hjx4IGc/iYiIXl8KA9083mLFPnszMzP07dsXe/fuxenTpzF8+HBMnToVDg4O+PDDD+XoIxEREb3ltArXqlWrhunTp+PmzZv4/fffddUnIiKiN4pCYaCTx9usRDeOe5ahoSGCg4MRHBysi+aIiIjeKG/7Ch9d0EnAQkRERM/3tmdHdIFXkIiIiPQeMyxEREQyUygMS7sLrz0GLERERDLjkJD2eAWJiIhI7zHDQkREJDNmWLTHgIWIiEhmnMOiPYZ8REREpPeYYSEiIpIZh4S0x4CFiIhIZhwS0h5DPiIiItJ7zLAQERHJjBkW7TFgISIikpkB57BojQELERGRzJhh0R5DPiIiItJ7zLAQERHJjBkW7THDQkREJDOFwlAnj+L6999/8fHHH8PW1hampqbw8vLCkSNHpO1CCIwfPx5OTk4wNTVFQEAALl26pNFGSkoKevToAQsLC1hZWSEkJAQZGRkadU6dOgU/Pz+YmJjAxcUF06dPL9mFegEGLERERG+g+/fv47333oORkRG2bNmCc+fOYdasWbC2tpbqTJ8+HfPnz0dERAQOHjwIMzMzBAYG4vHjx1KdHj164OzZs4iOjkZUVBRiY2PRv39/aXt6ejpatmyJihUr4ujRo5gxYwYmTJiAJUuW6PR8FEIIodMW9cDKc+dKuwtEeunq3ezS7gKR3hnjX1v2Y9Sr+5FO2jl8ZHWR644ePRr79u3Dnj17Ct0uhICzszOGDx+OESNGAADS0tLg6OiIZcuWoWvXrjh//jw8PT1x+PBh1K1bFwCwdetWtG7dGjdv3oSzszMWL16MMWPGIDExEcbGxtKxIyMjceHCBS3P+D/MsBAREcnMQGGok0dxbNy4EXXr1kXnzp3h4OAAb29v/Pjjj9L2hIQEJCYmIiAgQCqztLREgwYNEBcXBwCIi4uDlZWVFKwAQEBAAAwMDHDw4EGpjr+/vxSsAEBgYCDi4+Nx//79El2vwjBgISIiek1kZWUhPT1d45GVlVVo3StXrmDx4sWoUqUKtm3bhgEDBmDQoEFYvnw5ACAxMREA4OjoqLGfo6OjtC0xMREODg4a28uUKQMbGxuNOoW18fQxdIEBCxERkcx0Nek2PDwclpaWGo/w8PBCj6lWq1GnTh1MmTIF3t7e6N+/P/r164eIiIhXfPa6wYCFiIhIZroKWMLCwpCWlqbxCAsLK/SYTk5O8PT01Cjz8PDA9evXAQAqlQoAkJSUpFEnKSlJ2qZSqZCcnKyxPTc3FykpKRp1Cmvj6WPoAgMWIiKi14RSqYSFhYXGQ6lUFlr3vffeQ3x8vEbZxYsXUbFiRQCAq6srVCoVdu7cKW1PT0/HwYMH4evrCwDw9fVFamoqjh49KtWJiYmBWq1GgwYNpDqxsbHIycmR6kRHR6NatWoaK5K0xYCFiIhIZgpFGZ08imPo0KE4cOAApkyZgsuXL2PVqlVYsmQJQkND/79PCgwZMgSTJk3Cxo0bcfr0afTs2RPOzs4IDg4G8CQj06pVK/Tr1w+HDh3Cvn37MHDgQHTt2hXOzs4AgO7du8PY2BghISE4e/YsVq9ejXnz5mHYsGE6vYa80y0REZHMirvCRxfq1auHDRs2ICwsDN9++y1cXV0xd+5c9OjRQ6rz1VdfITMzE/3790dqaioaN26MrVu3wsTERKqzcuVKDBw4EC1atICBgQE6duyI+fPnS9stLS2xfft2hIaGwsfHB3Z2dhg/frzGvVp0gfdhIXqL8D4sRAW9ivuw+L33hU7a2bNvkU7aeR1xSIiIiIj0HoeEiIiIZFbc+SdUEK8gERGRzPjXmrXHISEiIiLSe8ywEBERyYxDQtrjFSQiIpJZaSxrftNwSIiIiIj0HjMsREREMlMY8OtWW7yCREREMuMcFu1xSIiIiIj0HkM+IiIimfE+LNpjwEJERCQzDglpj1eQiIhIZpx0qz3OYSEiIiK9x5CPiIhIZhwS0h6vIBERkdwYsGiNQ0JERESk9xjyERERyYyTbrXHK0hERCQzzmHRHoeEiIiISO8x5CMiIpIbh4S0xitIREQkN96aX2scEiIiIiK9xwwLERGRzLhKSHu8gkRERHLjKiGt8QoSERHJTDDDojXOYSEiIiK9x5CPiIhIbgZcJaQtBixERERyY8CiNQ4JERERkd5jhoWIiEhmghkWrTFgISIikhkDFu1xSIiIiIj0HjMsREREcmOGRWsMWIiIiGQmDDigoS0GLG+h9Hv3sPPXX3H52DHkZGfDRqXCh19+CefKlQutf/3cOexYsQL3bt5ETnY2LO3t4dOyJRp++KGs/Ty3bx/+/v13pCYnw9bJCS169kQVHx8AQF5uLv5etQqXjx7F/aQkKMuWxbu1aqHFJ5+gnI2NrP2iN1PSxXM4u+1/uHctAY/S7qPpFyNQwbve8+tfuoBj61YiLfEW8rKzYGZrj6r+AfB8P0jWfl49EocTf/2JjLt3YOGoQp2OPVDey1vafmLjGlw9vB8PU+7BoEwZ2FR0hXdwV9i/W0XWfhHJjSHfW+ZRRgaWhoXBoEwZdB83DgPmz8f7ffrAxMzsufsYmZigfuvW6DV5Mr74/nv4deqEv1etwtHt20vcj6tnzmBe//7P3X7jwgWsmz0b3i1aoP+sWajWoAFWT52K5GvXAAA5WVm4feUK/Lp0Qb9Zs9Bl1Cjc/fdf/DFlSon7RG+33KwsWJeviAbd+xapfhmlEu7NWqHVyAlo9+1s1AzqgBORq3ExdkeJ+5AYfxbrRg987vbky/HY8+N8VG7cDG3GT4VL7XrYtXAG7v97Xapj4eiE+t36oO2EGWj11USY29pjx9zJePwgvcT9Iu0JA0OdPLQxdepUKBQKDBkyRCp7/PgxQkNDYWtrC3Nzc3Ts2BFJSUka+12/fh1BQUEoW7YsHBwcMHLkSOTm5mrU2bVrF+rUqQOlUonKlStj2bJlWvW1MMywvGX2rV8PCzs7tPvyS6nM2tHxhfs4vfsunN59V3pu5eCACwcO4Pq5c/Bp2RIAINRq7NuwAce2b0dGaipsnZ3h17kzPBs1KlE/D0ZFobK3Nxq1bw8AaNa9O66cPInDmzcjaMAAmJiZ4ZMJEzT2+aBfP/z81VdIu3MHlvb2JTouvb3e8fLGO09lKl7GtoIrbCu4Ss/N7Rxw/dhBJF+6gKr+AQCevC/ObP0Ll2J34lF6KiwcnVCzTUdU9GlYoj6e37kFztVro0bgk+ymd/BHuH3uFOJjtqHhJ/0AAO82aKyxT90uPXF579+4f/ManDy8SnRc0p7asHTzA4cPH8YPP/yAmjVrapQPHToUmzZtwpo1a2BpaYmBAweiQ4cO2LdvHwAgLy8PQUFBUKlU2L9/P27fvo2ePXvCyMgIU/7/F8SEhAQEBQXh888/x8qVK7Fz5058+umncHJyQmBgoM7OgQHLW+bi4cNw8/bGmunTce3sWVjY2qJuq1ao8/+BR1HcvnIFN+Lj0ax7d6ls77p1OL17N1p//jlsnZxw7dw5bJg7F2UtLFCpRo1i9/NmfHyBISe32rURf+jQc/fJevgQUChemC0iksu96wlI/ucivIM/kspOb4lEwoE9aPDxp7BwdELSxfPY89MCKM0toKrmWexj3LlyscCQk3P1Wrhx4nCh9fNyc3EpdieMTMvCunzFYh+PdKc057BkZGSgR48e+PHHHzFp0iSpPC0tDT///DNWrVqF5s2bAwCWLl0KDw8PHDhwAA0bNsT27dtx7tw57NixA46Ojqhduza+++47jBo1ChMmTICxsTEiIiLg6uqKWbNmAQA8PDywd+9ezJkzhwELldz9pCQc2boVDT/8EI07dcKty5ex9eefYVimDGr9/wv2eeZ8+ikepqVBrVajyUcfoc777wMAcnNysHfdOnw8YQJc3N0BANYqFW6cP49j27eXKGDJSE2FuZWVRpmZlRUy7t8vtH5udjZ2/voravj5QVm2bLGPR1RSa0cOwOOMdIi8PNT6sDOq+LUAAOTl5ODM5ki8P2ws7N2qAgDK2Tsi+fIFXIzdUaKA5XFaKkzLWWmUmVhY4lFamkbZzZNHEfvjPORmZ8PU0grvDx0Dk3IWJTtBeu2FhoYiKCgIAQEBGgHL0aNHkZOTg4CAAKnM3d0dFSpUQFxcHBo2bIi4uDh4eXnB8alMfGBgIAYMGICzZ8/C29sbcXFxGm3k13l66EkX9DpguXHjBr755hv88ssvz62TlZWFrKwsjbKc7GwYGRvL3b3XkhACzm5uaPHxxwCeDPfcuX4dR7Zte2nA0nvyZGQ/fox/4+Oxc8UK2Dg5oYafH1Ju30ZOVhZ+mzhRo35ebi5Urv+lzMO7dfuvH2o1cnNyNMpq+vsjaMCAYp9TXm4u1s6cCQEg6LPPir0/kTYCv5qI3KzHuHPlEo6tX4Vy9iq4NngPD5ITkZudheg5kzTqq3NzYfPUUNKqgT2l/wu1Gnm5uRpl7zbwk4Z7isrRvTrajJ+OrAfpuLQnBrE/zMUHX0+GqYVlCc+StKWrDEth33lKpRJKpbLQ+n/88QeOHTuGw4cLZuESExNhbGwMq2d+OXR0dERiYqJUx/GZaQP5z19WJz09HY8ePYKpqWnRT/AF9DpgSUlJwfLly18YsISHh2PiM1+U7b/4Ah1DQ+Xu3mupnLU17F1cNMrsypfH+bi4l+6bP9fFsWJFZKSlYfcff6CGnx+yHz8GAHQbMwYWtrYa+xgaGUn//2z2bOn//168iB0rVqDXd99JZcqnXtTmVlbISE3VaCszNRXm1tYaZfnBStqdO/hk4kRmV+iVK2fvAACwLl8Bj9NTcfJ/a+Da4D3kZD15XzT/cjTKWmuuXDMs899Hb5vx06X/371yCcfWrULLkd9IZUYm/70vTCyt8OhBqkZbj9PTYGqpGYgYKU1g5KACHFSwd6uKDWMG4/LeGHi1bq/dyVKJqXUUsBT2nffNN99gwjNz+oAnv/QPHjwY0dHRMDEx0cnxS1OpBiwbN2584fYrV668tI2wsDAMGzZMo2x9EfZ7W7m4u+Puv/9qlN27davYk1TzMyQAYO/iAkMjI6TfvfvC4R8bJyfp/+n37sHAwECj7Gnlq1VDwqlTaNi2rVR25eRJlK9aVXqeH6yk3LqFnt99h7IWTHlT6RJCIO//V09YOZeHQRkjZKbcfeHwj4WDSvr/w/v3oDA01Ch7mv27VZF4/gw8A/6bx3L7/GnYv1u10PqF9Yteb4V95z0vu3L06FEkJyejTp06UlleXh5iY2OxYMECbNu2DdnZ2UhNTdXIsiQlJUGlevIaVKlUOPTM3MH8VURP13l2ZVFSUhIsLCx0ll0BSjlgCQ4OhkKhgBDiuXUUCsUL2ygsFcbhoOdr0LYtloaFYc/ataj+3nv499IlHNu+HW2eGorZuWIFHqSkIHjwYADA4c2bYWFvD7t33gHw5L4scX/9hfpBTz40laam8G3XDtt++QVCrYaLhweyHj7EjQsXoDQ1felQU6H9bNMGy8eORdxff6GKjw/O7N2LW//8I/UzLzcXa6ZPR+KVK+g6ZgyEWi3NbzE1N9fI7BAVRc7jx3iQnCg9z7ibjJTrV2FsZg5zWzscW78KD++noHHIk2XHF/7eBjMbO1iqnAEASRfP49z2KLg3bwXgSWakess2OPLnr4AQcKhcDdmPHiL5cjyMTcvCrVGTYvfRo8UH2DZzIs5u/x/Ke9VBwuH9uHf1H2nIKCfrMU5v2gCXWj4wtbJGVsYDXPh7Gx7eT0GlEq5MIt0QOlol9KLhn2e1aNECp0+f1ijr06cP3N3dMWrUKLi4uMDIyAg7d+5Ex44dAQDx8fG4fv06fH19AQC+vr6YPHkykpOT4eDwJJsYHR0NCwsLeHp6SnU2b96scZzo6GipDV0p1YDFyckJixYtQrt27QrdfuLECfj8/43CSDfeqVIFXUaNQsxvvyH2zz9h7eCAwL594dXkvw/PjPv3kXbnjvRcCIGYFSuQmpwMA0NDWKtUCOjZU1rSDDxZdmxmYYG969fjflISTMqWhZObGxr//5uguFzc3dFh6FD8vWoVYn77DTZOTvho9Gg4VHyy0uFBSgou/v+Y7JJnftvo+d13JZroS2+3e9f+wfaZ30rPj/z5KwDAzbcJ3uv7BR6lpiIz5Z60XajVOL5+FTLu3oHC0ADl7B1Rp2N3aUkzANQO/ggm5SxwekskMu4kwbisGWwquMKrdXCJ+uhQuRr8Pv0SJyJX4/iGP2DhoELT0JGwfqcCAMDAwADpif9iV9xuZGU8gNKsHGwruaHVVxNg9Y7LS1onOQmDF//yLYdy5cqhxjOfhWZmZrC1tZXKQ0JCMGzYMNjY2MDCwgJffvklfH190bDhkwC3ZcuW8PT0xCeffILp06cjMTERY8eORWhoqBQ4ff7551iwYAG++uor9O3bFzExMfjzzz+xadMmnZ6PQrwovSGzDz/8ELVr18a3335b6PaTJ0/C29sbarW6WO2uPHdOF90jeuNcvZtd2l0g0jtj/GvLfgz/wUd10k7sPO1+iW/atClq166NuXPnAnhy47jhw4fj999/R1ZWFgIDA7Fo0SJpuAcArl27hgEDBmDXrl0wMzNDr169MHXqVJR5ai7Wrl27MHToUJw7dw7ly5fHuHHj0Lt3b636+qxSDVj27NmDzMxMtGrVqtDtmZmZOHLkCJo0KV7qlAELUeEYsBAV9CoClsbDjumknb2z67y80huqVIeE/Pz8XrjdzMys2MEKERGRvimNIaE3Df+WEBEREek9vb4PCxER0ZuAGRbtMWAhIiKSmdDuDy0TGLAQERHJjhkW7XEOCxEREek9ZliIiIjkxvSA1hiwEBERyY1zWLTGmI+IiIj0HjMsREREcmN6QGsMWIiIiOTGgEVrvIRERESk95hhISIikpmC6QGtMWAhIiKSmcJAlHYXXnuM+YiIiEjvMcNCREQkMw4JaY8BCxERkcwMeOM4rTFgISIikpkBMyxa4yUkIiIivccMCxERkcy4Skh7DFiIiIhkxiEh7fESEhERkd5jhoWIiEhmzLBojwELERGRzBiwaI+XkIiIiPQeMyxEREQyY4ZFewxYiIiIZMaARXu8hERERKT3mGEhIiKSmSFvHKc1BixEREQy45CQ9hiwEBERyYwBi/Z4CYmIiEjvMcNCREQkM0OmB7TGgIWIiEhmBorS7sHrjzEfERER6T1mWIiIiGTGISHtMWAhIiKSGVcJaY+XkIiI6A0UHh6OevXqoVy5cnBwcEBwcDDi4+M16jx+/BihoaGwtbWFubk5OnbsiKSkJI06169fR1BQEMqWLQsHBweMHDkSubm5GnV27dqFOnXqQKlUonLlyli2bJnOz4cBCxERkcwMDXTzKI7du3cjNDQUBw4cQHR0NHJyctCyZUtkZmZKdYYOHYr//e9/WLNmDXbv3o1bt26hQ4cO0va8vDwEBQUhOzsb+/fvx/Lly7Fs2TKMHz9eqpOQkICgoCA0a9YMJ06cwJAhQ/Dpp59i27ZtWl+3pymEEG/c/YJXnjtX2l0g0ktX72aXdheI9M4Y/9qyH6PP2mM6aWdppzol3vfOnTtwcHDA7t274e/vj7S0NNjb22PVqlXo1KkTAODChQvw8PBAXFwcGjZsiC1btqBNmza4desWHB0dAQAREREYNWoU7ty5A2NjY4waNQqbNm3CmTNnpGN17doVqamp2Lp1q3Yn/BRmWIiIiF4TWVlZSE9P13hkZWUVad+0tDQAgI2NDQDg6NGjyMnJQUBAgFTH3d0dFSpUQFxcHAAgLi4OXl5eUrACAIGBgUhPT8fZs2elOk+3kV8nvw1dYcBCREQkM10NCYWHh8PS0lLjER4e/tLjq9VqDBkyBO+99x5q1KgBAEhMTISxsTGsrKw06jo6OiIxMVGq83Swkr89f9uL6qSnp+PRo0clul6F4SohIiIimelqlVBYWBiGDRumUaZUKl+6X2hoKM6cOYO9e/fqpiOlgAELERGRzAx1dKdbpVJZpADlaQMHDkRUVBRiY2NRvnx5qVylUiE7OxupqakaWZakpCSoVCqpzqFDhzTay19F9HSdZ1cWJSUlwcLCAqampsXq64twSIiIiOgNJITAwIEDsWHDBsTExMDV1VVju4+PD4yMjLBz506pLD4+HtevX4evry8AwNfXF6dPn0ZycrJUJzo6GhYWFvD09JTqPN1Gfp38NnSFGRYiIiKZlcadbkNDQ7Fq1Sr89ddfKFeunDTnxNLSEqamprC0tERISAiGDRsGGxsbWFhY4Msvv4Svry8aNmwIAGjZsiU8PT3xySefYPr06UhMTMTYsWMRGhoqZXo+//xzLFiwAF999RX69u2LmJgY/Pnnn9i0aZNOz4cBCxERkcxKI2BZvHgxAKBp06Ya5UuXLkXv3r0BAHPmzIGBgQE6duyIrKwsBAYGYtGiRVJdQ0NDREVFYcCAAfD19YWZmRl69eqFb7/9Vqrj6uqKTZs2YejQoZg3bx7Kly+Pn376CYGBgTo9H96HhegtwvuwEBX0Ku7DMniTbu7DMi+o5Pdhed0xw0JERCSzMgY6mnX7FmPAQkREJDP+tWbt8RISERGR3mOGhYiISGa6ug/L24wBCxERkcw4JKQ9XkIiIiLSe8ywEBERyYwZFu0xYCEiIpKZIZc1a40BCxERkcyYYdEeLyERERHpPWZYiIiIZMZlzdpjwEJERCQzzmHRHoeEiIiISO8xw0JERCQzTrrVHgMWIiIimXFISHuM+YiIiEjvMcNCREQkMw4JaY8BCxERkcwMFBwS0hZjPiIiItJ7zLAQERHJjENC2mPAQkREJDOuEtIeAxYiIiKZMcOiPV5CIiIi0nvMsBAREcmMQ0LaY8BCREQkMwYs2uOQEBEREek9ZliIiIhkxkm32mPAQkREJDMDDglpjTEfERER6T1mWIiIiGTGSbfaY8BCREQkM85h0R4vIREREek9ZliIiIhkxiEh7TFgISIikhlXCWmPAQsREZHMOIdFe7yEREREpPeYYSEiIpIZ57BojwELERGRzBiwaI9DQkRERKT3FEIIUdqdoDdTVlYWwsPDERYWBqVSWdrdIdIbfG8QFR8DFpJNeno6LC0tkZaWBgsLi9LuDpHe4HuDqPg4JERERER6jwELERER6T0GLERERKT3GLCQbJRKJb755htOKiR6Bt8bRMXHSbdERESk95hhISIiIr3HgIWIiIj0HgMWIiIi0nsMWEg2CxcuRKVKlWBiYoIGDRrg0KFDpd0lolIVGxuLtm3bwtnZGQqFApGRkaXdJaLXBgMWksXq1asxbNgwfPPNNzh27Bhq1aqFwMBAJCcnl3bXiEpNZmYmatWqhYULF5Z2V4heO1wlRLJo0KAB6tWrhwULFgAA1Go1XFxc8OWXX2L06NGl3Dui0qdQKLBhwwYEBweXdleIXgvMsJDOZWdn4+jRowgICJDKDAwMEBAQgLi4uFLsGRERva4YsJDO3b17F3l5eXB0dNQod3R0RGJiYin1ioiIXmcMWIiIiEjvMWAhnbOzs4OhoSGSkpI0ypOSkqBSqUqpV0RE9DpjwEI6Z2xsDB8fH+zcuVMqU6vV2LlzJ3x9fUuxZ0RE9LoqU9odoDfTsGHD0KtXL9StWxf169fH3LlzkZmZiT59+pR214hKTUZGBi5fviw9T0hIwIkTJ2BjY4MKFSqUYs+I9B+XNZNsFixYgBkzZiAxMRG1a9fG/Pnz0aBBg9LuFlGp2bVrF5o1a1agvFevXli2bNmr7xDRa4QBCxEREek9zmEhIiIivceAhYiIiPQeAxYiIiLSewxYiIiISO8xYCEiIiK9x4CFiIiI9B4DFiIiItJ7DFiIiIhI7zFgIXoD9e7dG8HBwdLzpk2bYsiQIa+8H7t27YJCoUBqauorPzYRvVkYsBC9Qr1794ZCoYBCoYCxsTEqV66Mb7/9Frm5ubIed/369fjuu++KVJdBBhHpI/7xQ6JXrFWrVli6dCmysrKwefNmhIaGwsjICGFhYRr1srOzYWxsrJNj2tjY6KQdIqLSwgwL0SumVCqhUqlQsWJFDBgwAAEBAdi4caM0jDN58mQ4OzujWrVqAIAbN26gS5cusLKygo2NDdq1a4erV69K7eXl5WHYsGGwsrKCra0tvvrqKzz7J8KeHRLKysrCqFGj4OLiAqVSicqVK+Pnn3/G1atXpT/OZ21tDYVCgd69ewMA1Go1wsPD4erqClNTU9SqVQtr167VOM7mzZtRtWpVmJqaolmzZhr9JCLSBgMWolJmamqK7OxsAMDOnTsRHx+P6OhoREVFIScnB4GBgShXrhz27NmDffv2wdzcHK1atZL2mTVrFpYtW4ZffvkFe/fuRUpKCjZs2PDCY/bs2RO///475s+fj/Pnz+OHH36Aubk5XFxcsG7dOgBAfHw8bt++jXnz5gEAwsPD8euvvyIiIgJnz57F0KFD8fHHH2P37t0AngRWHTp0QNu2bXHixAl8+umnGD16tFyXjYjeNoKIXplevXqJdu3aCSGEUKvVIjo6WiiVSjFixAjRq1cv4ejoKLKysqT6K1asENWqVRNqtVoqy8rKEqampmLbtm1CCCGcnJzE9OnTpe05OTmifPny0nGEEKJJkyZi8ODBQggh4uPjBQARHR1daB///vtvAUDcv39fKnv8+LEoW7as2L9/v0bdkJAQ0a1bNyGEEGFhYcLT01Nj+6hRowq0RURUEpzDQvSKRUVFwdzcHDk5OVCr1ejevTsmTJiA0NBQeHl5acxbOXnyJC5fvoxy5cpptPH48WP8888/SEtLw+3bt9GgQQNpW5kyZVC3bt0Cw0L5Tpw4AUNDQzRp0qTIfb58+TIePnyI999/X6M8Ozsb3t7eAIDz589r9AMAfH19i3wMIqIXYcBC9Io1a9YMixcvhrGxMZydnVGmzH9vQzMzM426GRkZ8PHxwcqVKwu0Y29vX6Ljm5qaFnufjIwMAMCmTZvwzjvvaGxTKpUl6gcRUXEwYCF6xczMzFC5cuUi1a1Tpw5Wr14NBwcHWFhYFFrHyckJBw8ehL+/PwAgNzcXR48eRZ06dQqt7+XlBbVajd27dyMgIKDA9vwMT15enlTm6ekJpVKJ69evPzcz4+HhgY0bN2qUHThw4OUnSURUBJx0S6THevToATs7O7Rr1w579uxBQkICdu3ahUGDBuHmzZsAgMGDB2Pq1KmIjIzEhQsX8MUXX7zwHiqVKlVCr1690LdvX0RGRkpt/vnnnwCAihUrQqFQICoqCnfu3EFGRgbKlSuHESNGYOjQoVi+fDn++ecfHDt2DN9//z2WL18OAPj8889x6dIljBw5EvHx8Vi1ahWWLVsm9yUiorcEAxYiPVa2bFnExsaiQoUK6NChAzw8PBASEoLHjx9LGZfhw4fjk08+Qa9eveDr64ty5cqhffv2L2x38eLF6NSpE7744gu4u7ujX79+yMzMBAC88847mDhxIkaPHg1HR0cMHDgQAPDdd99h3LhxCA8Ph4eHB1q1aoVNmzbB1dUVAFChQgWsW7cOkZGRqFWrFiIiIjBlyhQZrw4RvU0U4nkz84iIiIj0BDMsREREpPcYsBAREZHeY8BCREREeo8BCxEREek9BixERESk9xiwEBERkd5jwEJERER6jwELERER6T0GLERERKT3GLAQERGR3mPAQkRERHqPAQsRERHpvf8DS4qT/6wkiJ8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.96      1.00      0.98     15801\n",
      "    Positive       0.95      0.68      0.79      1955\n",
      "\n",
      "    accuracy                           0.96     17756\n",
      "   macro avg       0.96      0.84      0.89     17756\n",
      "weighted avg       0.96      0.96      0.96     17756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_trn_np = y_train.to_numpy()\n",
    "y_trn_np_ravel = y_train.to_numpy().ravel()\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "#Fit to training data and labels\n",
    "forest.fit(X_train, y_trn_np_ravel)\n",
    "\n",
    "#Predict results and generate confusion matrix\n",
    "forest_predicted = forest.predict(X_test)\n",
    "forest.score(X_test, y_test)\n",
    "accuracy = accuracy_score(y_test, forest_predicted)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "\n",
    "confusion = confusion_matrix(y_test, forest_predicted)\n",
    "print(confusion)\n",
    "sns.heatmap(confusion, cmap = 'icefire', annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Diabetes Diagnosis: Random Forest Confusion Matrix\\n')\n",
    "plt.show()\n",
    "\n",
    "#Print classification report\n",
    "target_names = ['Negative', 'Positive']\n",
    "print(classification_report(y_test, forest_predicted, target_names = target_names))\n",
    "tp = confusion[0][0]\n",
    "fp = confusion[0][1]\n",
    "tn = confusion[1][1]\n",
    "fn = confusion[1][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c80b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Best_Fit_Randomized(method, param_distributions, X_train, y_train, X_test, y_test):\n",
    "    rand_search_method = RandomizedSearchCV(method, param_distributions=param_distributions, n_iter=30, verbose=1)\n",
    "    best_fit = rand_search_method.fit(X_train, y_train)\n",
    "    predicted = best_fit.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predicted)\n",
    "    return best_fit, accuracy, predicted, rand_search_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "451106ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = np.arange(10, 900, 25)\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = np.arange(4, 10, 1)\n",
    "min_samples_split = np.arange(2, 8, 2)\n",
    "min_samples_leaf = np.arange(1, 4, 1)\n",
    "min_weight_fraction_leaf = np.arange(0, 0.5, 0.1)\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "min_impurity_decrease = np.arange(0.00005, 0.01, 0.002)\n",
    "bootstrap = [True, False]\n",
    "class_weight = [None, 'balanced', 'balanced_subsample']\n",
    "\n",
    "param_distributions = {'n_estimators':n_estimators, 'criterion':criterion, 'max_depth':max_depth,\n",
    "                       'min_samples_split':min_samples_split, 'min_samples_leaf':min_samples_leaf,\n",
    "                       'min_weight_fraction_leaf':min_weight_fraction_leaf, 'max_features':max_features,\n",
    "                       'min_impurity_decrease':min_impurity_decrease,\n",
    "                       'bootstrap':bootstrap, 'class_weight':class_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "30407781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "best_params {'n_estimators': 35, 'min_weight_fraction_leaf': 0.0, 'min_samples_split': 4, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.00805, 'max_features': None, 'max_depth': 4, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'bootstrap': True}\n",
      "best_estimator RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=4, max_features=None,\n",
      "                       min_impurity_decrease=0.00805, min_samples_leaf=3,\n",
      "                       min_samples_split=4, n_estimators=35)\n",
      "best_estimator.feature_importances_ [0.         0.         0.         0.         0.         0.\n",
      " 0.60903221 0.39096779]\n"
     ]
    }
   ],
   "source": [
    "forest_opt = RandomForestClassifier()\n",
    "best_fit_opt, accuracy_opt, predicted_opt, rand_search_opt = Best_Fit_Randomized(forest_opt, param_distributions, X_train, y_trn_np_ravel, X_test, y_test)\n",
    "best_params_opt = best_fit_opt.best_params_\n",
    "best_score_opt = best_fit_opt.best_score_\n",
    "best_estimator_opt = best_fit_opt.best_estimator_\n",
    "print(\"best_params\", best_params_opt)\n",
    "print(\"best_estimator\", best_estimator_opt)\n",
    "\n",
    "print(\"best_estimator.feature_importances_\", best_estimator_opt.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c239c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", best_score_opt)\n",
    "\n",
    "confusion_opt = confusion_matrix(y_test, predicted_opt)\n",
    "print(confusion_opt)\n",
    "sns.heatmap(confusion_opt, cmap = 'icefire', annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "#Print classification report\n",
    "target_names = ['Negative', 'Positive']\n",
    "print(classification_report(y_test, predicted_opt, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f611997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort_Values(unsorted_array):\n",
    "    pos = 0\n",
    "    highest = -1\n",
    "    ordered_array =[]\n",
    "    pos_array = []\n",
    "    while(len(ordered_array) < len(unsorted_array)): #Not all values entered\n",
    "        for i in range(0, len(unsorted_array), 1):\n",
    "            if(unsorted_array[i] >= highest):\n",
    "                highest = unsorted_array[i]\n",
    "                pos = i\n",
    "        ordered_array.append(highest)\n",
    "        pos_array.append(pos)\n",
    "        unsorted_array[pos] = -2 #Ignore position in the future\n",
    "        highest = -1\n",
    "        pos = 0\n",
    "            \n",
    "    return pos_array, ordered_array\n",
    "\n",
    "def Make_Pandas_Cols(head1):\n",
    "    df = pd.DataFrame(columns=head1)\n",
    "    for row in range(0, len(head1), 1):  #All cols except labels\n",
    "        column = head1[row]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def Make_Pandas(array1, array2, head1):\n",
    "    df = Make_Pandas_Cols(head1)\n",
    "    df.loc[\"Unoptimized\"] = array1\n",
    "    df.loc[\"Optimized\"] = array2\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728b92e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort features and importance percentages from highest to lowest for original and optimized\n",
    "\n",
    "feature_orig = forest.feature_importances_\n",
    "feature_opt = best_estimator_opt.feature_importances_\n",
    "pos_array, ordered_array = Sort_Values(feature_orig)\n",
    "print(\"Sorted original feature importance\\n\", pos_array)\n",
    "print(ordered_array)\n",
    "pos_array_opt, ordered_array_opt = Sort_Values(feature_opt)\n",
    "print(\"Sorted optimized feature importance\\n\", pos_array)\n",
    "print(ordered_array_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = []\n",
    "unopt = []\n",
    "opt = []\n",
    "for i in range(0, len(pos_array), 1):\n",
    "    headers.append(df.columns[pos_array[i]])\n",
    "    unopt.append(ordered_array[i] * 100)\n",
    "    opt.append(ordered_array_opt[i] * 100)\n",
    "    feature_pd = Make_Pandas(unopt, opt, headers)\n",
    "    feature_pd = feature_pd.round(decimals=4)\n",
    "    vals = feature_pd.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "plt.title = \"Histogram of Feature Relevance to Diabetes Diagnosis\"\n",
    "plt.bar(headers, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1367ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Outcome = X_test\n",
    "Final_Outcome['actual'] = y_test\n",
    "Final_Outcome['predicted'] = predicted_opt\n",
    "Final_Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f02cd6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.45170457 0.         0.         0.         0.45170457\n",
      " 0.45170457 0.         0.         0.45170457 0.45170457 1.        ]\n"
     ]
    }
   ],
   "source": [
    "y_pred_RFC = best_fit_opt.predict(X_test)\n",
    "\n",
    "RFC_accuracy = accuracy_score(y_test, y_pred_RFC)\n",
    "RFC_f1 = f1_score(y_test, y_pred_RFC)\n",
    "RFC_precision = precision_score(y_test, y_pred_RFC)\n",
    "RFC_recall = recall_score(y_test, y_pred_RFC)\n",
    "\n",
    "RFC_check_probabilities = best_fit_opt.predict_proba(X_check_ensemble)[:,1]\n",
    "print(RFC_check_probabilities[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64513682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#False negative cases, misdiagnosed as not diabetic\n",
    "f_neg_df = Final_Outcome.loc[(Final_Outcome['actual'] == 1) & (Final_Outcome['predicted'] == 0)]\n",
    "f_neg_df = f_neg_df.sort_values(by=['age'])\n",
    "f_neg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b86bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print normal ranges and data ranges\n",
    "print(\"Normal BMI: 18.5 to 24.9\")\n",
    "print(\"Evaluated Range BMI: \", Final_Outcome['bmi'].min(), \"to\", Final_Outcome['bmi'].max())\n",
    "print(\"False Negative Range BMI: \", f_neg_df['bmi'].min(), \"to\", f_neg_df['bmi'].max(), \"\\n\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "f_neg_low_bmi = f_neg_df.loc[(f_neg_df['bmi'] <= 30) & (f_neg_df['HbA1c_level'] > 5.7) & (f_neg_df['blood_glucose_level'] > 99)]\n",
    "\n",
    "f_neg_low_bmi = f_neg_low_bmi.sort_values(by=['bmi'])\n",
    "print(len(f_neg_low_bmi))\n",
    "#f_neg_low_bmi\n",
    "\n",
    "#Create histograms showing number of false negatives by BMI\n",
    "plt.hist(f_neg_df['bmi'], bins='auto')\n",
    "print(\"Approximate misdiagnoses by BMI:\", len(f_neg_low_bmi)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a8f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Normal HbA1c: 4% to 5.6%\")\n",
    "print(\"Evaluated Range HbA1c_level: \", Final_Outcome['HbA1c_level'].min(), \"to\", Final_Outcome['HbA1c_level'].max())\n",
    "print(\"False Negative Range HbA1c_level: \", f_neg_df['HbA1c_level'].min(), \"to\", f_neg_df['HbA1c_level'].max(), \"\\n\")\n",
    "\n",
    "f_neg_low_hba1c_hi_glucose = f_neg_df.loc[(f_neg_df['HbA1c_level'] <= 5.7)\n",
    "                                 & (f_neg_df['blood_glucose_level'] > 99)]\n",
    "print(len(f_neg_low_hba1c_hi_glucose))\n",
    "#f_neg_low_hba1c_hi_glucose\n",
    "\n",
    "plt.hist(f_neg_df['HbA1c_level'], bins='auto')\n",
    "\n",
    "print(\"Approximate misdiagnoses by HbA1c_level:\", len(f_neg_low_hba1c_hi_glucose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_neg_low_hba1c_hi_age = f_neg_df.loc[(f_neg_df['age'] > 70) \n",
    "                                      & (f_neg_df['HbA1c_level'] >= 5.7)\n",
    "                                          & (f_neg_df['bmi'] <= 30)]\n",
    "                                            \n",
    "#f_neg_low_hba1c_hi_age\n",
    "\n",
    "print(\"Evaluated Range Age: \", Final_Outcome['age'].min(), \"to\", Final_Outcome['age'].max())\n",
    "print(\"False Negative Range Age: \", f_neg_df['age'].min(), \"to\", f_neg_df['age'].max(), \"\\n\")\n",
    "plt.hist(f_neg_df['age'], bins='auto')\n",
    "\n",
    "print(\"Approximate misdiagnoses by age:\", len(f_neg_low_hba1c_hi_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e849b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "estims = best_estimator_opt.estimators_\n",
    "\n",
    "#Randomly choose 10 decision trees to display\n",
    "random_nums = random.sample(range(0, 99), 10)\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 5,figsize = (40,20))\n",
    "\n",
    "print(random_nums)\n",
    "for i in range(0, 5, 1):\n",
    "    tree.plot_tree(estims[random_nums[i]], feature_names=X.columns, filled=True, ax = axes[i])\n",
    "    \n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 5,figsize = (30,10))\n",
    "for i in range(5, 10, 1):\n",
    "    tree.plot_tree(estims[random_nums[i]], feature_names=X.columns, filled=True, ax = axes[i-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f5cec3",
   "metadata": {},
   "source": [
    "# ENSEMBLE COMBINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "15403cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.006278646656932495, 0.16759700877357084, 0.008638930420107082, 0.016033033564548316, 0.003405017473913943, 0.18415063360271172, 0.2728184429441194, 0.006962771760636179, 0.006123693118284519, 0.48728161845792484, 0.20684530032368642, 0.9985078830246867, 0.034717505113341415, 0.006376469068833351, 0.0320723740810818, 0.2699495878187513, 0.20273258510311343, 0.2840580463345571, 0.1790848717161975, 0.17743971696509517, 0.009805996788758905, 0.007733431365045661, 0.008062304649306297, 0.2535166820096887, 0.007276972884814927, 0.24292544002433025, 0.009745103981111187, 0.20072915256473706, 0.40564427214426474, 0.007853430715019033, 0.005286029634938766, 0.02148139145378317, 0.006094832343211966, 0.025970795342110633, 0.23942064048804085, 0.007400217814168647, 0.009266041885045003, 0.19489508522333066, 0.7411885075410787, 0.27528210770142636, 0.1753686072737126, 0.006066958430017064, 0.26212203146647994, 0.0049548680190249685, 0.17234575331529212, 0.017582146975521587, 0.9833429532215876, 0.2946510512159256, 0.1699314316538936, 0.007612972874560039, 0.00915972712830618, 0.22110086621023003, 0.3845881938556187, 0.9849857561665376, 0.2659157999681397, 0.00872649526298008, 0.006607541227727745, 0.25207234856571414, 0.9897285235343594, 0.2690404786913102, 0.004903510899926222, 0.005187000519414588, 0.01541203839799757, 0.008307916321050933, 0.19363033742100752, 0.2338846054545486, 0.41362609773217784, 0.005132770794934932, 0.0050426419419074405, 0.26239688088919383, 0.33295372190753014, 0.01054679250390884, 0.3096942849908676, 0.037432275509193, 0.2955620193528075, 0.981135672319984, 0.19775265057423141, 0.17176126623168578, 0.002791858413577729, 0.006290224972714755, 0.005902868646574904, 0.00957616119686085, 0.20764577840994278, 0.18353117439327443, 0.2560106516343026, 0.0051116523099417575, 0.008827326760886024, 0.32772830165306777, 0.019877794236646266, 0.008116037793512158, 0.011469556629705458, 0.006407717758960266, 0.01537774248911081, 0.18552919289154784, 0.27548088192758136, 0.24307782972211633, 0.18772694027166126, 0.2953990335743556, 0.006363281792626439, 0.0075958390780755895, 0.002799046768084547, 0.01630507144224015, 0.16750236829814427, 0.004076041737002854, 0.010862531974474393, 0.007783985503545986, 0.6176231443265758, 0.4558389834609219, 0.009545789871874323, 0.2720524001147396, 0.24235624058243793, 0.006622303891045719, 0.0049190981094845414, 0.004855881315446888, 0.014400391263111541, 0.35747954858774933, 0.010594419119529326, 0.18326027264770517, 0.005177381061550474, 0.007892772929289318, 0.4169122861124611, 0.00640156715636147, 0.15956685351855318, 0.006353803735300073, 0.02289788950351626, 0.22984920935758935, 0.24080492123712094, 0.008700589483169494, 0.3121249615520603, 0.007239192691288888, 0.007299303680523943, 0.2260209520141241, 0.16732257353539656, 0.008874079834942166, 0.19742767598442051, 0.20143947274966117, 0.21608918279834016, 0.005836855619568805, 0.2582295250581176, 0.9932874609164086, 0.1726399312965196, 0.00821644365024245, 0.9872402840218537, 0.012115927849757626, 0.4111617858795233, 0.009154123655868826, 0.18374529330894873, 0.008249361638188431, 0.006603134178124323, 0.00528137409894147, 0.00499141494202792, 0.24054182312657993, 0.3963312641401686, 0.2675937148232855, 0.16972761213321866, 0.010835574370489988, 0.006959273237450002, 0.006804535383686899, 0.005266213021907547, 0.29800764983796857, 0.25254431957991375, 0.004384263599409156, 0.020916238837268807, 0.19190462958634938, 0.004703510300852598, 0.004353611375937665, 0.011982757794383733, 0.40278452028898504, 0.006062602550534686, 0.018252634891079353, 0.004257368356269399, 0.9802510617534004, 0.1794106663712342, 0.2924701020101918, 0.18463163899106114, 0.9653623745701254, 0.005124080018525528, 0.004294793817357428, 0.0048716514382978575, 0.005365988901656578, 0.456489901390244, 0.3137900243459389, 0.010274701544972011, 0.008784475117894475, 0.1813318507765368, 0.1921289034735967, 0.17858484292991406, 0.006867504447922091, 0.7344001254062793, 0.25870044142696114, 0.00877033188753444, 0.33431004018213983, 0.004899513634895865, 0.007464972132171227, 0.004690260332117763, 0.1960462878470939, 0.00478783741089829, 0.2905887674915102, 0.0028079415760958147, 0.0045451595897140085, 0.3056521576296907, 0.011848089518610265, 0.4528520866639255, 0.006037040691024529, 0.236116970791445, 0.24782880708962768, 0.2337551279171892, 0.36791640139131054, 0.00535955098179397, 0.014130645827212704, 0.29476580520063583, 0.17200543903303078, 0.016527102822527805, 0.004737970162517423, 0.008632673944944887, 0.017956326473347356, 0.1720939238873973, 0.010090278673758129, 0.1721877489601735, 0.012719043502540517, 0.30071193690302955, 0.00940458580717295, 0.0030341373958648376, 0.26052082722473635, 0.020889461467424666, 0.005034012996954487, 0.211856556091058, 0.17546138004955436, 0.0066328149465027025, 0.2161246893424608, 0.2138745805999956, 0.006996052319547585, 0.01104308731089992, 0.9992753055531516, 0.25284587181024776, 0.005058810293705317, 0.20824114395099802, 0.19679664502954647, 0.3551150672687323, 0.9957372968413192, 0.0079225054643932, 0.00806589440496427, 0.20247448849183086, 0.005954486489213416, 0.4274004105474784, 0.019532522044963065, 0.0105725779583742, 0.20691343731179507, 0.004267151833433716, 0.005737008220511876, 0.006669663885330255, 0.009684214485140945, 0.010259716630130467, 0.25681201424564515, 0.007128955966306022, 0.004946745567040453, 0.013239373385070675, 0.17521621092281858, 0.2106875157981447, 0.014515613745509496, 0.004931939254071029, 0.23892949849567424, 0.9815295319060573, 0.009986462648217592, 0.007126874409786109, 0.004695518087047277, 0.00492980870238973, 0.1955804591005197, 0.00463804498978422, 0.008311583401828568, 0.006401854291361017, 0.17263697482715842, 0.23708125293301607, 0.198641514787491, 0.2348817985468763, 0.34040716168186536, 0.21643750104179243, 0.20405132280557245, 0.008889364067326926, 0.2187891455557308, 0.007208195080321482, 0.009156937618893987, 0.30152634259607003, 0.15000365356537848, 0.009008306390436493, 0.004434158372364249, 0.008136585036492944, 0.295370589916839, 0.005771350266004703, 0.008675682114398005, 0.23896028353424784, 0.00855643270537451, 0.007340393294449897, 0.18912303043811812, 0.007377674199355033, 0.2066967948260413, 0.5127721522059253, 0.35422930235257555, 0.007594676175866422, 0.9957253029865079, 0.22775110635552936, 0.17667359858934897, 0.00915212989548042, 0.16747656196824348, 0.6053896600024637, 0.007472203085956412, 0.17538986395240985, 0.39315951909568747, 0.02906928970159751, 0.2047633717210039, 0.00776307470378583, 0.008410563260788591, 0.006970420417038466, 0.008931617828924003, 0.23022802233001607, 0.006184330133760418, 0.006218869746728678, 0.006370402722602112, 0.012070936204056122, 0.1745658477912599, 0.2414336173915102, 0.004298404079267224, 0.004693701706998379, 0.005924187732673723, 0.012004797195159551, 0.2180911967920911, 0.28872040749405614, 0.20702717364134093, 0.005056180676927797, 0.9950518380995026, 0.25573464481916014, 0.19864271031483932, 0.18216042060344675, 0.1787304656105435, 0.8469034090554757, 0.010736829519400725, 0.0042535130006221234, 0.013284064599899205, 0.16533315290775988, 0.007443346106982741, 0.1932561063123788, 0.41804336460934366, 0.9307703635697366, 0.16963718231963576, 0.005052175139238262, 0.2254501202993624, 0.004821859726618444, 0.007466324683262127, 0.0025292823170291563, 0.18635540845831636, 0.02623226622099751, 0.2656802238592766, 0.24837014933886487, 0.024469386222348857, 0.010075366520368213, 0.008032753766220565, 0.198999347971892, 0.006614880928881602, 0.22507500024419122, 0.16476733876819183, 0.28526953507102926, 0.17867274240566483, 0.18338729479861654, 0.01089122352371036, 0.006279525072321529, 0.17669676419412178, 0.005380778900080691, 0.18632318155048566, 0.008904512075487144, 0.34724976474193336, 0.216847663671133, 0.18217923224781982, 0.9596862105188904, 0.28714040097782045, 0.007931108836766596, 0.19250834528321922, 0.3179954873749523, 0.979568624219687, 0.00631009321698768, 0.009815453247302625, 0.008724581930873124, 0.005260328931594033, 0.00425374724039562, 0.2715644322814059, 0.0252454807521985, 0.2801144319784289, 0.24961984088740818, 0.005306824691251788, 0.004245436976007121, 0.008917793127472588, 0.016858790940269288, 0.0071283258683378075, 0.16730714727360546, 0.9857772853361682, 0.3082821717198836, 0.00815901792639428, 0.2236358783796673, 0.0066805946552258655, 0.24029096723572774, 0.26427933095377854, 0.2924259472816242, 0.396011151477928, 0.010383601197831431, 0.017445693159631525, 0.0033366227459825587, 0.22441878301038892, 0.1762616459861301, 0.013274321764872022, 0.17980549235691548, 0.005708345547590206, 0.0038066821238015333, 0.1723470138634994, 0.17534815129060766, 0.189704518907444, 0.2904422904590555, 0.17919884219870938, 0.008427691266234393, 0.008269320926652522, 0.013305046054102413, 0.32248968297819, 0.0075369756810387345, 0.3957596652287281, 0.011392954551720055, 0.006416402301519128, 0.010381252403113892, 0.034407337639036036, 0.00667752804014483, 0.024465508540884574, 0.1863449454341666, 0.17622875551893669, 0.17040021995235582, 0.009876827785839752, 0.0044698037581905265, 0.055572776804344255, 0.18253626856964147, 0.7505075099889154, 0.49644739958312023, 0.009938849881624521, 0.0064028603698332905, 0.006561450967952408, 0.8155112345319628, 0.18862879530609888, 0.1598220661701324, 0.16710225393258202, 0.006957662534910395, 0.21463635619440233, 0.9968709784681136, 0.006894470025715149, 0.20424122803495792, 0.18652098432231073, 0.18826947498880128, 0.010098463162656808, 0.004971546733975409, 0.01825532100176807, 0.005764476882812813, 0.012519548571242699, 0.21793894832663596, 0.19317950779185022, 0.007031294176277457, 0.19486440198555702, 0.013713328019539364, 0.01008697094179047, 0.246253052754058, 0.0056271687001077045, 0.22620627851372005, 0.3583737850752252, 0.39950978703242174, 0.18899010566680802, 0.991772571824115, 0.20805803933584482, 0.004094341395850985, 0.22424339536444768, 0.2263815736985368, 0.3676268851317097, 0.006635163181878572, 0.20700610869553776, 0.1625629773087194, 0.2728779402011177, 0.44717349796086253, 0.01331804247871455, 0.9976083524257904, 0.005081124036148316, 0.9826573819449373, 0.26775722597383483, 0.00981209936874364, 0.17767333536848062, 0.011731057539902367, 0.30959234917678136, 0.006630700620080576, 0.0055906949116593845, 0.007583716661926954, 0.00556584300560012, 0.18604991119863873, 0.2574187059603448, 0.962152748404355, 0.2598354515303068, 0.3812475903733362, 0.19615191429041196, 0.4861997075275625, 0.0091326138432396, 0.0027680338960697428, 0.3515001850790932, 0.008457416571139314, 0.011832487455775332, 0.6189158268400837, 0.01410746272116035, 0.0035211764770872213, 0.1769809623347555, 0.06216576491196171, 0.220156478161661, 0.006559989391219324, 0.43966533004197217, 0.009143141105483575, 0.1784437074545184, 0.0027773516876664003, 0.5827758544241628, 0.013122790000646742, 0.006860452573726145, 0.00466488173331969, 0.0172005189255947, 0.004228306056482506, 0.0070313734896531544, 0.011008495288085741, 0.05297227671679464, 0.0168512922724405, 0.010050573406053755, 0.013757950231361529, 0.27733601026257226, 0.9137050559357516, 0.2143894112097487, 0.004648325634420061, 0.20910268946861638, 0.007159754094798355, 0.3239731986189286, 0.3197735270150347, 0.17461027976106402, 0.007286980618672005, 0.01310657952042774, 0.22472843918926433, 0.20540188455819736, 0.9975437410996812, 0.005069345910821627, 0.009091370324609034, 0.008116999601270752, 0.4483662466428635, 0.2714263962037111, 0.22205935798665308, 0.9446546195894598, 0.010181515970075772, 0.006259734929572577, 0.2852051730035125, 0.19297471074924732, 0.9757424272312409, 0.011154275600103203, 0.2011501486354353, 0.0068443464457750396, 0.016978398166389682, 0.6020589896484738, 0.1731937496837763, 0.012959273996901414, 0.006764926598155524, 0.20773137487345528, 0.007573322167396994, 0.003894892216663045, 0.016636318560650048, 0.9963498565823308, 0.20875869814942236, 0.26401193892007707, 0.23096795364693679, 0.26602599602522753, 0.0025239676296118013, 0.008244251038193684, 0.27379326463974746, 0.0039623107385845634, 0.011529024162781717, 0.1757524095702281, 0.26589238676848087, 0.3726672705929147, 0.8094013653584222, 0.004954293701712294, 0.009481801836088464, 0.1782903234913167, 0.9944625685663118, 0.00847799705631387, 0.02803346516161821, 0.007260027855780867, 0.00685192601550074, 0.006886434729555843, 0.9834692574533437, 0.15896307739194548, 0.7876773941572657, 0.004640667489621237, 0.01364665724244196, 0.009860579749400383, 0.004199487101591132, 0.02039534178318534, 0.005122913392577566, 0.33241141714344397, 0.2892491282783452, 0.3153449051965741, 0.5003229209418402, 0.9595130025372247, 0.007268633796036753, 0.26486279945985386, 0.01407663139212687, 0.6500936816201076, 0.17378303534119782, 0.0069038949303722175, 0.012819234842068128, 0.981543312121927, 0.29056910671402425, 0.2044835831875874, 0.32703352213461595, 0.010112625735685082, 0.2459046853397555, 0.17263278675199242, 0.2514014335326569, 0.213635912434258, 0.012598944366962236, 0.7059801832026962, 0.012031076637092025, 0.005164431671386962, 0.003997895256236437, 0.3473904122625935, 0.17634145285865135, 0.005773743045133428, 0.9914624339167908, 0.9954904897415648, 0.012960355453229308, 0.011958073133242816, 0.2592447060557803, 0.2690089314664198, 0.17392321018437018, 0.00582539508288261, 0.006236729380420329, 0.1742426010925191, 0.1853705280196548, 0.246374536785414, 0.336047680386604, 0.17854720633503562, 0.2925524310517592, 0.2798071563627932, 0.003859181801324401, 0.4204099075583826, 0.1825641784275983, 0.25816095562092933, 0.007077203035354012, 0.008362193657166105, 0.011199757009595801, 0.2588874260977956, 0.28102908363048795, 0.004273124998656296, 0.004658060512569338, 0.17161015668209334, 0.9485973848155718, 0.013991821794843987, 0.1804175549966954, 0.1876623627634827, 0.18236745505769925, 0.009409489742573739, 0.2365911515518485, 0.004060060264678468, 0.18220815818468103, 0.17653520884627255, 0.2049278968602466, 0.004618658269123449, 0.006383141941335378, 0.006299502084570894, 0.20739527161966234, 0.24660917825614476, 0.3629882059394176, 0.1651911327835803, 0.329318097970951, 0.00945269423604405, 0.17478215251378754, 0.013176600652085445, 0.01652876385143926, 0.2717311806187429, 0.06288699871043926, 0.9967880546192089, 0.8014702305858445, 0.7424703858902906, 0.8883895619211635, 0.17416623703636752, 0.012191534294225478, 0.2175862349417227, 0.9540643058381282, 0.18390997012582244, 0.2126812202820333, 0.17036651303858755, 0.019369788043934542, 0.9827282794178969, 0.20951419245454822, 0.0078055546986615055, 0.17166779301231647, 0.1764277307260068, 0.17979248721180113, 0.19576361954731297, 0.15026562454453984, 0.005884733668246211, 0.009820255562852776, 0.005364855063062386, 0.004064582837092416, 0.4828078844040894, 0.008632085777754858, 0.004971915115926682, 0.005351148100419528, 0.004776748750546421, 0.30366139310580986, 0.004839676873254561, 0.21534033230660962, 0.006018731389120507, 0.003822418895733116, 0.2079362765922117, 0.022939221960656276, 0.022445319762466078, 0.0051985203859382404, 0.005468206479351627, 0.25103522318546034, 0.006965793629633587, 0.15547695028061576, 0.007299466697125319, 0.0071853810445418765, 0.2775395823329665, 0.994102292514881, 0.16969075392390803, 0.2086153791692449, 0.013628794039957818, 0.17224047859688993, 0.17450298583746085, 0.008687705359211225, 0.21041054198071585, 0.25425045201190777, 0.010200406424627355, 0.1922976051031608, 0.007504631754601314, 0.007708160822028204, 0.005569717183394399, 0.007591065782822588, 0.2533050581452216, 0.005602957549008046, 0.18188188646962541, 0.25646251916555696, 0.20670958739138537, 0.5821840074754454, 0.007243037201006025, 0.2056083493789585, 0.007090143186893659, 0.008993854463132863, 0.2133321810446224, 0.18312012575545378, 0.24160525458066273, 0.007743327310429876, 0.205342866730767, 0.007006273247916309, 0.19000281243343733, 0.005604825237104102, 0.008537624591577095, 0.007159527791123721, 0.005316715120139728, 0.4023430602308336, 0.0219240275934701, 0.37176909455133056, 0.3131561007618816, 0.006925579508068282, 0.02457597483435471, 0.2843830943645315, 0.26569180530579506, 0.21709454577266674, 0.2639825426698139, 0.2647678133928135, 0.2804475332481596, 0.1835544596499584, 0.29998326833220196, 0.3429995764750402, 0.014370594479426096, 0.3735265663854778, 0.17516316175734983, 0.998905690589323, 0.011723962650283203, 0.006680103725963946, 0.9924963151056516, 0.9846823477778166, 0.007109548473725185, 0.008548737777425175, 0.2812811755559309, 0.007882321080997623, 0.006598857515396231, 0.019069569238416358, 0.0049805536696448304, 0.18585688355260288, 0.021208680459938675, 0.0026837340691815525, 0.20449476336585462, 0.32085492534955395, 0.1779281018564821, 0.009023519207122015, 0.006642983802322307, 0.1809258815686108, 0.005357248604790651, 0.1926214344405771, 0.012198809057150014, 0.004865378537190513, 0.24925517761466337, 0.19062522919979522, 0.005310011904692879, 0.34070864373727894, 0.005180203550158427, 0.1794402566991264, 0.007924453057104375, 0.007865448621354592, 0.15145944974483, 0.19088343104883318, 0.004936897291923247, 0.005273100298371803, 0.2057934965951273, 0.006665679798217424, 0.22912174589579853, 0.294670749308933, 0.16204081625815606, 0.2055714211722579, 0.30076873755851574, 0.00793236923283355, 0.007081219464476799, 0.27020259248318446, 0.00819009906868084, 0.03525108144070277, 0.4031817383107944, 0.010116757256744446, 0.007576805964271085, 0.17507095643410464, 0.19739439258857885, 0.007001671376009484, 0.006907141234562315, 0.023545292311408093, 0.016843131266681504, 0.33711449306718694, 0.015793158692755167, 0.011094915343410991, 0.009788494325044193, 0.006967328840401758, 0.9729456969326047, 0.005432207775657746, 0.0050379666089481155, 0.18474801414024666, 0.008517302176874499, 0.009464213618457104, 0.28317999984079445, 0.004683460356013468, 0.2721868773506298, 0.33594386114130387, 0.018176213601313714, 0.47416416478600276, 0.008675552310042899, 0.16714340442119066, 0.006542846142168191, 0.6041185558657316, 0.015520516080302494, 0.006401151832017143, 0.0045985417267925075, 0.01249856825970403, 0.9689784923299376, 0.34968945707158394, 0.011302642212402814, 0.20702393648235445, 0.008084061891015038, 0.2153027086704607, 0.21682846403286046, 0.003528791304380459, 0.006293821444300413, 0.005795863760326132, 0.1731185914655634, 0.004968199541480715, 0.0042857662653758505, 0.21658591129232213, 0.007026933701940435, 0.009767737480120187, 0.2138273159013903, 0.0369262757462055, 0.19133601743524165, 0.013170323029443291, 0.017602770685109768, 0.006728081009645318, 0.004629044110935157, 0.18050116522517554, 0.21585202846308188, 0.007879295021632276, 0.0038478868819823587, 0.006049634560151913, 0.17901613011651074, 0.015065701887251617, 0.007828485216750988, 0.005769635018661914, 0.00827250800837266, 0.42785623905960124, 0.18307563700928844, 0.18193290224238248, 0.00727109749472806, 0.17291548280931854, 0.33160911750341326, 0.008610511913924824, 0.2266679837250249, 0.00901549382908823, 0.1850080948913128, 0.0063666344825011245, 0.006558845812374852, 0.23830931122059804, 0.21837436804561483, 0.9637235952489149, 0.17885183543060248, 0.24366667397936845, 0.004160359352065449, 0.0052708161567393925, 0.3116638078034642, 0.003915940525656737, 0.005361116376582296, 0.012857810414110028, 0.014994646685301703, 0.019837362196809982, 0.004439448979502517, 0.9884875328174845, 0.003129372951609698, 0.004100541829741545, 0.1813967700893669, 0.27515489841373897, 0.2690811959459986, 0.1733196809942008, 0.2485322472726232, 0.1585492212385649, 0.011442228492759032, 0.010001424868387444, 0.30311839109504435, 0.006431158191333667, 0.0049122091388469355, 0.010414376012683666, 0.21546111249653166, 0.2573586519821051, 0.004195240626623505, 0.20072152808454236, 0.007016791487874181, 0.998350870776421, 0.23488020149026262, 0.9872178651425292, 0.00527716191943023, 0.9980201180974311, 0.19875509921195034, 0.9309005859057222, 0.0053294937079468325, 0.2971977517528601, 0.1721773362284117, 0.5326960789476325, 0.007370093501058107, 0.1803581671523055, 0.010095726574820517, 0.008343430775128462, 0.011712072021579254, 0.015062120745743122, 0.1761320854922044, 0.026577365792139186, 0.0073237061881987866, 0.19095283764282536, 0.9924349333409774, 0.18313830691353564, 0.00715733007282548, 0.00629833143878227, 0.19115188535866923, 0.3761639782755043, 0.005669607989992061, 0.006675097499570763, 0.005761747440732797, 0.0068436025535871265, 0.20526290212839937, 0.009230815327154902, 0.18369443215208148, 0.011360600946391804, 0.1651107474643445, 0.004947292006882632, 0.005557094927029855, 0.016083948102211778, 0.005936022237021456, 0.022705776648871204, 0.017326190178769324, 0.004949397624267006, 0.008183333454310571, 0.008567880482093547, 0.012594938876911248, 0.3281296196378447, 0.017163602157765464, 0.24936241736261208, 0.007982155336411676, 0.01423886173648076, 0.007192992064915298, 0.005082457952683383, 0.2564565477210944, 0.2474626328112534, 0.1765666908160161, 0.2968704896558768, 0.16717804111309922, 0.48243108317699135, 0.35428043668827136, 0.21228265551594921, 0.004198170576613396, 0.16988150733923335, 0.5366806972551126, 0.21007460147828516, 0.2629410281873759, 0.9982608889460554, 0.009435311595327628, 0.26285489212105534, 0.9147446894322901, 0.00541980941661759, 0.02204632142022267, 0.23264785432146842, 0.17808375320332342, 0.0035839717832265553, 0.20964922592974175, 0.011913212545728254, 0.2913299851674951, 0.00543104609996925, 0.01592585330445934, 0.49262762036267527, 0.012012693873784614, 0.2144975629423017, 0.011444310913374736, 0.8204071272829514, 0.01764996083789236, 0.006152911204960209, 0.22604231158607507, 0.009233666799282173, 0.17243098816770536, 0.15268416701840593, 0.20670092282392494, 0.02011932813437635, 0.1776292484472614, 0.0042118015499607794, 0.1673738456921689, 0.005933288467386662, 0.00498460685179262, 0.257518951837169, 0.34175992187579385, 0.018537846014897563, 0.34618571302614776, 0.006515431868698419, 0.32555449385599255, 0.005035893230211715, 0.4251049954938837, 0.24006310618199259, 0.009354411975298953, 0.29685878341484195, 0.204694262530346, 0.006572492186341279, 0.025985524151102196, 0.006610425694581983, 0.3286376646556748, 0.35883081327140137, 0.23169015455407227, 0.013070147371710332, 0.016002387477918732, 0.008255254827152243, 0.006325845519019047, 0.971408314839086, 0.1682920033416754, 0.22997908094252234, 0.008798423945905283, 0.20394734886552907, 0.010549079465338701, 0.0051530086334854825, 0.35149044063804796, 0.22512020223791712, 0.010208720947589667, 0.0037025714941943725, 0.19426511199629737, 0.18128565506133176, 0.16823214309040413, 0.17571689256627676, 0.009332912984834326, 0.011219983975106526, 0.40604653720083167, 0.26133080574064493, 0.004737218224155964, 0.017169771622723387, 0.266195104735897, 0.5139112769660562, 0.21348312108092476, 0.006692478238018413, 0.015544180308409993, 0.18134017057700455, 0.007357981911222647, 0.17820194178554874, 0.005610600497551158, 0.004290990755664589, 0.016910314974375746, 0.006773466544303473, 0.2858492939513693, 0.2548624995754683, 0.2208556586582794, 0.3076529357304245, 0.007326510233621779, 0.008299315459472129, 0.9811946982144761, 0.0045594530541024384, 0.02187780330510397, 0.3125215341760781, 0.010033310363257017, 0.007387441897401337, 0.004315037376131674, 0.00547147937085967, 0.9250620629713866, 0.008932879655115177, 0.004979136527724261, 0.0074751908205075305, 0.17021551593803724, 0.254048187431126, 0.005770769704146288, 0.9969128960975175, 0.007121696304006116, 0.007328005885415435, 0.013560452490076046, 0.009018033987930323, 0.25056616720557734, 0.01089045514897581, 0.19983011512582272, 0.008018403036842472, 0.17301454846534564, 0.20202045962121018, 0.007848800882177919, 0.005673789765582983, 0.9803169202752671, 0.19669586079771922, 0.28516346578457324, 0.005652567402164554, 0.004547920998928884, 0.029768978222401578, 0.24092463378599346, 0.017635175780206822, 0.007503318705592541, 0.3386855352687197, 0.205010588289268, 0.3039365060733646, 0.29041130825100236, 0.005664730697510419, 0.010795478152287803, 0.00917358412716137, 0.2664925975381887, 0.008620369663548282, 0.013861843924323354, 0.20941690643530192, 0.013783543633244058, 0.3469986823330063, 0.992070540661969, 0.00761293750747454, 0.1599335436676848, 0.2416952149097087, 0.006428902929252088, 0.009001231561765625, 0.006954943113191378, 0.010675484659085764, 0.005279226742144702, 0.1696814002888197, 0.020443024006782513, 0.0066586708313969845, 0.008504814074174296, 0.2240143574748822, 0.003946929075545257, 0.006110260663394139, 0.0075212898223250505, 0.9965672497949702, 0.15432706401099971, 0.2863758493476063, 0.014009473701044325, 0.010568964913360153, 0.006675280665177726, 0.0041647574799134725, 0.010427484035477679, 0.008291098415376641, 0.2142614792937199, 0.007014543635138459, 0.007320010864870131, 0.006959258771483086, 0.20417362784360688, 0.18381279518303972, 0.006206461952332587, 0.0048008282928597565, 0.3759179780029107, 0.009330192609610152, 0.01723879704410402, 0.0087044162638757, 0.9892847701998995, 0.006563237069167375, 0.02471341755019362, 0.17668627544226415, 0.007725419816633587, 0.32961680442231256, 0.1825780958957066, 0.17674567887155487, 0.01715940449690566, 0.16869117710483228, 0.9993132479796685, 0.3660345833829209, 0.17274491794170052, 0.04974681795003404, 0.17518317405381478, 0.0025924302192695636, 0.42846851112139783, 0.010075967477979154, 0.9932585065427397, 0.002613075102060849, 0.02132461071135172, 0.00539320626125222, 0.018874788986647014, 0.9923749125973524, 0.0072659588695321905, 0.006459167596850461, 0.1846965429231847, 0.9765799307021681, 0.017388095044431576, 0.012438308356081514, 0.2566074754556663, 0.2808175418426313, 0.00877645847215856, 0.20269520624529153, 0.5195010052917235, 0.017712030218655896, 0.011567230629326297, 0.1925933174342635, 0.004919730184174593, 0.007937666583038, 0.2627039899439614, 0.19343854316998, 0.6042675370074992, 0.007045235373052456, 0.006576432068615926, 0.0063798941172498545, 0.4076336364272144, 0.005760618725998184, 0.9383348655105843, 0.20862020744811827, 0.010432653477578893, 0.012400482192554586, 0.35301319734651193, 0.008043737323343373, 0.010564178987316968, 0.26561488376275644, 0.0068550950920943775, 0.19975911784201178, 0.005592543554332125, 0.013069551780905266, 0.34404681300427564, 0.2758957408740613, 0.0048933378708136965, 0.017839234759724272, 0.18650080465815982, 0.3493297178935536, 0.027138610404618586, 0.003879836044957555, 0.004153453892900693, 0.5099714996759124, 0.008023484020662849, 0.2461008516805969, 0.00807260215129829, 0.2136167463521919, 0.007721211410185206, 0.5956563319173176, 0.01673154291916902, 0.008619914028833551, 0.34711160017321996, 0.22831459558243478, 0.18320208112225328, 0.2972955413486764, 0.0061775391791636545, 0.24313762729711394, 0.002550708005748948, 0.23629576570749028, 0.19783508804793956, 0.012776216292130821, 0.0058983881721671235, 0.294027949629624, 0.9968827527227286, 0.005531821640732426, 0.017284192652045095, 0.1705810067832243, 0.009493671487530933, 0.4442357588184214, 0.006700655047412905, 0.17262843839875072, 0.30327465498151107, 0.015137437347510975, 0.0038012171281221357, 0.014911603089162886, 0.9862916672581528, 0.3147382956312788, 0.007417635307132542, 0.0053461851265398826, 0.17712744303835393, 0.00639433896846236, 0.16910456894715212, 0.006372587734191981, 0.2955824795631914, 0.008070240025648516, 0.010986135987441591, 0.21300465189496992, 0.20711569921187017, 0.004753067176590852, 0.005213472992121931, 0.17697132346245245, 0.25770894997249894, 0.005208588252488956, 0.18509194692419806, 0.540077564126688, 0.7783869096838602, 0.003681603849461579, 0.16772238401268452, 0.009844856545371327, 0.01573152804160351, 0.0049729379723277905, 0.007990218041884625, 0.005061753952398089, 0.008045971074737836, 0.18380957449337446, 0.9987797198961843, 0.0036322372540460992, 0.017233098109151686, 0.3917961564683164, 0.005867497443421502, 0.004580724205906673, 0.7062983489100886, 0.01881537047089478, 0.25303621201671, 0.014465389327790701, 0.20654539202890965, 0.24331618345313727, 0.943336830219504, 0.19624573849009308, 0.2303211014780566, 0.006443741962420743, 0.006583838396563088, 0.005363519128888733, 0.26487529395980425, 0.02011266639142073, 0.008399108707289238, 0.0051063098687694555, 0.378855657313315, 0.004087293342397037, 0.0025195296674678405, 0.005114948738798403, 0.0066114507115774684, 0.18162420907724863, 0.26777337325109074, 0.00896426729213515, 0.9653581704329037, 0.004111192459723388, 0.19923700958556195, 0.007844806571516755, 0.23204487714310645, 0.011318526053431352, 0.23775841690413202, 0.007386368876644224, 0.009582758610738026, 0.006506986583634072, 0.006050973336952086, 0.009901617797540294, 0.22226137824717562, 0.2551982060783465, 0.6541718235138314, 0.008561044609415716, 0.9990221054685042, 0.02870799499527811, 0.00937761687600845, 0.005235411415579515, 0.16074995006973763, 0.17738709374346834, 0.005514589955359734, 0.0076294714537428225, 0.370268321069678, 0.006125286024948011, 0.019998446686707572, 0.013505270906658413, 0.1744646486401062, 0.31851466278143786, 0.011552157336830545, 0.44309328149793553, 0.27153016387517925, 0.008294363343184879, 0.998337433299481, 0.1879258226949873, 0.015121476072803196, 0.20738201931444278, 0.27262614507900923, 0.4004338643763213, 0.010833792725319803, 0.40295538074456355, 0.007878132302694964, 0.008002265957787552, 0.29185899189403486, 0.19850147515147198, 0.006547016891747637, 0.0049118084660042275, 0.18192118929637194, 0.014457104258632317, 0.4400164324327223, 0.006848474237281041, 0.3658732930916656, 0.21036626313626816, 0.014837022621283565, 0.008865520417686863, 0.011344288413516207, 0.17255323377583234, 0.007762850853303299, 0.021125642310387147, 0.32324756772983687, 0.17635609762753438, 0.7358491008410735, 0.014934960777363159, 0.004005598496707481, 0.25160350288356215, 0.22332583849748544, 0.5288174218447914, 0.03364325938860354, 0.0050257201271798665, 0.017606577756533234, 0.007093930972861407, 0.998152360799802, 0.007558045111927431, 0.006520775403360271, 0.005819234497225637, 0.24290406183878366, 0.20065852426444594, 0.005700395454003198, 0.1942445229739662, 0.3484464184803393, 0.005860688756887756, 0.007096768623856536, 0.2726189724022684, 0.006263849900042105, 0.006994113854558535, 0.03842379360333145, 0.2946456274169459, 0.00898982769418777, 0.005031216031527098, 0.005751799476657469, 0.1856969339237365, 0.0026690575706116914, 0.33178828664525795, 0.2775141729002508, 0.28080844337658734, 0.3694822844429503, 0.36739748135614425, 0.22056577228695218, 0.9967783836137467, 0.1660499418282163, 0.02105533286030493, 0.012885936962051021, 0.4578116848549513, 0.006050419790294089, 0.00643747169463099, 0.8232886220465352, 0.21209089547901416, 0.008108773471052594, 0.20328992108465746, 0.2636145125695291, 0.45414106543012345, 0.003839251354312446, 0.004343385995691936, 0.24857790231033228, 0.2834848845831829, 0.1880294020868652, 0.276767748254668, 0.009575103299165144, 0.17564612166340016, 0.00655012642758138, 0.6764907505972384, 0.009986935818743293, 0.6823782011857586, 0.22577369457178736, 0.006711078903543574, 0.17815789266302484, 0.2806528083212427, 0.009014896808665098, 0.017757061135522608, 0.010097160674061623, 0.004901770252124519, 0.013319674922580798, 0.4201477730907187, 0.17607098040551156, 0.47925887828368535, 0.16825919860284771, 0.00827714238631843, 0.008916595560318371, 0.16383421822612693, 0.19254532514307773, 0.006505599107631694, 0.005877123785987401, 0.007391802725804757, 0.006712907128211407, 0.011767856806582043, 0.0057920317272105275, 0.006612429129319589, 0.3380859611127798, 0.21041006293945125, 0.3169536799744427, 0.2030604016956992, 0.25506056852618275, 0.5181801768174947, 0.004786146377413346, 0.004569825209398488, 0.3071307316399592, 0.0046513351655631295, 0.17853709987192007, 0.3092162348370995, 0.010336334387362821, 0.014420807503338549, 0.68325028835107, 0.2804971633669558, 0.007600657894120427, 0.007513309020422902, 0.007454250299589213, 0.005323792127141311, 0.0060605279390693505, 0.8674244742947905, 0.21449195013889472, 0.4126783800877249, 0.010410228648499718, 0.005476860962592765, 0.011670329699002446, 0.2952851173507658, 0.9608081407733817, 0.17962903890178894, 0.24757875831423043, 0.21040045526522838, 0.20319834081250154, 0.00743073572388587, 0.006682275727845316, 0.0047888911564136485, 0.007048613029206417, 0.17609767558478542, 0.27177107562716446, 0.16993394602744585, 0.21297631735696976, 0.003972759689052895, 0.2219704771372647, 0.014870043894332871, 0.2673323862471121, 0.27368546429254015, 0.16564464160316017, 0.24962669772572865, 0.17402361071191166, 0.196281519365557, 0.37873816368222935, 0.00745828554913846, 0.05943778268185937, 0.0085019997150867, 0.012267321859633255, 0.002954930084867178, 0.015278025053180721, 0.017449025458946433, 0.42088061106241903, 0.17430808870447967, 0.2668212842016541, 0.007318011038538003, 0.012465861248403027, 0.01252498635362953, 0.00519897630607462, 0.0071770610309711755, 0.008311398804338227, 0.005036342885632947, 0.028909509336531813, 0.020708651616117117, 0.02347153356133551, 0.0052978065729554265, 0.00814292453773343, 0.18641117516195024, 0.005149311075800066, 0.005493141924748901, 0.18557503652917143, 0.018625854885793512, 0.004886815988990624, 0.2605403920771149, 0.007351673086807792, 0.3322853915972381, 0.01397550588006504, 0.9831072321949987, 0.17939215183520663, 0.004274290768108268, 0.1807281475383058, 0.162262632470395, 0.37315592153538224, 0.16464680771035467, 0.005683637146331461, 0.2989877167733207, 0.00541625063312819, 0.21985402173795093, 0.005200950606309357, 0.004999691504056464, 0.006651810967122575, 0.025596345073392465, 0.3369623969213977, 0.9614180214744192, 0.007477025410435855, 0.006968220395041414, 0.005243607764572608, 0.21235703479304063, 0.2839763098218689, 0.33968986088078595, 0.0060895661796506306, 0.01007118954927312, 0.023931297748206192, 0.24416836820525034, 0.2139837548836826, 0.0067779455342298, 0.012240586601744628, 0.00421433362320407, 0.011321805262206655, 0.007445190583182777, 0.014844954283034242, 0.037442046772784315, 0.013455329564558928, 0.9572214459208448, 0.4119709431494993, 0.010124227535823002, 0.005153146020990244, 0.28752591769959635, 0.21996330363483574, 0.19767472795506136, 0.35156665502583795, 0.17087809424147943, 0.010842015233057318, 0.43549831789370114, 0.22548200223578693, 0.0032183910027611495, 0.004585789566005043, 0.005186910371877364, 0.004679759091656245, 0.004813327516358403, 0.012517489643708446, 0.2343054122547675, 0.018959872439307385, 0.9580681227351848, 0.18978916350401454, 0.3635973556352653, 0.01709288440139047, 0.012706748549262691, 0.21013205403411345, 0.005467954411016551, 0.049004926138088496, 0.0063531964974029385, 0.4715180143039177, 0.2576639410807646, 0.00758356619412148, 0.9986996630582465, 0.0226246080750397, 0.9941039708351369, 0.17684082365137382, 0.19838786443718595, 0.9174369621396756, 0.005034547395862834, 0.005855744102007229, 0.01186796231202609, 0.006737008346003219, 0.20302637294941595, 0.008533692256631573, 0.24789510181982455, 0.011923592670802242, 0.3407656791974447, 0.0028025813323413295, 0.1743252616595104, 0.50146717883533, 0.00370250022392842, 0.22294534617543138, 0.272553921366297, 0.3163194623185265, 0.1656431001092874, 0.19559452519419135, 0.010377739676141794, 0.5652454904165005, 0.23550742698568972, 0.005271584885033867, 0.9420264771235118, 0.013350828638238981, 0.004403840354470202, 0.35276794886745644, 0.9937870172854422, 0.005645506747751484, 0.010283556312129039, 0.005633171926566566, 0.38208631648908964, 0.003566979173393554, 0.013794353205306654, 0.21612197115734955, 0.32689810081481374, 0.263408671661328, 0.004556703688993188, 0.23186628577152635, 0.2265253102813375, 0.00510077370351957, 0.005178165967215133, 0.17919371193305164, 0.01356553716820932, 0.168665255130821, 0.007360573010107837, 0.3778973052511482, 0.9966336934936688, 0.008643831831564412, 0.22256746354852988, 0.6419763991826632, 0.1888177257129854, 0.0030954396226567367, 0.7538017940626518, 0.2027912838247688, 0.011245789800287995, 0.005260576483864774, 0.19957969467455716, 0.8294413285188789, 0.012385736131896648, 0.20617364805205463, 0.005612007303005046, 0.004184441322694201, 0.006047084942224053, 0.004963655506774601, 0.22884477946929516, 0.8306596853199757, 0.00920851247639183, 0.3490213781156788, 0.30025655431466747, 0.006966266023906249, 0.28214158923819854, 0.007816072661049224, 0.005698245093976773, 0.00830530675474966, 0.16523846747868257, 0.015859850391026387, 0.17195073943787453, 0.007964758578626177, 0.9674071354990432, 0.006306863689870366, 0.41547960693001385, 0.006035756640019138, 0.2955629048227936, 0.19527575034384786, 0.005898264750872835, 0.3818941264446063, 0.016786781036571313, 0.006060562693689727, 0.024404576267341105, 0.22786009341241453, 0.00734669929349067, 0.19640390666503466, 0.00594739426633172, 0.02305352889987125, 0.015118150394238845, 0.00972976854474998, 0.006857870674372105, 0.003598040421237389, 0.24227083401643146, 0.2322474896479758, 0.017085227442605374, 0.18424121193231546, 0.22813843765589448, 0.2899714382272006, 0.23044592208212888, 0.004730695876609261, 0.3270772659212585, 0.0207019255929526, 0.007563742476936172, 0.007418039256520013, 0.006831032032372213, 0.004798150270825668, 0.1687941601212816, 0.0056555867222522265, 0.27298342289556776, 0.3487910955068793, 0.012205388250331423, 0.1679738541936953, 0.2133974428246681, 0.017553255374150374, 0.007106306058264363, 0.18129007390867452, 0.23572731917578696, 0.005426674109720452, 0.0056852587986516686, 0.43800284731407546, 0.1770712839724466, 0.17234173927393742, 0.004449034293964125, 0.00737979269718021, 0.17975665750420874, 0.24276089077557786, 0.8652150060478436, 0.007648981276919899, 0.25231818162234976, 0.007372303320939105, 0.013688726200008303, 0.008492147284325248, 0.17807587465391753, 0.00587949028045418, 0.006253782945160822, 0.31686461170142544, 0.19989466017182175, 0.00977231104504976, 0.006970605979202365, 0.010754790792679818, 0.007461209093138507, 0.23055747053000647, 0.21030423170051818, 0.006264180852084862, 0.012632398784055197, 0.005056686019146208, 0.005948698852553176, 0.25340537172571825, 0.005285719177005893, 0.0176417099000012, 0.005587876209145734, 0.006327443417381951, 0.8545810148560955, 0.01469358561813671, 0.006242698134311753, 0.576115049334047, 0.010296322683992526, 0.006535738141432646, 0.0072552347870748195, 0.007451584088768757, 0.2103872756694684, 0.1760592875156909, 0.004574787218123495, 0.0090528144098223, 0.0028138034563399443, 0.0055969095834365774, 0.004003342209923261, 0.22099711637085048, 0.9741759692407308, 0.007714500031806112, 0.008452677985693035, 0.00562864046904142, 0.21909232682887014, 0.00772993359539331, 0.004951738878365611, 0.33330478107737094, 0.005568243403303644, 0.0037537410421334574, 0.013579301697948796, 0.20644835251006535, 0.9638965466483476, 0.01988165731586027, 0.006345599709192988, 0.3174016172179579, 0.006439415647603, 0.006720303473226421, 0.43406810211130076, 0.003463928246324374, 0.005951794183081815, 0.19833302038098113, 0.005853327855649948, 0.0044954193327684695, 0.19883043421603808, 0.27220772255281955, 0.9941376947516725, 0.006570716367415352, 0.007151827411531161, 0.2837019133985512, 0.004974628553497536, 0.005783507389272681, 0.007616802423163027, 0.011535632641584418, 0.006539216204521707, 0.016687407685996233, 0.17395526725369057, 0.2152322415559643, 0.17061525613246548, 0.19646451484878003, 0.008293878516918238, 0.18012776737149058, 0.0047251955123890224, 0.1712778996830322, 0.00829204619151342, 0.9936010997185729, 0.23555270952644647, 0.3721599190200159, 0.21565681947638599, 0.0058718404547097106, 0.21953895090897257, 0.004788870943262039, 0.1803593939560419, 0.23826371864589158, 0.0038703152954925432, 0.47150942478517605, 0.8757258687258875, 0.26334920370589465, 0.16310151905986553, 0.006325581013531274, 0.2727499508614256, 0.3164651967460732, 0.010228359491927888, 0.011686893596003549, 0.009932332420356224, 0.25847006486162916, 0.2725340776516818, 0.17661716612774486, 0.20400610953784254, 0.02568280274669972, 0.2171661381081551, 0.21069950464371298, 0.013982252567085653, 0.38094082889572206, 0.27653089039639855, 0.20583634822433897, 0.009160103009537995, 0.9952833543771582, 0.005363442609549117, 0.23986971329210732, 0.009053967023772572, 0.38766085466960976, 0.0047859657401909715, 0.013711835505408373, 0.2962248665843771, 0.2343297550197783, 0.17760863975723282, 0.17340592642540698, 0.007245092531308509, 0.202368979193906, 0.9973867635362754, 0.005668325638750755, 0.01388653241115562, 0.006851874030076351, 0.010623922767988838, 0.2547630355497327, 0.009633449980651182, 0.8632659025575842, 0.005078651708153461, 0.9447301403249928, 0.8135596578751116, 0.007400731136147893, 0.1775354640811069, 0.1922058038706488, 0.004645737654747875, 0.16120639397312692, 0.21656011052676155, 0.01039526835700359, 0.22630503731789892, 0.006580196314994345, 0.006651476307930753, 0.17308395509493346, 0.005094384012974111, 0.1882140054179063, 0.005734644226068874, 0.16987310569445407, 0.006206822751999216, 0.007785574544959953, 0.29229746576122684, 0.004783276755137009, 0.009764388795965693, 0.22813935222993853, 0.1927212495249448, 0.009116732653722577, 0.004918437054701894, 0.20174401989091528, 0.25469190141225273, 0.19542397544664053, 0.21475272951870183, 0.011072398038291614, 0.26834140815052765, 0.24860897756263423, 0.005155939990993616, 0.44258848895491115, 0.009576141158296534, 0.013217320261795486, 0.18369252665646538, 0.011689489175583875, 0.1944554489127932, 0.014542760497595269, 0.20178911235543995, 0.006743150743422239, 0.009457833229544866, 0.007015799219204128, 0.9237380197207121, 0.01668313342370887, 0.2639324641054055, 0.6641581432491321, 0.9557373718614754, 0.23968253549585747, 0.3086884725620723, 0.005292863551019769, 0.24185605038915292, 0.4245135005631878, 0.037926368433108516, 0.01591734232276948, 0.5600271786710637, 0.006481457870219456, 0.20827930161793126, 0.3146580622086045, 0.24852414095513806, 0.006096278524940284, 0.27888339737014894, 0.006151747758350992, 0.009372462648927183, 0.15292275508116573, 0.007609667165475213, 0.0069004810984635645, 0.19855122134816738, 0.34827554459234056, 0.010263007151738984, 0.008497869582338396, 0.26691876053256414, 0.004214402274532031, 0.2137759303027538, 0.1751036299599045, 0.24978167105064647, 0.18197230164524447, 0.011391766504212236, 0.0073532042917663675, 0.008505047410707872, 0.004306851197483126, 0.005952944008741989, 0.005461526465486756, 0.0067544019914118954, 0.3229275582010967, 0.0073348895829664085, 0.005153844151441177, 0.9515345056707534, 0.3211664888763057, 0.004272363746911741, 0.2971252552018975, 0.00839986020063922, 0.009986973220027421, 0.25604621609126565, 0.010287469397827513, 0.3473106545392502, 0.012713255702975922, 0.17541711952914174, 0.25012118640289177, 0.30892219625586753, 0.9951213191289705, 0.005122402315160685, 0.22290971405932536, 0.31765472328309646, 0.02181362497776297, 0.0049173292318831, 0.00723573684252126, 0.007557833017382355, 0.016645763847520867, 0.005341815772748169, 0.006502526156206645, 0.2713499176183778, 0.005497529919874044, 0.005298368739682531, 0.17273535985046978, 0.007993104631631356, 0.2883386618223368, 0.19240021513128988, 0.2187556435445973, 0.1827973885487591, 0.21500013045292934, 0.7394973946300867, 0.006127787064992939, 0.20615330594313241, 0.009393947407340243, 0.00809186591223518, 0.008134285653970834, 0.17643223270432373, 0.17901435659055126, 0.005298750580692016, 0.026018621465940923, 0.24696164400864373, 0.0025062178883018026, 0.2924036581387438, 0.37054457900324633, 0.2777599317057754, 0.21966878976832216, 0.2324992730907767, 0.005433651216858592, 0.29777005706250387, 0.006399857175101293, 0.9657562841949874, 0.00600394730163541, 0.20657779565743303, 0.004404377975638807, 0.24191874531181767, 0.20837404458317457, 0.16921774278329585, 0.3402951360889577, 0.006632627344487272, 0.29397269906847195, 0.006400282822340893, 0.033145965175051875, 0.22662595850059347, 0.011722262589459763, 0.3601015505784581, 0.0182304973032919, 0.011638604854807486, 0.2722645402367986, 0.005406582483737352, 0.06002253979654634, 0.004279816115807179, 0.3045303218347614, 0.7869996696034209, 0.008850182305079644, 0.009041072808389885, 0.18051110305665152, 0.006945383417509032, 0.004911873768099033, 0.006076740324343426, 0.012881541637358595, 0.019990262888462024, 0.17220809206302568, 0.010770618967205905, 0.008202659785578725, 0.20865709009940753, 0.2712756096771434, 0.024189334651553818, 0.00668469519909858, 0.29258986332380776, 0.9832223657421519, 0.23079886764318852, 0.0069159340584228155, 0.01539618270488528, 0.20186490213122188, 0.019476599568093354, 0.006579771877556167, 0.005965051595319206, 0.2942640375015132, 0.29406060827202596, 0.004111600652323945, 0.005340979251648532, 0.19910839867095964, 0.6727499058620481, 0.006602345397605461, 0.449532018519326, 0.2795040801640815, 0.004850651982978625, 0.011142332003662764, 0.01122976321377825, 0.36799532352435105, 0.010451911895987357, 0.21890061972253871, 0.20419266678324213, 0.8599949998384822, 0.2414618522766791, 0.008954826199575038, 0.3523318578270598, 0.9969223668947824, 0.00411303281270694, 0.0070473521265323625, 0.004107043447694527, 0.01176250478400002, 0.19034231635301305, 0.16964245775641992, 0.008920542687616417, 0.2938784807220169, 0.3061090575780034, 0.3554839909716949, 0.005728765889393067, 0.2620281898851684, 0.9883291380085237, 0.19478779293338072, 0.00568921118341634, 0.0026427219634165677, 0.006952987956281456, 0.226998055551407, 0.014745058735535516, 0.5930142914611427, 0.005184998079905658, 0.2847032857347068, 0.2339784145527895, 0.011412555372801746, 0.3091192761424463, 0.005946704988249968, 0.003905566903981753, 0.1949293543414257, 0.007193811683165314, 0.34288675177188627, 0.18151711283410135, 0.012636761355371562, 0.4244750447925606, 0.19095810360009768, 0.015751356440012392, 0.00906937979229307, 0.006803704738107837, 0.26657388273725774, 0.005433663848292937, 0.16396683441187437, 0.007660057529327447, 0.010889219405150755, 0.0054000687932093585, 0.1824685966938262, 0.01398537987485522, 0.17761932408760076, 0.004948289054389096, 0.01148691775402003, 0.17556318415380645, 0.02056450832743929, 0.17840501394115185, 0.006938045409081779, 0.1804472270865093, 0.022696672903399447, 0.2011050264279743, 0.3816912724242925, 0.009260389918609752, 0.29718104707861925, 0.016147288928620027, 0.17233647319926956, 0.010680245736908345, 0.17959347823605398, 0.3161713036410442, 0.9840172904532136, 0.25324273779239115, 0.9245107422639238, 0.3266087740090622, 0.004349897174597909, 0.010055006062924737, 0.4733499211735542, 0.2983498569964353, 0.1753965224564788, 0.005491258903399767, 0.014214657769381665, 0.00478787165713342, 0.009986341929700729, 0.2343991638741862, 0.005252350619065417, 0.9687117513707728, 0.2457203889368905, 0.013556622286541255, 0.4045624195077986, 0.0066372263025582644, 0.007268316445788254, 0.004927568780460578, 0.006673001154488489, 0.00518986768033003, 0.02049691858516386, 0.902156185392784, 0.28345208270487965, 0.8773972084604016, 0.18582408517340931, 0.21692043203898137, 0.22335478292026847, 0.24856813013291118, 0.004056961333293663, 0.007575774847361541, 0.23905430293910493, 0.34294030266864817, 0.28322996707103587, 0.007581299569407665, 0.21980191132552962, 0.0067895088305573005, 0.0041361841157514945, 0.01499840193179781, 0.17291708633472386, 0.18344911529179458, 0.0165885381425507, 0.17429774093506148, 0.1605416108228461, 0.9892181675943004, 0.015057840855149501, 0.34207398166537795, 0.004228264892842195, 0.004921332012551393, 0.009547548120780843, 0.004266966656984774, 0.1853361481140346, 0.20266682189275606, 0.007781385831313001, 0.00722261423619938, 0.3867402061937511, 0.007119443146122608, 0.007038939826523777, 0.23274169672893358, 0.9947944906823467, 0.1773249456924591, 0.010033862536130252, 0.007031150758325199, 0.00743774683394762, 0.3373932826542114, 0.005158190506180063, 0.27922692084327233, 0.005104993786866514, 0.010327667522260914, 0.010900177799751512, 0.24348608429213067, 0.007902690446355885, 0.0032932952411509216, 0.9991349918203778, 0.17256573482355386, 0.009715533634114192, 0.380452858034147, 0.18081760885957338, 0.17553901178730982, 0.24775788905623936, 0.008671762251135197, 0.1683404993702757, 0.19531082730441024, 0.0066242210382873425, 0.007062774203407673, 0.1973537139873698, 0.21069088932482072, 0.005363811747360274, 0.3298550224213001, 0.006214643853689353, 0.004980249238735884, 0.008819195070233, 0.3315203101354145, 0.22196029022653951, 0.1772229125132596, 0.006498210155434118, 0.20451034619843494, 0.00674978290127715, 0.004756495925517624, 0.038158260604186804, 0.007284044650690411, 0.0048245953634750306, 0.2547636219378243, 0.17634817503257483, 0.009671147185025581, 0.011151467829341446, 0.27450965050490544, 0.009655604381714884, 0.00973959304097738, 0.24493932628371676, 0.02144115303717032, 0.18588509567144193, 0.24761928086994334, 0.2510872228177207, 0.23939348608260386, 0.0031956049187905895, 0.006624719688523031, 0.01491118429545757, 0.0067559917284079245, 0.013648580186516079, 0.006459784404408922, 0.010357101552695704, 0.013685945231284989, 0.004751624028403401, 0.2452638402084126, 0.1704463538375612, 0.010610277551890823, 0.1795943607988983, 0.9879359958503444, 0.26165159931783544, 0.21901512028797535, 0.003329750404859628, 0.007768986400500499, 0.005989941747942912, 0.17110516238508178, 0.008887641548898815, 0.00852368494515363, 0.007835286519795554, 0.97917377063937, 0.015620324907875639, 0.2111444966352588, 0.006607778046940289, 0.007888527767325203, 0.24690867258743912, 0.006982465223974285, 0.24042069789171133, 0.012471766576889589, 0.2272209094566418, 0.009436663176458034, 0.006747134975710443, 0.9946744138302086, 0.010135706923242258, 0.007148772597838193, 0.1818226263187366, 0.8199362541920876, 0.23770482546479868, 0.010179731029602715, 0.19243341595142352, 0.03712505947661529, 0.0052665996218198945, 0.3032644341540788, 0.004491075570063176, 0.0067124922888569215, 0.01351764733239661, 0.9607925192846403, 0.20827320788686188, 0.006714198226521851, 0.005584878273183572, 0.5574465123838352, 0.011596479040548125, 0.01728920311054939, 0.009371525709985578, 0.23045871880294938, 0.1802109072013887, 0.00604685759794638, 0.012984632439902537, 0.22303992762576308, 0.19677321063432343, 0.005184514721551212, 0.17496697174510173, 0.9410051587144965, 0.29949427227187203, 0.2628308689845656, 0.18155096960667794, 0.21259351733307658, 0.007824371692544742, 0.009743112007075201, 0.006480619526524658, 0.17683100751729472, 0.17502410881503974, 0.007842292091960761, 0.9824753839984752, 0.1735237495558892, 0.006831241820388951, 0.005795084394250011, 0.2202829543724889, 0.01531155521350186, 0.006131839876020369, 0.2005435244318226, 0.007652570154510485, 0.0075488886874110405, 0.00904113239186464, 0.29563453397715905, 0.26816005220838834, 0.19762598509226492, 0.2541989070344342, 0.33631936288765674, 0.006343574660405464, 0.44159627910460963, 0.0049785919355176435, 0.24894505515070253, 0.22210776732607432, 0.007923972374706927, 0.008502771396529316, 0.25071222245260394, 0.2930346727690784, 0.17929236847077026, 0.008882456318000508, 0.014491559917275743, 0.004937798987523279, 0.27796744577298094, 0.005994652517586501, 0.009657360604015761, 0.014283870416960453, 0.28863920239975505, 0.18018627670168336, 0.007147864048816322, 0.008390920207145741, 0.00851519350827541, 0.18354997997992006, 0.22942929005860008, 0.43093768391648446, 0.22008642276153717, 0.264752945029592, 0.416865536288059, 0.006905852889386539, 0.01112230027823198, 0.02102121146990535, 0.008952160064112763, 0.20854651379494762, 0.9585901099735112, 0.508568729271248, 0.008935670498599004, 0.0043218204896071505, 0.01010121700332468, 0.24385689725666163, 0.005027069584632212, 0.022378924619210976, 0.18962765205751722, 0.17097152792659703, 0.28541154251569056, 0.0051443891502707595, 0.19478015456754832, 0.003857100349890219, 0.016039162587726398, 0.24216356960585939, 0.20611147695242235, 0.2073277970314576, 0.17021142976322953, 0.006515586600508209, 0.006042354795652135, 0.9964691202518421, 0.02651110575063174, 0.005069839965228899, 0.01227806770829696, 0.00519963939078673, 0.020180545284224423, 0.23873734866850518, 0.006720691172131687, 0.005289522589820976, 0.9976360060404532, 0.2456889209102348, 0.98927193294636, 0.004896758002587641, 0.32644229531367125, 0.2734889722407775, 0.2807484268228266, 0.01031603314767561, 0.2570752674237481, 0.00737273641304538, 0.007729786264080312, 0.005317735314505827, 0.24091805687892484, 0.2244789643795663, 0.01010554407048758, 0.01321991589482029, 0.03487411292675704, 0.0062171674302124984, 0.006699714495919541, 0.0157979580022734, 0.0050006587979684654, 0.27254359953832596, 0.2378547663583611, 0.007557876804057366, 0.3327324472150796, 0.1672218368589372, 0.2523715122547385, 0.00692730760297243, 0.16869145406719024, 0.9909445160559196, 0.0158946976942003, 0.8781927206203677, 0.008898919331486522, 0.2777374406207812, 0.006159793561172118, 0.17474466158188895, 0.21221021853316596, 0.009328428912509077, 0.26062954299438523, 0.025419647997285726, 0.01351241482090648, 0.19245018037838718, 0.01844853418987817, 0.005091211444393326, 0.28675154033701644, 0.30074397350767934, 0.24049003522393603, 0.01707331665360201, 0.23451718869055388, 0.005556102892284884, 0.006935775785816174, 0.0043133188369543635, 0.005212613220061906, 0.2904229464102052, 0.005325158920713894, 0.15856463722119582, 0.02237851616165322, 0.21112624231825527, 0.0062337731444831145, 0.1663565541942763, 0.006580867839434036, 0.18967877906402064, 0.23706033781507752, 0.2733191871604717, 0.18382829721663246, 0.003826946445223799, 0.16406328889317182, 0.1880751964153658, 0.03079989332960955, 0.005396739080948447, 0.4967826073342374, 0.017496412676720207, 0.1900149517059401, 0.4143221451067218, 0.00417285623408225, 0.015406404341781017, 0.011983347327661584, 0.004964715206657432, 0.004732952208347619, 0.012711149243398152, 0.9748210999594102, 0.00823256790518934, 0.008849646965004149, 0.2819539078521911, 0.003938283432154013, 0.4511878970245767, 0.8741405064283803, 0.21824478745884152, 0.24610970960882733, 0.005383423498527119, 0.005035585291419727, 0.0071091947607214686, 0.006447785841664853, 0.2891073856321847, 0.03170539216931683, 0.2939847875851795, 0.586713653260692, 0.0070618461637767, 0.015141642157203624, 0.00788896561932038, 0.004857775693396077, 0.9902496861294252, 0.006051561321038684, 0.003790669240630371, 0.17871544672743403, 0.22838141761676853, 0.25339267918686115, 0.16357012797380152, 0.008764208745053252, 0.4390894623613495, 0.2845438493081722, 0.010339565129653455, 0.3773410868029738, 0.2700727306495472, 0.009694547221037339, 0.774272025180913, 0.017902414244951897, 0.24715819339016287, 0.27308850842847565, 0.008967927324278048, 0.15806940611056397, 0.019266772826537496, 0.004322431236551046, 0.005314146968317668, 0.004103068449614905, 0.008572025099006514, 0.004703593788615092, 0.0073805684365946846, 0.005971995420952462, 0.3107016531095802, 0.006957590282077452, 0.1700326740006079, 0.0073707228112964065, 0.3650709568604209, 0.012272240468550598, 0.2680383860459705, 0.00487020938720383, 0.012116595161497533, 0.25704005061034974, 0.2550023220838666, 0.008365994961292783, 0.010393222439681668, 0.005611931044074054, 0.00962453777918636, 0.9785750631780605, 0.9982120547357696, 0.20451621179324725, 0.9945600417605855, 0.431019353262339, 0.004015992792469933, 0.004901317827225136, 0.006748057903152614, 0.005342643989534812, 0.18703826273506063, 0.9625978777327742, 0.18303762666739995, 0.007214088360986961, 0.17827197322027616, 0.005342601746893147, 0.3740400035936367, 0.015488158924198503, 0.18791559736119362, 0.006808478732260152, 0.01582454912189208, 0.011635937444912795, 0.4669249490794185, 0.1699833410264156, 0.004913337311148705, 0.22835858600761622, 0.008163972355943417, 0.026985639328840974, 0.01672999482902751, 0.2718975330274802, 0.007719949669665152, 0.18240785412509505, 0.012414933840562957, 0.2087796422910123, 0.3141052189444616, 0.17708475560793985, 0.007394906674736281, 0.23895631339612056, 0.006642422984516977, 0.005285048301437606, 0.008711391633782201, 0.013154661963544, 0.02052201071772187, 0.003986329383443567, 0.23179090943990843, 0.0096264167694053, 0.006254449842510924, 0.26273856933686995, 0.29041698258865045, 0.004665609677998245, 0.21731310396085435, 0.006847406719351808, 0.004077533886617517, 0.009372742663354486, 0.18458437340577447, 0.012362226469008026, 0.006248401266950267, 0.17960323829897606, 0.010839213136082543, 0.2018591761559796, 0.0042646301439381255, 0.21603621768331752, 0.012658519762389095, 0.9767439703002014, 0.2674545151402952, 0.2851128316867261, 0.01605077910208542, 0.16483437424651934, 0.004930636851177604, 0.015732092443948253, 0.010007501222201157, 0.9226195162964133, 0.1830089331948479, 0.007303011744594929, 0.17770444155379977, 0.18851623198043838, 0.3149094485743032, 0.012647039881144607, 0.2084824269017056, 0.23445985618135723, 0.2307167002664695, 0.006871324904800304, 0.013026248829819741, 0.295580989019548, 0.19565522029515053, 0.011643659404934148, 0.9936009867020426, 0.9940181912510786, 0.9907825579480161, 0.02198563007456617, 0.00822377741941292, 0.007606468405569377, 0.01390976146706038, 0.006317717530124854, 0.20322532031638418, 0.004781934922989993, 0.19918867568739107, 0.015438886276864416, 0.015436175948078017, 0.36524151883921835, 0.19012342002948435, 0.011419705235579832, 0.17886013436551895, 0.20731255436587648, 0.2067614304815964, 0.22957580297999092, 0.018097256082837073, 0.21227717231159124, 0.019789750861393295, 0.0053948889756425845, 0.21357339025936684, 0.008943205214916917, 0.010419781907466424, 0.009113888103927792, 0.021329695940582885, 0.21941691766885638, 0.0054477027860632, 0.9957732981087875, 0.2553154802947877, 0.006116212907606748, 0.22611856987507822, 0.007472392180341875, 0.4307802951057995, 0.17367740675918308, 0.18811125189471198, 0.19949504356652203, 0.010393399572456418, 0.23838245973981476, 0.9771074722665902, 0.667307032388395, 0.9640928143529854, 0.3036081113267572, 0.009136525742935725, 0.012321301438653561, 0.0070421569936348315, 0.009737412206565326, 0.19522706413472496, 0.0058701902143695715, 0.00786316852306582, 0.2087829063290878, 0.010255922366705902, 0.2193673480806654, 0.005112968594718527, 0.014543258796846141, 0.007044290765963707, 0.004397626699040668, 0.3032786764533658, 0.006344836585251983, 0.005862983737297686, 0.9780931491402576, 0.2505922520778152, 0.006129421649682091, 0.01283719882085595, 0.23090364897487248, 0.8293565144447161, 0.005202866139462382, 0.0024507142288951074, 0.010356010726490998, 0.6936280254755843, 0.9924749073938477, 0.028854217624147502, 0.3021771141540957, 0.9208351447977678, 0.9595577795248995, 0.004719385345657628, 0.38758923044583204, 0.007910981855620369, 0.31338224930087455, 0.2682799316228152, 0.01317708531542427, 0.21841719268102583, 0.3888415447291068, 0.0046736305976174, 0.23910424331778507, 0.019790567980719723, 0.00639690790029009, 0.17343532224987507, 0.2721546415936177, 0.18449931994589117, 0.24796380157874032, 0.008586600355185488, 0.02515271548592743, 0.1986840529001269, 0.004028158090906994, 0.440974544549363, 0.008773292305099913, 0.17665057055427874, 0.1565784465949856, 0.2742803893699133, 0.2161091065920137, 0.21631089449512783, 0.004143263335613285, 0.02242273280499609, 0.16035621678852102, 0.31455914606844576, 0.00887300524990596, 0.009377271196269951, 0.3449280032641376, 0.004688225385595735, 0.17257319658444062, 0.20797699972753564, 0.011120896842439585, 0.18409970752864172, 0.005501020166216856, 0.37684230369456617, 0.18630640892506703, 0.1676280426965569, 0.0053094266706678606, 0.0044649621646703965, 0.9944216943911026, 0.3130715679829723, 0.005016497502627582, 0.004517148040585449, 0.29787751404553586, 0.014916819362219235, 0.018920591092515426, 0.011113947353132049, 0.0076826196413180975, 0.3255316866479104, 0.2013693795928586, 0.007109758522533427, 0.011904562264829556, 0.0034100533876232, 0.010471070009158154, 0.006625529450635657, 0.27729554660602873, 0.9901784015177315, 0.22045507104286477, 0.006008395576559895, 0.007725378510794538, 0.20794120936788313, 0.30457589653060385, 0.203809575839739, 0.009830599626052648, 0.21707121831750417, 0.2471897783463967, 0.1709327388171782, 0.16612295409951677, 0.33804311458741404, 0.01819047875394291, 0.008767563178117317, 0.01580035793386839, 0.0073555928444247465, 0.0055251246897546425, 0.010082207399484388, 0.2488864383199127, 0.18205189705104188, 0.007997396253957323, 0.41084394997821694, 0.181566957159704, 0.19981917940710814, 0.007785517659170322, 0.011341122399023915, 0.007550281242906665, 0.37729063079621866, 0.2258056136842974, 0.006275235812194305, 0.007427207114557015, 0.020110239226077253, 0.3343242920097594, 0.3368365082151378, 0.3565461135970565, 0.15899739903878674, 0.987966263680216, 0.1797441202433357, 0.01500915121466966, 0.008858408644031037, 0.23065947485593838, 0.17664846953595087, 0.005050397611359016, 0.16956078659475649, 0.014791841004428766, 0.009759501465879485, 0.014923673715207895, 0.009347182274169025, 0.9711894834086416, 0.3964761839140044, 0.010899081423884864, 0.17570319795290834, 0.218338010142389, 0.005315793591424327, 0.9878115311878783, 0.006431550701828801, 0.17130135050591952, 0.009517259324314518, 0.0102827228818629, 0.010684469583300528, 0.23000075558872432, 0.00981119333954875, 0.9947986123516823, 0.004947181824605199, 0.005287791273515092, 0.007928515404031325, 0.004689274211559091, 0.014848879815315234, 0.007502892000967058, 0.02123976651533879, 0.012599995941578197, 0.00979400584476659, 0.3312927077951218, 0.01244186231649412, 0.009079827174492334, 0.006828163007367568, 0.1650216640851587, 0.28552517557707185, 0.018002087560631038, 0.2747015393219, 0.20606481976912797, 0.24733941526190534, 0.0027444057045434805, 0.15316130064792763, 0.17087553949512677, 0.006033506945363978, 0.0072406791267401165, 0.007932247398294212, 0.008832946344749815, 0.19206436438895225, 0.01076154140884454, 0.009032986829445457, 0.3501288910453223, 0.005851652221234153, 0.25723501069206733, 0.22453598671346842, 0.1776586204683637, 0.18113776528203918, 0.23942277927362593, 0.0055441700435332735, 0.00662584365873344, 0.3119683409816878, 0.009318285864644808, 0.9500672333084113, 0.004587245222205129, 0.004076998193564699, 0.18767195545514137, 0.25509768884940803, 0.003813063462574086, 0.2047139183132536, 0.22087898893522262, 0.016204693864410206, 0.008476781216245548, 0.18540085923071165, 0.006460641733811837, 0.9964482777173218, 0.01094279171003167, 0.009642764002775396, 0.010560140784340019, 0.47417365418800517, 0.011633589711821221, 0.005866173322565348, 0.009503770211113361, 0.23051323188453926, 0.005340980836652458, 0.011842531935440685, 0.9817651736437034, 0.018534726075324436, 0.20724846127866292, 0.004125914580758932, 0.005123487286453044, 0.007520355568140005, 0.013768270680651121, 0.8299785609623909, 0.015116105683587924, 0.00437394928130738, 0.16964263884146588, 0.012984893842892312, 0.24452089369771177, 0.19319949089513547, 0.008517979887295496, 0.011371432096992174, 0.7945017385432487, 0.9966687186786154, 0.18009004654737906, 0.006033751040334169, 0.35509880560941465, 0.005998060062944221, 0.015032503295596977, 0.18426716043459992, 0.2871968264887832, 0.005979413413527551, 0.004224195176968935, 0.02123722312567065, 0.006953209317261865, 0.016254165506662324, 0.00887561122528966, 0.18554553559714185, 0.3937090501564398, 0.009005270185284494, 0.7185009334867424, 0.020716418529173938, 0.3808976092489967, 0.01741777037151437, 0.22684327577484087, 0.881981483821249, 0.1600869423546306, 0.00487506474586079, 0.007459877633785799, 0.007568947657380396, 0.008116588475670082, 0.24747351915618762, 0.003946511572978286, 0.016008749095723675, 0.009917601761059986, 0.006963115566313015, 0.006006857079511118, 0.01930954323923162, 0.2054594740560713, 0.21378308100946297, 0.1727545756382687, 0.007169858181987879, 0.25128240973934085, 0.010933516524792849, 0.281425332248574, 0.17900534266214846, 0.008763954224172414, 0.2843515180465446, 0.2623516786891642, 0.02215024080885825, 0.18153387782393676, 0.007124656133430791, 0.2955432982902825, 0.34558824343741734, 0.012832712216854036, 0.1884552039771197, 0.9993019221148509, 0.2987323816646814, 0.016605914594219125, 0.3922649017768402, 0.23301791926764104, 0.16804623844146943, 0.007507701113399707, 0.008417475346640366, 0.9443156921964844, 0.15865093715259748, 0.005606393394940464, 0.5354058324615232, 0.009810363033547957, 0.2485345554813539, 0.010209980763749144, 0.006118707310269299, 0.006279669125423132, 0.005979667660499399, 0.005608310016917646, 0.4309342261825721, 0.9009369040575002, 0.006018985782681277, 0.0096109738308969, 0.015974800175676297, 0.007384569965948674, 0.009408250736948454, 0.005718925389361553, 0.0036374545809645, 0.0076653012394071384, 0.16921606967124686, 0.17855741299916916, 0.015214495121608803, 0.004906411070024251, 0.9468763138586958, 0.008296126925576323, 0.005213024224351351, 0.18420786806850462, 0.006433641093064645, 0.02224664866896043, 0.8090713386536024, 0.32458811599186344, 0.007225563220319988, 0.9669247911522958, 0.005854262448608692, 0.1754944850901961, 0.010399343657743906, 0.007384521063348523, 0.0024422166802537193, 0.005171904916407276, 0.5812653730284678, 0.17097193331332539, 0.2671126777683339, 0.002528335591147653, 0.25633407025928834, 0.21068164684301555, 0.3266962686814011, 0.004941978299078051, 0.9956600307620911, 0.008948504427500708, 0.010933673080937033, 0.01928104796786186, 0.008751887797260282, 0.009052117401682871, 0.23091441317381045, 0.025912843132669353, 0.20971041054004996, 0.16257162386134025, 0.01453999912841714, 0.17807233653512966, 0.01141681317897751, 0.28494884338155113, 0.24353726476797127, 0.25252437069035905, 0.004674598739731562, 0.31702370876259034, 0.011511180506156793, 0.007739329146352009, 0.05038128772025896, 0.0037974204139471952, 0.00518146017669786, 0.0045329491050988945, 0.2410739572294141, 0.3211413964750192, 0.7607584895134618, 0.19379017966253595, 0.35757846962866935, 0.005363365178495068, 0.006610186812123888, 0.010056457043101935, 0.2457014444129222, 0.008255535409791539, 0.009292218648624062, 0.007428940083147294, 0.25928947175972294, 0.21770165829893812, 0.17552050910877073, 0.20555671964645655, 0.18157968943255998, 0.0077519348577488895, 0.27382729154238206, 0.1886346606335248, 0.31945589862105533, 0.44632167612416734, 0.2338358157215769, 0.006669992184889906, 0.006855572922667455, 0.006730916947179374, 0.18470656185572104, 0.004249823987807063, 0.005187534080504192, 0.007460999792616953, 0.005464494860827726, 0.26442683302816183, 0.0062862711772096016, 0.015523647746450008, 0.007042366154970464, 0.9974599559147006, 0.9741174186572183, 0.18485520675127243, 0.004861255936674441, 0.014277326365303196, 0.007023310553132559, 0.009713880843175406, 0.006818916930106989, 0.3081023429210893, 0.0028086212122136263, 0.006680435667724023, 0.41815006209617195, 0.016120274315167996, 0.02223678874700216, 0.9964524402798622, 0.17652701726758907, 0.6389423080461687, 0.25410592812115296, 0.17609387319713543, 0.22716612326658153, 0.2873296285976681, 0.006138025437763661, 0.28178369161613076, 0.006820381358839093, 0.31602777306595997, 0.3573253049477445, 0.28903415245953173, 0.19120723274685988, 0.35984667293663597, 0.27695112703454694, 0.25717573624693013, 0.42091101940989445, 0.005216601725027414, 0.006688536976167983, 0.33542945503954885, 0.018605220095425555, 0.011703514647780513, 0.215956416125079, 0.25354662379217885, 0.1890538987743934, 0.0065995618722999244, 0.005610302582465763, 0.006355926259074034, 0.27618242549975514, 0.23779558004374338, 0.007463464572853372, 0.9935419416072697, 0.203096697804991, 0.005549448916058119, 0.005916730971955094, 0.005232684674170395, 0.0027800036655042915, 0.3769968126013463, 0.006691436211639047, 0.012850089622543774, 0.20584931158070544, 0.023290435149833852, 0.005315719184815684, 0.004171040768032589, 0.004816978876906555, 0.006346183747521544, 0.014503777484964448, 0.25963701385469773, 0.012267242198732126, 0.005418050982005313, 0.1634203466333484, 0.005216130858703121, 0.9987835175471931, 0.003385842903202067, 0.008098445914036446, 0.16664034874650818, 0.005601609568213033, 0.21404718651263457, 0.391907074946007, 0.007581741017678324, 0.999194456895113, 0.005201203163416648, 0.0056465850442995865, 0.006291979018957255, 0.006214345666725667, 0.27192435877823046, 0.00409074037139003, 0.01179704659104869, 0.006249436759780065, 0.007135413582252852, 0.004262695359153347, 0.23521726659642106, 0.004823731007908039, 0.20650992027130832, 0.006621258177230396, 0.006686749070570389, 0.020205209404033583, 0.2306403833946459, 0.3523318578270598, 0.2747664467200206, 0.007508204069783851, 0.17265719203255808, 0.20163614153181245, 0.010779113180216827, 0.02461252201347596, 0.1690614831244852, 0.17577233256817396, 0.0052844117308532106, 0.00525145118637388, 0.006049847869739639, 0.011418260640124692, 0.7361760495277812, 0.007881013680821263, 0.22245471844076753, 0.16877869494769104, 0.17675308731711686, 0.008392023129498586, 0.1829307178906218, 0.007559075938166734, 0.48588932563705833, 0.9912183152827538, 0.008045064177699518, 0.9993232658469111, 0.008527155199638738, 0.005522754044587226, 0.2508008214163167, 0.36851107818340756, 0.9946779842047704, 0.24569542321651627, 0.1708789817181483, 0.3135731676409062, 0.8707926004853708, 0.013917956585755292, 0.9850989037014222, 0.009852741607195894, 0.972292878681936, 0.18385320927079046, 0.21920112169927275, 0.007643055018983554, 0.005668593313371931, 0.010404286686981784, 0.009000160983633277, 0.02021036904403327, 0.004566293202912715, 0.23943777335476027, 0.006676734363970953, 0.24254694866567228, 0.17071307238287442, 0.00841098999578818, 0.005169150651127983, 0.20232225298343443, 0.28085766711905136, 0.004695760839823962, 0.008132093909235536, 0.011623329772588554, 0.003169047804030033, 0.008844450060880285, 0.011680097302120584, 0.008841555110293301, 0.2876259915403214, 0.009526979137138278, 0.004756549487264897, 0.009776316058815217, 0.32059218282610824, 0.8240277074932589, 0.20546685142974913, 0.19824753355129485, 0.17449603210926296, 0.00775952855523704, 0.004271363096461287, 0.26104603019854594, 0.00728815682945042, 0.004070765275144944, 0.004858474718431938, 0.16088489635192887, 0.9781221111075156, 0.0038706481152657878, 0.006627336073069263, 0.21730424679377386, 0.6637741861250896, 0.21410619705505685, 0.008675000618809652, 0.16432119099733, 0.16996125207061932, 0.009336246304229873, 0.25038495651984194, 0.007516290285134299, 0.006832309480126687, 0.004409557562642669, 0.007287230963401919, 0.007979598758226064, 0.008323081846348552, 0.00787699272045334, 0.0042584040992183535, 0.36774116755689634, 0.006419737562087326, 0.16119472970339868, 0.006740414295653259, 0.006642579453095546, 0.26849909700215635, 0.17950323274655214, 0.16290005294281015, 0.01006135110221215, 0.009184801434871166, 0.1642775872244817, 0.18144425074365764, 0.19504091231186663, 0.007312080989339989, 0.016473498823884658, 0.011630403112950367, 0.012985605304368864, 0.0071879667848707895, 0.2258069054194272, 0.18951837493969798, 0.17103569102776853, 0.012150195155902207, 0.9298171125421211, 0.029467835010835934, 0.014653261758384517, 0.5343827292467815, 0.20692458114477602, 0.9926941916044936, 0.01951383232993671, 0.005720267202541549, 0.03090754947635463, 0.2613649765573934, 0.9973208061095724, 0.007379368459912426, 0.008038921847295474, 0.015597671902861767, 0.017326611527981185, 0.002713480912883875, 0.007171180323289887, 0.1991386962540104, 0.2695288393765544, 0.012831901347915835, 0.19425168535473067, 0.004613878505998668, 0.00474830840235739, 0.20523410130118236, 0.26731926242302917, 0.19225472619352815, 0.00515143029465917, 0.2372389801160318, 0.008533775371319554, 0.006479454180047398, 0.009629963180957275, 0.21946529328514686, 0.19533344986194068, 0.02248485271238201, 0.2960443561279973, 0.005261637201652433, 0.9923723658347527, 0.9794485172004097, 0.22200852054728942, 0.376267057144241, 0.19866882762044685, 0.16849566948135525, 0.008473833871843054, 0.004867068069960237, 0.2897249364486998, 0.004821859439813852, 0.9982572690825939, 0.008330808583448765, 0.01965444619247382, 0.009113698545111537, 0.22573372521251384, 0.15963377998839273, 0.1728678819747223, 0.23704570621121634, 0.17691785408269206, 0.006611512762391604, 0.9805408753439111, 0.2582499791033913, 0.3042623802944182, 0.011267847760876842, 0.9937128450258119, 0.1824523797797653, 0.006892474859552262, 0.004805832436191203, 0.006732096170688815, 0.0076510652711984685, 0.2303144599332076, 0.9934783052689526, 0.007755783230118661, 0.013150894227603415, 0.01649630510070047, 0.16667045943459663, 0.01589130808522793, 0.9134674974367378, 0.0071902540054785535, 0.006318375937097064, 0.9443447567922547, 0.003726540451347791, 0.9934946723856319, 0.2859005434538271, 0.1840782707253965, 0.01484845734034095, 0.08469247659112317, 0.009209379977229312, 0.022136683628492006, 0.013440117980322287, 0.40290063954899963, 0.17086468326684118, 0.005722949858785823, 0.008014375751427777, 0.25519756525460424, 0.00705302420388965, 0.008478241886510203, 0.2871630903936717, 0.012463448780328902, 0.17931291976395056, 0.004508147327753458, 0.003748619798556623, 0.003808352124462545, 0.23186159623931096, 0.012874513081967728, 0.18393248595586706, 0.29077031746448523, 0.9937543751976599, 0.16802893789540363, 0.19560527125408744, 0.009193320111172208, 0.9947769417018142, 0.04597390432125841, 0.2608796342837428, 0.007025284289022447, 0.00679783512626701, 0.062256477706648265, 0.023694155726166823, 0.009634772052531835, 0.004276459575020254, 0.9790967051600459, 0.25863965069991735, 0.2883710871532755, 0.008867410175879406, 0.06261720942070655, 0.007190805734098097, 0.36658369782841943, 0.6672135385025482, 0.007286703284138563, 0.21716542815666676, 0.01802178149187312, 0.2791962917436772, 0.17580458965718432, 0.2364885358431953, 0.006463273810589185, 0.25211247990420804, 0.1730048196252263, 0.00618012983127265, 0.01055806607830392, 0.008522200148468306, 0.30442686496363697, 0.9642353183823336, 0.3398732594811786, 0.017674237168567378, 0.005400174056498718, 0.25667662839467026, 0.2986604984328274, 0.005166358904136365, 0.36684975711177403, 0.008981947991338054, 0.22244217850291215, 0.00979442082929854, 0.25013406842859737, 0.17961318976583385, 0.0125665305807838, 0.007625532760711925, 0.008567322120497031, 0.01346773553488133, 0.20634790389908658, 0.2451938331975716, 0.45185272037126367, 0.004407357016209611, 0.006635163181878572, 0.012976304580201584, 0.002660256616393442, 0.21155992874779345, 0.008379059392438161, 0.8958548373640065, 0.007233905080834748, 0.9851542051935243, 0.005376954236352297, 0.0036047784893880504, 0.20679950193368685, 0.204633805976023, 0.23090607743037053, 0.1851119207728989, 0.25794777965674176, 0.007640181280774433, 0.0038699107233758742, 0.26598635916466573, 0.005367022021558017, 0.004217610872907644, 0.003934776499716034, 0.004847235666195242, 0.004928179459519304, 0.01562755359154071, 0.011432587926017562, 0.1626628182820027, 0.004997618877263844, 0.024792919016779356, 0.2668024263811222, 0.0074234664923316235, 0.9571794851712578, 0.010614688831962867, 0.004969952175734683, 0.22714463856771774, 0.00663620065161502, 0.18380868931242839, 0.006724037153089594, 0.007859941954800703, 0.17555592363593658, 0.1817034389045551, 0.00643121469026995, 0.9956878985685462, 0.230097139862659, 0.009631167970762144, 0.33096759058909936, 0.010748032310407796, 0.19810074355722146, 0.006098832277473054, 0.010117148911039377, 0.2808959854979754, 0.3462187670503408, 0.007477251996924681, 0.29465540733043, 0.012491401425441329, 0.18568235389998067, 0.008272516094513833, 0.22369805539690618, 0.0036159082456929197, 0.007537989295166893, 0.0067851259112646535, 0.015056420481362827, 0.19656919469485623, 0.007992857597461777, 0.37520534544919704, 0.03430597237254489, 0.005659674902249586, 0.32005797133311503, 0.005160218234215464, 0.261499354351554, 0.006082288062518198, 0.368082079220846, 0.017454942844347492, 0.005295286484855091, 0.2186968179243673, 0.016528404085576213, 0.44074318614832386, 0.3307212202725145, 0.005633086730709333, 0.010293455511016594, 0.3010168587302122, 0.007197162145262532, 0.006624067579072988, 0.0034782779051464405, 0.00946110150869001, 0.004986930833414931, 0.015531200370892102, 0.9390355585976753, 0.005247615220178284, 0.17315314425221817, 0.5590989054959121, 0.007622847713438138, 0.2548039172540528, 0.0143949246364755, 0.34828014403140234, 0.22683527722932398, 0.008954892559986658, 0.9814854497366463, 0.012078244470667446, 0.21491007223072128, 0.16817512458126468, 0.006340940887335524, 0.2814537048120257, 0.18094161945225617, 0.009516958703177278, 0.24691171015473282, 0.3587636010723699, 0.004902535975685584, 0.004179784077213348, 0.9964907334065485, 0.3624792336229916, 0.19701983479848417, 0.45494091814338444, 0.011959558958265431, 0.1879464808147657, 0.004792825379205257, 0.00471461474667805, 0.0030591239492460706, 0.23952045756100554, 0.2132038519031772, 0.2056492613752322, 0.008235470743360188, 0.24080024628979238, 0.005051675802391093, 0.01782409214975397, 0.177737193720537, 0.0054388803041614175, 0.004822332285177805, 0.004039087457534873, 0.005965835605520588, 0.008038339768554717, 0.26923661790625786, 0.3418157740048312, 0.2576071038385449, 0.2577257522545977, 0.005263495713298031, 0.006714024393112586, 0.33126087539631544, 0.43663400637460825, 0.2991594273932111, 0.0044143963044361405, 0.010786331815302395, 0.4034982541825607, 0.00732904471517233, 0.9470564376545305, 0.9949260889445208, 0.005054398049465234, 0.23191549951923998, 0.2525596103322888, 0.01004784260094343, 0.006909809544234809, 0.008714644782271292, 0.21728863609831087, 0.0233842581032637, 0.017861735762963352, 0.005308762033074749, 0.18404909229527425, 0.010670889415180277, 0.004290098839232091, 0.005517233435662479, 0.005480561724031929, 0.007298365991921522, 0.2403536773431733, 0.006319643843627933, 0.0049798698342452844, 0.5069802996030044, 0.17736277754717972, 0.017344167261958535, 0.23112716399062114, 0.26190204181688914, 0.005542861886270542, 0.4379935461667646, 0.006542962441838631, 0.19030870182746285, 0.016556497257859328, 0.9812317511415423, 0.006443882689319305, 0.0065998301857723785, 0.006478893195703071, 0.9988699903456137, 0.00944368856151433, 0.22586404202789157, 0.006268553934162383, 0.02899607419001865, 0.5071640412375384, 0.218510653390633, 0.01065001297696226, 0.008353132278888273, 0.2993596156692253, 0.27033869404216815, 0.007517028602922022, 0.008047688682022401, 0.006260358158455188, 0.011542060839321975, 0.014824338773900617, 0.0073446170024323455, 0.009840656322762441, 0.1991593690527922, 0.3674746024732299, 0.21785616213797848, 0.25599738477646183, 0.2335758400437662, 0.005730555425930905, 0.0024776592451369855, 0.19324358980217682, 0.17911290158025894, 0.262739874765478, 0.010052499190663183, 0.010811520101123118, 0.013312494290123295, 0.0047201501737693784, 0.9904205447619834, 0.008390841429482532, 0.005743660880149791, 0.006113494639409683, 0.4264126379109615, 0.005479972572417034, 0.014432343793113787, 0.004203148780420881, 0.013372543039855713, 0.006715848772967783, 0.38337310816460807, 0.021863582149909626, 0.2377684789665769, 0.38486772166950894, 0.1671577643635967, 0.010294897893339268, 0.005202964032532194, 0.018634863941741627, 0.29318224164228956, 0.21410965922748157, 0.44990582321771344, 0.7531075342959759, 0.013251135765740878, 0.007578285360175998, 0.026684948385270052, 0.004940427944219868, 0.20541582146052367, 0.007300915363306082, 0.006464989057967184, 0.007848000584199138, 0.007453569572701286, 0.006564766576243689, 0.006563568182810928, 0.005827482318765621, 0.00773608217053728, 0.3134907096642912, 0.005572470716208481, 0.006500066573483832, 0.24632930438694928, 0.009217776828083153, 0.009185402493131455, 0.003810559854082485, 0.00981212178509476, 0.003953650868557363, 0.038892750388488606, 0.809320070876479, 0.007528304430721229, 0.010626478637045123, 0.011280866498862167, 0.009077919571701159, 0.007281626679315422, 0.024618667239525546, 0.004757254803516214, 0.006650979555895492, 0.26501452205390597, 0.004080008606051471, 0.33440893627160584, 0.01205568485085592, 0.004994073175785393, 0.17569326911941552, 0.32447722574141036, 0.019773337087064122, 0.28155313930571135, 0.002676491501156894, 0.0047009781662858754, 0.1762557080286999, 0.18580731675946618, 0.1824681151553875, 0.9888937444561032, 0.0033921168228345125, 0.239800964456222, 0.23400709251208213, 0.008472851827093248, 0.20024391018317098, 0.32554564088848104, 0.9202604450706677, 0.2366148657647678, 0.028910249568700284, 0.00610060993827666, 0.176007200186779, 0.005475327448672524, 0.01397030438617203, 0.017455943717206872, 0.1759868621332127, 0.004756617402404751, 0.18166416012119782, 0.19207089605877392, 0.011676078140350252, 0.014271889627272279, 0.012616589676972219, 0.34926828311485036, 0.9963662708343386, 0.2740964011297862, 0.006906026339160615, 0.03299399968597472, 0.00847204137000459, 0.5147907702865164, 0.213814451499306, 0.21525621053051874, 0.007050301714098635, 0.007525799005933742, 0.01586349856679517, 0.06317001082637225, 0.0122062231767607, 0.00588180662664715, 0.007830374659421687, 0.24653352261967187, 0.9992109139896328, 0.688743314638216, 0.006436872628143511, 0.18685525932891164, 0.21338743288979312, 0.006730781272924085, 0.007178236128034678, 0.008035253335713106, 0.20097050475032796, 0.0065549440360777545, 0.19743507257582812, 0.0049971357170518205, 0.004969705353201317, 0.005075976506429322, 0.010266222174269465, 0.006346914641582054, 0.20865709009940753, 0.007738646700063755, 0.004874145498236161, 0.004863249676024033, 0.007626326912503816, 0.0056891369386719345, 0.9006620704314263, 0.1758868461721256, 0.21758454655858772, 0.008416179902366283, 0.25562816857954496, 0.2592930831547106, 0.004032464967770206, 0.01796236634145243, 0.005503535892171832, 0.1691539719796556, 0.2911287731118137, 0.00898317441062431, 0.014548319685286531, 0.006960887938189282, 0.9937355844793392, 0.005748268083724193, 0.016853689422851457, 0.014981189185743583, 0.013875128641065585, 0.010565347329136578, 0.9797620552880946, 0.2105117690565462, 0.005000861773426542, 0.004461255217649344, 0.004404045337928864, 0.00892572632723165, 0.27941690498787863, 0.005427464888745987, 0.2303794279069325, 0.19868377487005986, 0.44814047961870274, 0.013175390166831776, 0.01680185166615106, 0.011001313131533175, 0.17605705244596964, 0.014678923266505913, 0.004936541101665467, 0.005822810233252873, 0.007042744515696413, 0.01079578960834995, 0.01214616626057936, 0.0035008702622828384, 0.23760457201000984, 0.29931391762361564, 0.9777080887575791, 0.28586061224690285, 0.015549808909082459, 0.2335295032286911, 0.18518787440833473, 0.1886751802986858, 0.008627664874060779, 0.019393123075413538, 0.17051976655833445, 0.30785410710468697, 0.40610109083277135, 0.17982501595364125, 0.0052202807529526255, 0.1859560600356666, 0.013384516555387995, 0.005774654672637094, 0.9988985616862531, 0.2938044159739332, 0.25861984089029916, 0.32958486090226174, 0.28236427983736767, 0.006988159359132438, 0.18643137491711848, 0.17795841273440505, 0.24706679855438735, 0.006581441974543381, 0.01790135596715318, 0.19184745467555114, 0.006412074671746064, 0.17651553907180487, 0.9940666709863404, 0.9232145574408492, 0.324296362057441, 0.008105962185488305, 0.30262737195714856, 0.006713303687744594, 0.0058363037833879545, 0.009578707606316985, 0.011396272343844294, 0.013237436998256335, 0.1845229007593869, 0.00579665452955439, 0.007090072696876458, 0.019617872276060856, 0.005672546706350799, 0.007001258369725379, 0.005190386195407454, 0.008973050554078401, 0.004768868785628539, 0.9939166376198372, 0.2363929064321698, 0.007444428884542677, 0.0054441879997834015, 0.006998875774488148, 0.2435972236885184, 0.028052522773276675, 0.17624698959224752, 0.005755615054109243, 0.009257003979953089, 0.005684791689362622, 0.01771757835842855, 0.012234171110380533, 0.0034512310673181145, 0.2640647408524416, 0.010148983410026426, 0.03716614360371285, 0.006393794192895837, 0.00811152555189211, 0.3110718944241895, 0.01248163917769679, 0.5022457941507256, 0.25136320686004876, 0.2533673158419757, 0.006348062456189644, 0.2838981253472473, 0.007393048692586123, 0.19391063539387093, 0.004847815114614398, 0.022932329090555058, 0.39525601032602653, 0.9955937401188022, 0.007980459056507658, 0.16830572604006008, 0.008554537459917147, 0.9955588458133795, 0.008961791560870043, 0.00957593115824365, 0.00661156953398563, 0.00923525377364973, 0.009249390395799043, 0.24042263107189882, 0.16445085161297515, 0.2535426179128502, 0.008592542928105708, 0.01586436006051744, 0.008076874963160846, 0.010290404254055504, 0.26766945314689605, 0.24514603130506282, 0.02193289657459936, 0.010314547715204524, 0.3491460454491454, 0.008140494508208553, 0.1520979715914838, 0.17593010701650327, 0.16693814682059344, 0.4375995476433522, 0.005943115763853319, 0.011904749815481765, 0.010618721436013605, 0.35518380220115064, 0.032530699479207316, 0.006423832602958731, 0.1905574030613303, 0.21217782510527516, 0.006282368893110462, 0.0052935471840367876, 0.2023025959139748, 0.3688738078686453, 0.0036838230211210204, 0.23985060970685657, 0.003787157493797269, 0.005976020058451102, 0.9909456908086471, 0.16636404422031098, 0.2239666273155771, 0.009389412165838653, 0.3533792183039677, 0.008962333233714481, 0.16957424673708255, 0.005324873897349033, 0.3055757069212901, 0.48172673118727993, 0.005144117030033004, 0.009661546549756594, 0.30247356056131147, 0.012105385431942567, 0.19600963342187708, 0.2546666105777996, 0.1787742250738999, 0.19374748124489546, 0.009077970061281838, 0.25345104066417634, 0.009056997015181367, 0.6863638790605451, 0.004959379913521333, 0.9968448275408179, 0.004666239884507274, 0.012156669793689352, 0.3408200678886372, 0.32254862833548925, 0.019518983001794957, 0.01838823882624471, 0.213814451499306, 0.17368918541762243, 0.004312282386478135, 0.20111609099049887, 0.20532650211522258, 0.1972476350795981, 0.9838239490615297, 0.17491052941029755, 0.0044510915370895646, 0.009167034157514053, 0.0042837050349720275, 0.30908380076708686, 0.007743410956355751, 0.005740128731733316, 0.019952147007580873, 0.909802263160721, 0.18484521546680946, 0.20802442513311054, 0.23941530558229385, 0.4106670080198179, 0.00410495924877602, 0.004927413427484521, 0.9965373099684911, 0.013406174497139982, 0.5204703965234301, 0.0075910257582018515, 0.005338081126285397, 0.19844489404611043, 0.003977020249339459, 0.16844055302362107, 0.19745847479103543, 0.00322079381950218, 0.011280460492453187, 0.246441403033776, 0.006226412493454384, 0.020623352117354134, 0.0047480272031429, 0.007191664803310654, 0.008663776552770041, 0.005323829216565635, 0.3358435756651621, 0.006615487107705095, 0.63563543894652, 0.2702460573187266, 0.007427332591303123, 0.005801813790743318, 0.17403982430597556, 0.17735185497294606, 0.013261220448985856, 0.00987644093264531, 0.009164866403527702, 0.00986464723280284, 0.007905831284566744, 0.7710551544052601, 0.008895051925278693, 0.2229576892424324, 0.010215162398482887, 0.00658284641850859, 0.007604319206537596, 0.010992210686859398, 0.0062406504495806335, 0.2054149883078515, 0.010636439271843037, 0.01247558552012472, 0.007865782685516938, 0.16118256005881676, 0.1766473421209318, 0.1667233160611317, 0.23984903281176084, 0.5687488372434093, 0.1561048911733673, 0.007348098522164243, 0.010079859027928479, 0.9970389810555951, 0.2881203059453796, 0.004141243998450241, 0.9421869158925842, 0.005198409746488786, 0.0068218432504811135, 0.23632386552420884, 0.027742630199516317, 0.3325500264693011, 0.011352065836461967, 0.007166850006437557, 0.997074895786384, 0.2000318957954886, 0.0042245183603762965, 0.17184612342420058, 0.00999354543719833, 0.00682385917534698, 0.2396061729315754, 0.009792191011099963, 0.01110825895821769, 0.21267996484323298, 0.2762108773304799, 0.004140442933462073, 0.9352341359539555, 0.004446045745204174, 0.43907745890476024, 0.007094587251966701, 0.025262501908765337, 0.0047588738472597635, 0.24156386278519143, 0.46922057508146625, 0.2669758643939273, 0.03496973722251171, 0.24745645857618243, 0.016671827852794207, 0.0036511498781893388, 0.013079501895717875, 0.18322118386427266, 0.17792331971917863, 0.009696545581499334, 0.1930030796322159, 0.30295706122211663, 0.25181108053562284, 0.006009438470556006, 0.009288937448016055, 0.21583700449238097, 0.004448486267635338, 0.29272682523322835, 0.3207755374479811, 0.2974444909807651, 0.006103771516620231, 0.004936728796045631, 0.024659983170482194, 0.011458757055483895, 0.587061737175163, 0.8236870484532861, 0.8703585608653144, 0.27372176326335984, 0.236837185140035, 0.2661913451134975, 0.004774985797121889, 0.29847503961736793, 0.32823623455092255, 0.4826602850792383, 0.16227914550287914, 0.16788472538861682, 0.007570678885647513, 0.006683168378181295, 0.005050747192313273, 0.17813795726172857, 0.19883703375558864, 0.006748325679875732, 0.011550681579205508, 0.4140336990256528, 0.1707675399516016, 0.014523821154003243, 0.012077378549481984, 0.007592895347179785, 0.3303220844135424, 0.2951120566942687, 0.03262825131109196, 0.006386414124172289, 0.005324035175137939, 0.007023785491482946, 0.174702680675995, 0.007075744807493313, 0.9776698384943634, 0.004670892075405102, 0.17275726943564573, 0.0063266788084694325, 0.009534237917926104, 0.34989410941418064, 0.003921058503265889, 0.012126004124370284, 0.00834132317752656, 0.0053259255319415815, 0.22398173138299504, 0.17373466768967544, 0.006984460709756763, 0.007802056100979613, 0.2969700698692031, 0.0068915847051046275, 0.3226180509674869, 0.25466380573488057, 0.004995452170817971, 0.1722442233991462, 0.9983859512580173, 0.20945070043905153, 0.004805691573598287, 0.1749741837320967, 0.9716527170974616, 0.013430789198754067, 0.25347481025067764, 0.01507777595284057, 0.006563510281366018, 0.011536839490855868, 0.17399687584909515, 0.21709358387255706, 0.01036909111697336, 0.2414685698578911, 0.20820806461629623, 0.21146240727880428, 0.23607745346447317, 0.00516510113301357, 0.00954550220967803, 0.24274839554449054, 0.009307275095577971, 0.24926850607197007, 0.16048950647000929, 0.4099322594933995, 0.00809680925969137, 0.00854638695584361, 0.23148446877269996, 0.181679755216317, 0.00485423108139101, 0.006362692632480362, 0.01200537351872443, 0.008969380812634266, 0.9954572853973647, 0.00449509397059063, 0.2727672934397484, 0.022254462258237333, 0.41650535635907865, 0.1798770694946032, 0.008209927129997607, 0.21640313414180637, 0.1799518637361034, 0.007325490627165424, 0.32279920390682226, 0.004502817767771151, 0.0047024742235369146, 0.32015274790249615, 0.007206071871120759, 0.3196191816414271, 0.18713660278185562, 0.011373366918086667, 0.3576269504141488, 0.005627732274151172, 0.19823003081641827, 0.2565491037053863, 0.00603940424601797, 0.007136937066357165, 0.006911792073269108, 0.30368276540870454, 0.20908370922189928, 0.16788879181405092, 0.21873578815721412, 0.01998602709579267, 0.014178891026468476, 0.005699440589310302, 0.18345378272378804, 0.007040115166470498, 0.1895138275456971, 0.007165341770003404, 0.006441212546798091, 0.21646888634954847, 0.16952849208587104, 0.18784600297571907, 0.3611627269732637, 0.29998139140620683, 0.017671241876031432, 0.008188539471435866, 0.24447608137585516, 0.24471980137075716, 0.006810565689577014, 0.003942514023768968, 0.3618272379695579, 0.1849962394035117, 0.011659406964882952, 0.017642210119132008, 0.00396348192242424, 0.01433543199018947, 0.21294886936956778, 0.16897295945048244, 0.20998757250597871, 0.005166328644094868, 0.3834164257690774, 0.3123591151617232, 0.014032836649442092, 0.014410011017032395, 0.012163923896041826, 0.2825272686207173, 0.006952835327075014, 0.17294113088004245, 0.18152062288418724, 0.01968227634251617, 0.012329154754399307, 0.17493947651666186, 0.99679569619632, 0.006469323010190178, 0.17328391722938263, 0.0070059013810978305, 0.16414937907679006, 0.18174753829830126, 0.008549981308799045, 0.01591976300059348, 0.010150774364739205, 0.005364819722086146, 0.006030385950569402, 0.9890162416656783, 0.005208411325295677, 0.8380789646602971, 0.004240530877944916, 0.006231250314270747, 0.20440105264162245, 0.0050279653271585335, 0.006718528547650149, 0.011549906953027185, 0.007885340068271149, 0.206344151483904, 0.24203006879667627, 0.010397130041347994, 0.006369646218887241, 0.23422007107387363, 0.3013994893204869, 0.049013589654633975, 0.004428892801875586, 0.009355231556011269, 0.17557165558345594, 0.1851834193775153, 0.008267967811214872, 0.2979321436826009, 0.2513875359415263, 0.17191530774449218, 0.011611420715081797, 0.18557917308699481, 0.006998242749272976, 0.24853225518811167, 0.9712412118737255, 0.9993435142629785, 0.17483034795833347, 0.0162717116886799, 0.4224346692246709, 0.008953894602886021, 0.25695967675077047, 0.012627597184680647, 0.005108523949349245, 0.012873252381568313, 0.005854933533928849, 0.009060009565456486, 0.006098392886928119, 0.014809366496928007, 0.012334007254743267, 0.00732035677753991, 0.20757409428791262, 0.005422297259006137, 0.20988248857045594, 0.33709846273136024, 0.011400582250189478, 0.22793420985517032, 0.38334737516869866, 0.2619998505217078, 0.010531448067737979, 0.009383137422939884, 0.7465623662110874, 0.008666692974428881, 0.017549375285150885, 0.23283086131422903, 0.01826655632635576, 0.17279874129631478, 0.1774864026349266, 0.17689244918415972, 0.9853933878356873, 0.18707659262105067, 0.005331687174503077, 0.004910978832852255, 0.0059807182821367474, 0.2712003948867075, 0.007475171340358006, 0.00790202360302009, 0.00680401916609541, 0.35904511615340867, 0.006552199143975743, 0.009166083119381593, 0.18092081897757523, 0.3173434450037378, 0.2602570795935625, 0.006834842904075607, 0.18882141247204912, 0.4716258204941413, 0.9949674463789664, 0.17237288253117544, 0.020483129887835294, 0.0061410158453414155, 0.2950061558666513, 0.0052917259296701375, 0.007507621744182792, 0.012659563433678005, 0.9434405056250916, 0.1902386026801559, 0.007003704056684751, 0.27035425903352023, 0.23579941903030074, 0.012337759574745581, 0.4552250160871188, 0.19745990782328687, 0.3217040723291086, 0.17640270910141262, 0.35602802376754017, 0.006899621492024428, 0.2171996409679931, 0.008011261488410136, 0.010482301409170126, 0.01120725017713018, 0.0110600222014175, 0.00948378281616161, 0.9345106479404821, 0.006650312382251797, 0.6850700577915771, 0.2139130992410257, 0.17106383235126246, 0.008356516831066464, 0.35747510036945646, 0.39548745124989887, 0.17845626008720072, 0.009336520118140455, 0.009915192883440326, 0.005312236792046946, 0.3466593163435603, 0.2717173889082341, 0.00651372968827805, 0.006433621104413137, 0.2049231709576348, 0.2676203168653478, 0.19600380809986534, 0.23364614660387945, 0.009057197374032416, 0.005548020736718638, 0.6799240421795414, 0.9939561160888171, 0.16186676224259264, 0.2654253759357441, 0.006927819515073649, 0.17075858081367504, 0.1732300764835811, 0.20904679491909314, 0.011068553932841006, 0.004386078638229597, 0.9967393990471796, 0.21589611810637893, 0.007132192807255365, 0.27733330587856564, 0.007394931753950581, 0.009047902094711196, 0.20821562939919824, 0.01775758604704186, 0.012991445548277292, 0.005846368874174694, 0.007539615339262006, 0.0056051799715036, 0.036720500185084846, 0.005049564234094474, 0.018058960739000974, 0.009155341799606998, 0.008767713609439318, 0.19120007139818948, 0.22523098392104357, 0.013923398121375316, 0.26818383079765706, 0.9382399944258091, 0.019286208732955994, 0.1531705263671105, 0.008206818849426062, 0.014629684983128105, 0.20687400902583103, 0.3127227968180975, 0.9984410531889831, 0.1749229791652982, 0.004597629585183141, 0.1704537205472478, 0.006897446765224851, 0.00700568314324038, 0.008179953228154003, 0.003703233620636334, 0.005353430980919276, 0.9694248950150215, 0.32523051266231195, 0.2524596553524505, 0.03148119172795096, 0.014663245632264696, 0.01095890442147118, 0.01656072465111856, 0.9588655097957488, 0.012616504311350753, 0.004915960198584235, 0.16590204236112496, 0.21305301235271357, 0.004684803599348508, 0.006268127285458271, 0.005530333511957844, 0.43731027397798833, 0.014588254394382381, 0.012006139504754387, 0.005169528598750038, 0.16909809245083243, 0.015403701802247153, 0.008244084737232147, 0.01233165626015029, 0.007886817427012714, 0.3139396423104299, 0.2558935957199939, 0.18580778629506867, 0.23890215278493232, 0.009035781424867611, 0.011936796610675952, 0.004971299114056242, 0.008260657467535282, 0.00665929437856076, 0.0058618571071862476, 0.0041416872524146124, 0.21688009857865684, 0.005507980954694814, 0.007518160412754524, 0.007534540976145607, 0.3003276194294862, 0.9910056232742805, 0.012460529294104643, 0.004787875470206681, 0.015105262624873004, 0.006857681411075279, 0.005134561353832133, 0.006370582960962618, 0.284428853499855, 0.9910323568260027, 0.21663106033585877, 0.006317141021209737, 0.2231951988684448, 0.2256727691746234, 0.006517908281407334, 0.2672528959054641, 0.33477653536043284, 0.1794440626783032, 0.1776467324297244, 0.015367320163257838, 0.01380982725337516, 0.004755139065609833, 0.005220184124796407, 0.2816471636665002, 0.009581461083601913, 0.01920442021469439, 0.25056450727709556, 0.4180862597551481, 0.004653995657088424, 0.006228107254331308, 0.004981717100311764, 0.012628564334588005, 0.006335175850098568, 0.015155143077732452, 0.0080032322466152, 0.0042346161047456905, 0.009715471113606898, 0.22847815870343346, 0.17724330049499212, 0.24557673129641477, 0.2482105094364345, 0.005060475320474658, 0.006874856461871765, 0.16637693600679987, 0.9780325245287251, 0.008239676054120614, 0.2656950635931301, 0.15829728567674872, 0.015501550399646435, 0.004755769653510261, 0.20395632075995962, 0.004245796930656998, 0.0032624004862291675, 0.22849225692993974, 0.44006035121969006, 0.0062652560865186875, 0.25721609296654935, 0.16995150562630437, 0.007249823899877227, 0.2995184516973718, 0.1880521695497433, 0.18008408884637883, 0.0067343116064199435, 0.0070636276872105596, 0.01592070277772427, 0.014289042999864079, 0.013360821832423412, 0.36496105508880317, 0.004334281068930098, 0.006256190336769569, 0.012026836694678479, 0.00599025070256466, 0.016371990184360235, 0.02557272403450745, 0.0030062390200161354, 0.2315687531750981, 0.007188637934487913, 0.996960296392299, 0.40887307560143243, 0.01422381885493804, 0.004861253620521174, 0.9910657430366223, 0.2607110640433318, 0.2545667539164277, 0.01801429804687242, 0.0107269047634259, 0.38132197400725676, 0.3458901652570743, 0.019668920977855973, 0.1927437933908138, 0.006698333798954465, 0.005302460566658594, 0.9981280438983193, 0.9907601245130657, 0.01197947212125572, 0.005902566093930738, 0.010048273368212266, 0.9766626520343165, 0.029612455608357117, 0.2965515971690431, 0.0040941474250947765, 0.26904860225010657, 0.009731101944436741, 0.008476351645630374, 0.007749031276847898, 0.004251314923540734, 0.014017610931210322, 0.009697413338596252, 0.023630112061553164, 0.006541154702973337, 0.011924914254497578, 0.007918022146846974, 0.22638065127163207, 0.1847222177416518, 0.010690883618196242, 0.0075921316715542074, 0.2774439212305101, 0.010069537846921418, 0.019268910062771552, 0.2674596251893787, 0.008704299532588599, 0.009255132467989223, 0.16492608325770566, 0.017225588247692235, 0.011111733239925668, 0.2882733014549471, 0.010221837073619953, 0.8448469692309675, 0.009546319878809384, 0.005419875538866846, 0.007432929174245206, 0.008859275890328151, 0.005524638310444536, 0.00994201998319133, 0.008510409318759108, 0.3384315016394708, 0.19341065698311094, 0.18143612900575762, 0.30906826410762755, 0.008096052850573028, 0.23032102370169572, 0.007007030790514856, 0.9405385106262847, 0.9080339878962385, 0.007620357104815156, 0.007772008063448225, 0.013946138007487886, 0.004663607881957579, 0.005023002989139701, 0.3874825847826056, 0.006308120809758961, 0.0097489549130277, 0.27613468381664436, 0.0045016652034249845, 0.006284494030418339, 0.25606915503550254, 0.17480963352358364, 0.004183978651073416, 0.2573502627844016, 0.005165689043898694, 0.9474453295434959, 0.22008341219782268, 0.2838293105012315, 0.02200365766534155, 0.01548785013589918, 0.23580574075401733, 0.01079352711831872, 0.004666422021923282, 0.4050102337013799, 0.012341033024031679, 0.011950790676944621, 0.00961746448866126, 0.007976308823662731, 0.24236930460383652, 0.9786739201170696, 0.004796311166118804, 0.24488771976497675, 0.006850333008973041, 0.006212564264671769, 0.9326625825863346, 0.21273113527503457, 0.005199842442112693, 0.18696354476253038, 0.008460343067294755, 0.007926598532345005, 0.0036166997272287387, 0.012152445927321372, 0.005961190927257554, 0.004120703572477132, 0.009255216996983985, 0.7639716723443013, 0.005123936400567221, 0.007236935609866868, 0.3748586490122797, 0.009498093798364186, 0.008042317586876863, 0.01516891157071984, 0.1875291288291437, 0.3927815831113064, 0.2714153574651028, 0.011322252341659013, 0.004854091955735896, 0.00683476653396137, 0.009141269758636378, 0.005010808087874389, 0.010190101399981482, 0.17015820255656808, 0.3058021084751211, 0.02288914683184324, 0.007360489236514213, 0.48954689274977703, 0.00897512389379579, 0.00785355140179374, 0.17928213486015654, 0.01073281380222125, 0.2873992295010296, 0.010539416474942715, 0.1523297131825501, 0.18568089370401553, 0.01039775350392492, 0.005196199150746102, 0.15712449794556604, 0.21481230874507554, 0.5250479284692573, 0.007017146724938844, 0.010275057939354751, 0.17061327813016774, 0.012043049529201159, 0.9819387597911651, 0.21336062602158878, 0.9917891546564652, 0.20334973976845222, 0.006248690619445764, 0.004477014620491427, 0.004735389741843027, 0.03203455959597649, 0.007320658005763985, 0.2851186470531877, 0.007596926877826683, 0.00983589711807622, 0.009797150899404779, 0.009925188150700724, 0.004771520760548131, 0.004757020482579042, 0.007182665131965579, 0.0051642306335845396, 0.007585980112316681, 0.009998414740698592, 0.0057075853181405055, 0.004208755755354883, 0.2826511041423402, 0.007906779477708306, 0.012442988433288227, 0.38628452755107845, 0.004666084798607541, 0.24696308276252552, 0.007568205490516847, 0.4310974525861096, 0.22831234125344593, 0.007343586744520189, 0.23103087433795988, 0.009175012160026658, 0.3444985185735755, 0.22867565574840631, 0.00721281305972387, 0.20762190839970607, 0.004541807515157912, 0.004840551193000819, 0.004391128794982895, 0.2412527669518611, 0.008327392037550715, 0.1959855750513571, 0.3393150454425675, 0.006036758744676996, 0.00719609359935617, 0.006459926502499315, 0.0053680140481193305, 0.007038544000584357, 0.9977288261088488, 0.004940079233562608, 0.28861836006658, 0.0082638722795547, 0.012770178792615581, 0.23251353044666706, 0.004715606244281951, 0.17616715200686434, 0.005433468151254128, 0.009744221897533543, 0.1698998134578653, 0.3077148026993536, 0.36980759393118134, 0.6619264722019553, 0.011395048799450174, 0.006369769812773751, 0.23373186016910724, 0.015112503290556118, 0.297248381836187, 0.007271006986105881, 0.04477109840405466, 0.01036805333959158, 0.9186939397595968, 0.2089480389751, 0.0106418106604328, 0.240640591087726, 0.01077160106399008, 0.17831170737351693, 0.22493592657086098, 0.2935823188535771, 0.007730101187407169, 0.0024825651770295034, 0.022636798235761996, 0.007294167525591802, 0.22267133733310446, 0.007091926085776707, 0.005110270511612869, 0.2859359326110624, 0.004660324329658793, 0.011762339763380814, 0.00693425228745192, 0.29115686554290604, 0.007832174612853888, 0.20623910168336118, 0.012840929480783306, 0.2285273930173826, 0.004632095208981711, 0.026590851410057764, 0.2097180260510195, 0.004919492514684044, 0.9951309887156012, 0.28341577606593604, 0.005451521358347235, 0.00800714471603171, 0.004586171479246269, 0.0043086106958580275, 0.007368458978061577, 0.9736469646456714, 0.308127635993128, 0.05165741532339137, 0.00661975700193175, 0.23204872012292, 0.2186793537820525, 0.012690265447160943, 0.16531929253099, 0.022130543409548675, 0.27413817902246995, 0.018251216036426255, 0.009713959883850234, 0.21335927392531767, 0.009015080226473564, 0.00643700127591343, 0.009523929644898866, 0.01395643799836792, 0.007474899263679456, 0.6156525991828206, 0.009789111822394368, 0.007387102411704309, 0.38913020652686664, 0.004704825726590548, 0.010679688259307034, 0.18083219271528295, 0.005344824697953618, 0.025419705454213286, 0.24461242846529496, 0.005190543288839585, 0.18411228441247202, 0.23751506294927124, 0.006062891972124167, 0.3100105202084581, 0.20006869333615634, 0.24076317001309983, 0.3826251898997129, 0.2045315642439532, 0.004944901550275608, 0.0041801518415627995, 0.004954507791629437, 0.1938184174761868, 0.21941347912177422, 0.005607477136410677, 0.010956001902601348, 0.00402178325842618, 0.9938315413133803, 0.20262510574711112, 0.28642104921015415, 0.15713655627469159, 0.2028894464449782, 0.006221849774153283, 0.005923108119490262, 0.011574316127451391, 0.006523337224647454, 0.2556987441735205, 0.33817192155619946, 0.014762869747428402, 0.012897515523205432, 0.31823313694289473, 0.3362765874758051, 0.0072105229252375155, 0.004985500535980839, 0.009408425352297932, 0.33163155512739206, 0.21401250411834769, 0.1676172371615076, 0.18016736817916965, 0.187627113618024, 0.010903723552152711, 0.016098375968651574, 0.008013469248451966, 0.010352737522440512, 0.2807495142381636, 0.5068034115487373, 0.27054402016371604, 0.20600147332639945, 0.004613272689237001, 0.41329422957214146, 0.9978947137378307, 0.32651745764391005, 0.17266304103951055, 0.02493633749257757, 0.6434773626263919, 0.2233638791352474, 0.23133878858912327, 0.1907682951650621, 0.013401123171751949, 0.4123416271697418, 0.227531562692793, 0.17111550020284852, 0.1836726906432556, 0.17206716180189577, 0.014874485004753525, 0.2570695139834958, 0.2276329711174719, 0.008895065626772189, 0.9956880457655857]\n"
     ]
    }
   ],
   "source": [
    "#Combine metrics from all models into lists for each metric type\n",
    "ensemble_accuracies = [NN_accuracy[0], MLP_accuracy[0], float(LR_accuracy), float(RFC_accuracy)]\n",
    "ensemble_f1 = [NN_f1[0], MLP_f1[0], float(LR_f1), float(RFC_f1)]\n",
    "ensemble_precision = [NN_precision[0], MLP_precision[0], LR_precision, RFC_precision]\n",
    "ensemble_recall = [NN_recall[0], MLP_recall[0], LR_recall, RFC_recall]\n",
    "\n",
    "#Get errors of each metric in ensemble metrics lists by subtracting each metric from 1\n",
    "ensemble_accuracy_errors = [1-acc for acc in ensemble_accuracies]\n",
    "ensemble_f1_errors = [1-f1 for f1 in ensemble_f1]\n",
    "ensemble_precision_errors = [1-prec for prec in ensemble_precision]\n",
    "ensemble_recall_errors = [1-rec for rec in ensemble_recall]\n",
    "\n",
    "# Combine the errors into a list where each element is the combined error for a given model\n",
    "summed_errors = [\n",
    "    acc_err + f1_err + prec_err + rec_err \n",
    "    for acc_err, f1_err, prec_err, rec_err \n",
    "    in zip(ensemble_accuracy_errors, ensemble_f1_errors, ensemble_precision_errors, ensemble_recall_errors)\n",
    "]\n",
    "\n",
    "#Take the inverse of errors, accounting for cases where error is 0\n",
    "inverse_summed_errors = [1/err if err != 0 else 0 for err in summed_errors]\n",
    "\n",
    "#Normalize the errors by dividing each model's summed error by the total to get weights\n",
    "total_inverse_summed_errors = sum(inverse_summed_errors)\n",
    "weights = [inv_err/total_inverse_summed_errors for inv_err in inverse_summed_errors]\n",
    "\n",
    "#Take the predictions we made with each of the models on the check ensemble set, and using the weights, combine into one probability for each data point\n",
    "ensemble_predictions = [\n",
    "    float(NN_check_probabilities[i][0] * weights[0] + \n",
    "          MLP_check_probabilities[i] * weights[1] +\n",
    "          LR_check_probabilities[i] * weights[2] +\n",
    "          RFC_check_probabilities[i] * weights[3])\n",
    "    for i in range(len(NN_check_probabilities))\n",
    "]\n",
    "\n",
    "print(ensemble_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8df9cb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9600135165577833, 0.956127506195089, 0.9488060373958098, 0.9630547420590223]\n",
      "0.7736720554272517\n",
      "0.9970238095238095\n",
      "0.6320754716981132\n",
      "[0.6578005115089514]\n",
      "[0.6388746803069054]\n",
      "0.6332480818414322\n",
      "0.6644501278772379\n"
     ]
    }
   ],
   "source": [
    "#Debugging print statements to double check metrics (can delete)\n",
    "print(ensemble_accuracies)\n",
    "print(ensemble_f1)\n",
    "print(ensemble_precision)\n",
    "print(ensemble_recall)\n",
    "\n",
    "print((NN_recall))\n",
    "print((MLP_recall))\n",
    "print((LR_recall))\n",
    "print((RFC_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f7008ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.9608\n",
      "Ensemble F1 Score: 0.7736720554272517\n",
      "Ensemble Precision: 0.9970238095238095\n",
      "Ensemble Recall: 0.6320754716981132\n"
     ]
    }
   ],
   "source": [
    "#Set the probability threshold for predicting if a data point has diabetes or not (0.6-0.65 tend to have the best overall results)\n",
    "threshold = 0.6\n",
    "\n",
    "#To determine ensemble metrics, change from probabilities to discrete class predictions\n",
    "ensemble_y_pred = [1 if prob > threshold else 0 for prob in ensemble_predictions]\n",
    "\n",
    "#Calculate metrics for the combined ensemble method\n",
    "ensemble_accuracy = accuracy_score(y_check_ensemble, ensemble_y_pred)\n",
    "ensemble_f1 = f1_score(y_check_ensemble, ensemble_y_pred)\n",
    "ensemble_precision = precision_score(y_check_ensemble, ensemble_y_pred)\n",
    "ensemble_recall = recall_score(y_check_ensemble, ensemble_y_pred)\n",
    "\n",
    "print(\"Ensemble Accuracy:\", ensemble_accuracy)\n",
    "print(\"Ensemble F1 Score:\", ensemble_f1)\n",
    "print(\"Ensemble Precision:\", ensemble_precision)\n",
    "print(\"Ensemble Recall:\", ensemble_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "25c77e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Value</th>\n",
       "      <th>NN Probabilities</th>\n",
       "      <th>MLP Probabilities</th>\n",
       "      <th>LR Probabilities</th>\n",
       "      <th>RFC Probabilities</th>\n",
       "      <th>Ensemble Probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34031</td>\n",
       "      <td>0.12035</td>\n",
       "      <td>0.14730</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.28075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>1</td>\n",
       "      <td>0.56280</td>\n",
       "      <td>0.36119</td>\n",
       "      <td>0.68379</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.50680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34042</td>\n",
       "      <td>0.10775</td>\n",
       "      <td>0.11187</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.27054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>0</td>\n",
       "      <td>0.24087</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.03512</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.20600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01732</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40868</td>\n",
       "      <td>0.45633</td>\n",
       "      <td>0.31378</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.41329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99630</td>\n",
       "      <td>0.99557</td>\n",
       "      <td>0.99969</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.99789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>0</td>\n",
       "      <td>0.33397</td>\n",
       "      <td>0.22241</td>\n",
       "      <td>0.26026</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.32652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>0</td>\n",
       "      <td>0.13760</td>\n",
       "      <td>0.00871</td>\n",
       "      <td>0.01226</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.17266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04541</td>\n",
       "      <td>0.03162</td>\n",
       "      <td>0.02602</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>1</td>\n",
       "      <td>0.51281</td>\n",
       "      <td>0.50745</td>\n",
       "      <td>0.46413</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.64348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>0</td>\n",
       "      <td>0.26958</td>\n",
       "      <td>0.06174</td>\n",
       "      <td>0.02671</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.22336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>0</td>\n",
       "      <td>0.20308</td>\n",
       "      <td>0.04261</td>\n",
       "      <td>0.17508</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.23134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>0</td>\n",
       "      <td>0.16978</td>\n",
       "      <td>0.01178</td>\n",
       "      <td>0.05557</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.19077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04911</td>\n",
       "      <td>0.00086</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>0</td>\n",
       "      <td>0.39466</td>\n",
       "      <td>0.38700</td>\n",
       "      <td>0.40892</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.41234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>0</td>\n",
       "      <td>0.22690</td>\n",
       "      <td>0.06251</td>\n",
       "      <td>0.10193</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.22753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>0</td>\n",
       "      <td>0.14692</td>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.00184</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.17112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>0</td>\n",
       "      <td>0.18424</td>\n",
       "      <td>0.00428</td>\n",
       "      <td>0.01071</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.18367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>0</td>\n",
       "      <td>0.14954</td>\n",
       "      <td>0.00126</td>\n",
       "      <td>0.00253</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.17207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00381</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.06798</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0</td>\n",
       "      <td>0.26415</td>\n",
       "      <td>0.11140</td>\n",
       "      <td>0.14088</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.25707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.29617</td>\n",
       "      <td>0.04748</td>\n",
       "      <td>0.02976</td>\n",
       "      <td>0.45170</td>\n",
       "      <td>0.22763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>0.03086</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>0.00198</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99592</td>\n",
       "      <td>0.98925</td>\n",
       "      <td>0.99679</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.99569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      True Value  NN Probabilities  MLP Probabilities  LR Probabilities  \\\n",
       "4975           0           0.34031            0.12035           0.14730   \n",
       "4976           1           0.56280            0.36119           0.68379   \n",
       "4977           0           0.34042            0.10775           0.11187   \n",
       "4978           0           0.24087            0.01394           0.03512   \n",
       "4979           0           0.01732            0.00005           0.00001   \n",
       "4980           0           0.40868            0.45633           0.31378   \n",
       "4981           1           0.99630            0.99557           0.99969   \n",
       "4982           0           0.33397            0.22241           0.26026   \n",
       "4983           0           0.13760            0.00871           0.01226   \n",
       "4984           0           0.04541            0.03162           0.02602   \n",
       "4985           1           0.51281            0.50745           0.46413   \n",
       "4986           0           0.26958            0.06174           0.02671   \n",
       "4987           0           0.20308            0.04261           0.17508   \n",
       "4988           0           0.16978            0.01178           0.05557   \n",
       "4989           0           0.04911            0.00086           0.00075   \n",
       "4990           0           0.39466            0.38700           0.40892   \n",
       "4991           0           0.22690            0.06251           0.10193   \n",
       "4992           0           0.14692            0.00077           0.00184   \n",
       "4993           0           0.18424            0.00428           0.01071   \n",
       "4994           0           0.14954            0.00126           0.00253   \n",
       "4995           0           0.00381            0.00007           0.06798   \n",
       "4996           0           0.26415            0.11140           0.14088   \n",
       "4997           0           0.29617            0.04748           0.02976   \n",
       "4998           0           0.03086            0.00123           0.00198   \n",
       "4999           1           0.99592            0.98925           0.99679   \n",
       "\n",
       "      RFC Probabilities  Ensemble Probabilities  \n",
       "4975            0.45170                 0.28075  \n",
       "4976            0.45170                 0.50680  \n",
       "4977            0.45170                 0.27054  \n",
       "4978            0.45170                 0.20600  \n",
       "4979            0.00000                 0.00461  \n",
       "4980            0.45170                 0.41329  \n",
       "4981            1.00000                 0.99789  \n",
       "4982            0.45170                 0.32652  \n",
       "4983            0.45170                 0.17266  \n",
       "4984            0.00000                 0.02494  \n",
       "4985            1.00000                 0.64348  \n",
       "4986            0.45170                 0.22336  \n",
       "4987            0.45170                 0.23134  \n",
       "4988            0.45170                 0.19077  \n",
       "4989            0.00000                 0.01340  \n",
       "4990            0.45170                 0.41234  \n",
       "4991            0.45170                 0.22753  \n",
       "4992            0.45170                 0.17112  \n",
       "4993            0.45170                 0.18367  \n",
       "4994            0.45170                 0.17207  \n",
       "4995            0.00000                 0.01487  \n",
       "4996            0.45170                 0.25707  \n",
       "4997            0.45170                 0.22763  \n",
       "4998            0.00000                 0.00890  \n",
       "4999            1.00000                 0.99569  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine probability predictions for each \n",
    "NN_probs = [prob[0] for prob in NN_check_probabilities]\n",
    "MLP_probs = MLP_check_probabilities.tolist()\n",
    "LR_probs = LR_check_probabilities.tolist()\n",
    "RFC_probs = RFC_check_probabilities.tolist()\n",
    "\n",
    "\n",
    "df_probs = pd.DataFrame({\n",
    "    \"True Value\": y_check_ensemble.values.ravel(),\n",
    "    \"NN Probabilities\": NN_probs,\n",
    "    \"MLP Probabilities\": MLP_probs,\n",
    "    \"LR Probabilities\": LR_probs,\n",
    "    \"RFC Probabilities\": RFC_probs,\n",
    "    \"Ensemble Probabilities\": ensemble_predictions\n",
    "})\n",
    "\n",
    "df_probs.tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "dc1584b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model  Accuracy  F1 Score  Precision  Recall\n",
      "0        NN   0.96001   0.78367    0.96910 0.65780\n",
      "1       MLP   0.95613   0.76228    0.94478 0.63887\n",
      "2        LR   0.94881   0.73146    0.86573 0.63325\n",
      "3       RFC   0.96305   0.79840    1.00000 0.66445\n",
      "4  Ensemble   0.96080   0.77367    0.99702 0.63208\n"
     ]
    }
   ],
   "source": [
    "#Combine the scores of each model (including ensemble) into a table for comparison\n",
    "metrics_data = {\n",
    "    'Model': ['NN', 'MLP', 'LR', 'RFC', 'Ensemble'],\n",
    "    'Accuracy': [NN_accuracy[0], MLP_accuracy[0], LR_accuracy, RFC_accuracy, ensemble_accuracy],\n",
    "    'F1 Score': [NN_f1[0], MLP_f1[0], LR_f1, RFC_f1, ensemble_f1],\n",
    "    'Precision': [NN_precision[0], MLP_precision[0], LR_precision, RFC_precision, ensemble_precision],\n",
    "    'Recall': [NN_recall[0], MLP_recall[0], LR_recall, RFC_recall, ensemble_recall]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_data)\n",
    "\n",
    "print(df_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
