{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f6c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c235962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   gender               100000 non-null  object \n",
      " 1   age                  100000 non-null  float64\n",
      " 2   hypertension         100000 non-null  int64  \n",
      " 3   heart_disease        100000 non-null  int64  \n",
      " 4   smoking_history      100000 non-null  object \n",
      " 5   bmi                  100000 non-null  float64\n",
      " 6   HbA1c_level          100000 non-null  float64\n",
      " 7   blood_glucose_level  100000 non-null  int64  \n",
      " 8   diabetes             100000 non-null  int64  \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b970b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.2</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>17.37</td>\n",
       "      <td>6.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>former</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Female</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0      Female  80.0             0              1           never  25.19   \n",
       "1      Female  54.0             0              0         No Info  27.32   \n",
       "2        Male  28.0             0              0           never  27.32   \n",
       "3      Female  36.0             0              0         current  23.45   \n",
       "4        Male  76.0             1              1         current  20.14   \n",
       "...       ...   ...           ...            ...             ...    ...   \n",
       "99995  Female  80.0             0              0         No Info  27.32   \n",
       "99996  Female   2.0             0              0         No Info  17.37   \n",
       "99997    Male  66.0             0              0          former  27.83   \n",
       "99998  Female  24.0             0              0           never  35.42   \n",
       "99999  Female  57.0             0              0         current  22.43   \n",
       "\n",
       "       HbA1c_level  blood_glucose_level  diabetes  \n",
       "0              6.6                  140         0  \n",
       "1              6.6                   80         0  \n",
       "2              5.7                  158         0  \n",
       "3              5.0                  155         0  \n",
       "4              4.8                  155         0  \n",
       "...            ...                  ...       ...  \n",
       "99995          6.2                   90         0  \n",
       "99996          6.5                  100         0  \n",
       "99997          5.7                  155         0  \n",
       "99998          4.0                  100         0  \n",
       "99999          6.6                   90         0  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a8957",
   "metadata": {},
   "source": [
    "## Data cleaning:\n",
    "- Removal of gender \"other\" and smoking \"no info\" due to lack of clarity on actual values (e.g. transgender, decline to state, etc).  Entries would likely not provide insight for feature correlation to category outcome.\n",
    "- Conversion of gender and smoking history to numeric values using dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a660fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 64184 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   gender               64184 non-null  int64  \n",
      " 1   age                  64184 non-null  float64\n",
      " 2   hypertension         64184 non-null  int64  \n",
      " 3   heart_disease        64184 non-null  int64  \n",
      " 4   smoking_history      64184 non-null  int64  \n",
      " 5   bmi                  64184 non-null  float64\n",
      " 6   HbA1c_level          64184 non-null  float64\n",
      " 7   blood_glucose_level  64184 non-null  int64  \n",
      " 8   diabetes             64184 non-null  int64  \n",
      "dtypes: float64(3), int64(6)\n",
      "memory usage: 4.9 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99992</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.34</td>\n",
       "      <td>6.5</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99993</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.69</td>\n",
       "      <td>3.5</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64184 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease  smoking_history    bmi  \\\n",
       "0           1  80.0             0              1                0  25.19   \n",
       "2           0  28.0             0              0                0  27.32   \n",
       "3           1  36.0             0              0                1  23.45   \n",
       "4           0  76.0             1              1                1  20.14   \n",
       "5           1  20.0             0              0                0  27.32   \n",
       "...       ...   ...           ...            ...              ...    ...   \n",
       "99992       1  26.0             0              0                0  34.34   \n",
       "99993       1  40.0             0              0                0  40.69   \n",
       "99997       0  66.0             0              0                3  27.83   \n",
       "99998       1  24.0             0              0                0  35.42   \n",
       "99999       1  57.0             0              0                1  22.43   \n",
       "\n",
       "       HbA1c_level  blood_glucose_level  diabetes  \n",
       "0              6.6                  140         0  \n",
       "2              5.7                  158         0  \n",
       "3              5.0                  155         0  \n",
       "4              4.8                  155         0  \n",
       "5              6.6                   85         0  \n",
       "...            ...                  ...       ...  \n",
       "99992          6.5                  160         0  \n",
       "99993          3.5                  155         0  \n",
       "99997          5.7                  155         0  \n",
       "99998          4.0                  100         0  \n",
       "99999          6.6                   90         0  \n",
       "\n",
       "[64184 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataValDict = {'gender': {'Male': 0, 'Female': 1, 'Other': 3}, 'smoking_history': {'never': 0, 'current': 1, 'ever': 2, 'former': 3, 'not current': 4}}\n",
    "\n",
    "#Original file is saved as original data.  Df will be 'cleaned' file.\n",
    "df = data[data['gender'] != 'Other']\n",
    "df = data[data['smoking_history'] != 'No Info']\n",
    "\n",
    "df = df.replace(dataValDict)\n",
    "df['gender'] = pd.to_numeric(df['gender'])\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee9dec",
   "metadata": {},
   "source": [
    "## Training and Test set creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d6a106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41428, 8), (17756, 8))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split features from (diabetes) label\n",
    "\n",
    "features = ['gender','age','hypertension','heart_disease','smoking_history', 'bmi','HbA1c_level','blood_glucose_level']\n",
    "\n",
    "df_check_ensemble = df.sample(5000)\n",
    "df = df.drop(df_check_ensemble.index)\n",
    "\n",
    "\n",
    "X = df.loc[:, features]\n",
    "y = df.loc[:, ['diabetes']]\n",
    "\n",
    "X_check_ensemble = df_check_ensemble.loc[:, features]\n",
    "y_check_ensemble = df_check_ensemble.loc[:, ['diabetes']]\n",
    "#Data will be shuffled before split by default. No stratification. Test size = 30% of set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size = .70)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8b3f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create np array versions of test and train data\n",
    "X_trn_np = X_train.to_numpy() \n",
    "X_tst_np = X_test.to_numpy() \n",
    "y_trn_np = y_train.to_numpy() \n",
    "y_tst_np = y_test.to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9980ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "746/746 [==============================] - 4s 2ms/step - loss: 0.2131 - accuracy: 0.9062 - val_loss: 0.0534 - val_accuracy: 0.9264 - lr: 0.0010\n",
      "Epoch 2/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0475 - accuracy: 0.9393 - val_loss: 0.0498 - val_accuracy: 0.9430 - lr: 0.0010\n",
      "Epoch 3/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0443 - accuracy: 0.9407 - val_loss: 0.0377 - val_accuracy: 0.9498 - lr: 0.0010\n",
      "Epoch 4/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0436 - accuracy: 0.9415 - val_loss: 0.0382 - val_accuracy: 0.9481 - lr: 0.0010\n",
      "Epoch 5/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0420 - accuracy: 0.9425 - val_loss: 0.0377 - val_accuracy: 0.9503 - lr: 0.0010\n",
      "Epoch 6/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0409 - accuracy: 0.9434 - val_loss: 0.0371 - val_accuracy: 0.9491 - lr: 0.0010\n",
      "Epoch 7/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0410 - accuracy: 0.9441 - val_loss: 0.0395 - val_accuracy: 0.9481 - lr: 0.0010\n",
      "Epoch 8/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0405 - accuracy: 0.9442 - val_loss: 0.0346 - val_accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 9/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0395 - accuracy: 0.9456 - val_loss: 0.0379 - val_accuracy: 0.9455 - lr: 0.0010\n",
      "Epoch 10/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0397 - accuracy: 0.9456 - val_loss: 0.0351 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 11/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0391 - accuracy: 0.9453 - val_loss: 0.0360 - val_accuracy: 0.9517 - lr: 0.0010\n",
      "Epoch 12/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0392 - accuracy: 0.9463 - val_loss: 0.0349 - val_accuracy: 0.9544 - lr: 0.0010\n",
      "Epoch 13/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0394 - accuracy: 0.9453 - val_loss: 0.0357 - val_accuracy: 0.9546 - lr: 0.0010\n",
      "Epoch 14/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0365 - accuracy: 0.9492 - val_loss: 0.0352 - val_accuracy: 0.9491 - lr: 5.0000e-04\n",
      "Epoch 15/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0373 - accuracy: 0.9477 - val_loss: 0.0338 - val_accuracy: 0.9517 - lr: 5.0000e-04\n",
      "Epoch 16/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0374 - accuracy: 0.9471 - val_loss: 0.0346 - val_accuracy: 0.9479 - lr: 5.0000e-04\n",
      "Epoch 17/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0362 - accuracy: 0.9487 - val_loss: 0.0331 - val_accuracy: 0.9541 - lr: 5.0000e-04\n",
      "Epoch 18/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0364 - accuracy: 0.9485 - val_loss: 0.0327 - val_accuracy: 0.9524 - lr: 5.0000e-04\n",
      "Epoch 19/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0363 - accuracy: 0.9484 - val_loss: 0.0329 - val_accuracy: 0.9517 - lr: 5.0000e-04\n",
      "Epoch 20/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0361 - accuracy: 0.9491 - val_loss: 0.0327 - val_accuracy: 0.9539 - lr: 5.0000e-04\n",
      "Epoch 21/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0367 - accuracy: 0.9485 - val_loss: 0.0342 - val_accuracy: 0.9496 - lr: 5.0000e-04\n",
      "Epoch 22/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0365 - accuracy: 0.9480 - val_loss: 0.0335 - val_accuracy: 0.9508 - lr: 5.0000e-04\n",
      "Epoch 23/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0368 - accuracy: 0.9475 - val_loss: 0.0340 - val_accuracy: 0.9491 - lr: 5.0000e-04\n",
      "Epoch 24/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0347 - accuracy: 0.9501 - val_loss: 0.0332 - val_accuracy: 0.9493 - lr: 2.5000e-04\n",
      "Epoch 25/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0348 - accuracy: 0.9506 - val_loss: 0.0325 - val_accuracy: 0.9522 - lr: 2.5000e-04\n",
      "Epoch 26/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0349 - accuracy: 0.9504 - val_loss: 0.0322 - val_accuracy: 0.9549 - lr: 2.5000e-04\n",
      "Epoch 27/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0345 - accuracy: 0.9502 - val_loss: 0.0321 - val_accuracy: 0.9544 - lr: 2.5000e-04\n",
      "Epoch 28/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0345 - accuracy: 0.9510 - val_loss: 0.0323 - val_accuracy: 0.9539 - lr: 2.5000e-04\n",
      "Epoch 29/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0348 - accuracy: 0.9500 - val_loss: 0.0319 - val_accuracy: 0.9539 - lr: 2.5000e-04\n",
      "Epoch 30/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0344 - accuracy: 0.9509 - val_loss: 0.0322 - val_accuracy: 0.9537 - lr: 2.5000e-04\n",
      "Epoch 31/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0346 - accuracy: 0.9502 - val_loss: 0.0327 - val_accuracy: 0.9512 - lr: 2.5000e-04\n",
      "Epoch 32/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0347 - accuracy: 0.9508 - val_loss: 0.0319 - val_accuracy: 0.9553 - lr: 2.5000e-04\n",
      "Epoch 33/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0347 - accuracy: 0.9504 - val_loss: 0.0329 - val_accuracy: 0.9517 - lr: 2.5000e-04\n",
      "Epoch 34/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0342 - accuracy: 0.9512 - val_loss: 0.0320 - val_accuracy: 0.9515 - lr: 2.5000e-04\n",
      "Epoch 35/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0340 - accuracy: 0.9512 - val_loss: 0.0314 - val_accuracy: 0.9527 - lr: 1.2500e-04\n",
      "Epoch 36/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0334 - accuracy: 0.9518 - val_loss: 0.0316 - val_accuracy: 0.9524 - lr: 1.2500e-04\n",
      "Epoch 37/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0340 - accuracy: 0.9507 - val_loss: 0.0314 - val_accuracy: 0.9539 - lr: 1.2500e-04\n",
      "Epoch 38/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0337 - accuracy: 0.9513 - val_loss: 0.0320 - val_accuracy: 0.9522 - lr: 1.2500e-04\n",
      "Epoch 39/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0343 - accuracy: 0.9504 - val_loss: 0.0320 - val_accuracy: 0.9515 - lr: 1.2500e-04\n",
      "Epoch 40/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0334 - accuracy: 0.9513 - val_loss: 0.0315 - val_accuracy: 0.9534 - lr: 1.2500e-04\n",
      "Epoch 41/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0334 - accuracy: 0.9517 - val_loss: 0.0314 - val_accuracy: 0.9537 - lr: 6.2500e-05\n",
      "Epoch 42/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0334 - accuracy: 0.9520 - val_loss: 0.0319 - val_accuracy: 0.9512 - lr: 6.2500e-05\n",
      "Epoch 43/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0337 - accuracy: 0.9505 - val_loss: 0.0316 - val_accuracy: 0.9532 - lr: 6.2500e-05\n",
      "Epoch 44/250\n",
      "746/746 [==============================] - 1s 2ms/step - loss: 0.0334 - accuracy: 0.9516 - val_loss: 0.0314 - val_accuracy: 0.9527 - lr: 6.2500e-05\n",
      "Epoch 45/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0337 - accuracy: 0.9516 - val_loss: 0.0312 - val_accuracy: 0.9541 - lr: 6.2500e-05\n",
      "Epoch 46/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0334 - accuracy: 0.9509 - val_loss: 0.0313 - val_accuracy: 0.9546 - lr: 6.2500e-05\n",
      "Epoch 47/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0329 - accuracy: 0.9523 - val_loss: 0.0315 - val_accuracy: 0.9527 - lr: 6.2500e-05\n",
      "Epoch 48/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0332 - accuracy: 0.9517 - val_loss: 0.0313 - val_accuracy: 0.9539 - lr: 6.2500e-05\n",
      "Epoch 49/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0332 - accuracy: 0.9516 - val_loss: 0.0311 - val_accuracy: 0.9549 - lr: 6.2500e-05\n",
      "Epoch 50/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0332 - accuracy: 0.9525 - val_loss: 0.0315 - val_accuracy: 0.9534 - lr: 6.2500e-05\n",
      "Epoch 51/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0331 - accuracy: 0.9519 - val_loss: 0.0311 - val_accuracy: 0.9549 - lr: 3.1250e-05\n",
      "Epoch 52/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0330 - accuracy: 0.9520 - val_loss: 0.0310 - val_accuracy: 0.9556 - lr: 3.1250e-05\n",
      "Epoch 53/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9530 - val_loss: 0.0311 - val_accuracy: 0.9544 - lr: 3.1250e-05\n",
      "Epoch 54/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0334 - accuracy: 0.9520 - val_loss: 0.0313 - val_accuracy: 0.9539 - lr: 3.1250e-05\n",
      "Epoch 55/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0328 - accuracy: 0.9522 - val_loss: 0.0313 - val_accuracy: 0.9532 - lr: 3.1250e-05\n",
      "Epoch 56/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0328 - accuracy: 0.9531 - val_loss: 0.0312 - val_accuracy: 0.9539 - lr: 3.1250e-05\n",
      "Epoch 57/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0327 - accuracy: 0.9522 - val_loss: 0.0311 - val_accuracy: 0.9539 - lr: 1.5625e-05\n",
      "Epoch 58/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0321 - accuracy: 0.9534 - val_loss: 0.0310 - val_accuracy: 0.9551 - lr: 1.5625e-05\n",
      "Epoch 59/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9534 - val_loss: 0.0308 - val_accuracy: 0.9553 - lr: 1.5625e-05\n",
      "Epoch 60/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9533 - val_loss: 0.0309 - val_accuracy: 0.9546 - lr: 1.5625e-05\n",
      "Epoch 61/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0327 - accuracy: 0.9529 - val_loss: 0.0310 - val_accuracy: 0.9549 - lr: 1.5625e-05\n",
      "Epoch 62/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0330 - accuracy: 0.9523 - val_loss: 0.0312 - val_accuracy: 0.9534 - lr: 1.5625e-05\n",
      "Epoch 63/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9529 - val_loss: 0.0310 - val_accuracy: 0.9558 - lr: 1.5625e-05\n",
      "Epoch 64/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0328 - accuracy: 0.9528 - val_loss: 0.0311 - val_accuracy: 0.9541 - lr: 1.5625e-05\n",
      "Epoch 65/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0327 - accuracy: 0.9528 - val_loss: 0.0310 - val_accuracy: 0.9541 - lr: 7.8125e-06\n",
      "Epoch 66/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9531 - val_loss: 0.0310 - val_accuracy: 0.9549 - lr: 7.8125e-06\n",
      "Epoch 67/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0328 - accuracy: 0.9526 - val_loss: 0.0310 - val_accuracy: 0.9549 - lr: 7.8125e-06\n",
      "Epoch 68/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0330 - accuracy: 0.9523 - val_loss: 0.0311 - val_accuracy: 0.9544 - lr: 7.8125e-06\n",
      "Epoch 69/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9526 - val_loss: 0.0311 - val_accuracy: 0.9546 - lr: 7.8125e-06\n",
      "Epoch 70/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9528 - val_loss: 0.0309 - val_accuracy: 0.9551 - lr: 3.9063e-06\n",
      "Epoch 71/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9530 - val_loss: 0.0309 - val_accuracy: 0.9551 - lr: 3.9063e-06\n",
      "Epoch 72/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9524 - val_loss: 0.0311 - val_accuracy: 0.9546 - lr: 3.9063e-06\n",
      "Epoch 73/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0331 - accuracy: 0.9527 - val_loss: 0.0311 - val_accuracy: 0.9544 - lr: 3.9063e-06\n",
      "Epoch 74/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9529 - val_loss: 0.0311 - val_accuracy: 0.9541 - lr: 3.9063e-06\n",
      "Epoch 75/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9531 - val_loss: 0.0311 - val_accuracy: 0.9546 - lr: 1.9531e-06\n",
      "Epoch 76/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9533 - val_loss: 0.0311 - val_accuracy: 0.9546 - lr: 1.9531e-06\n",
      "Epoch 77/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0329 - accuracy: 0.9530 - val_loss: 0.0309 - val_accuracy: 0.9558 - lr: 1.9531e-06\n",
      "Epoch 78/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9532 - val_loss: 0.0309 - val_accuracy: 0.9549 - lr: 1.9531e-06\n",
      "Epoch 79/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0330 - accuracy: 0.9524 - val_loss: 0.0309 - val_accuracy: 0.9549 - lr: 1.9531e-06\n",
      "Epoch 80/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9539 - val_loss: 0.0310 - val_accuracy: 0.9546 - lr: 9.7656e-07\n",
      "Epoch 81/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9534 - val_loss: 0.0310 - val_accuracy: 0.9549 - lr: 9.7656e-07\n",
      "Epoch 82/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9533 - val_loss: 0.0310 - val_accuracy: 0.9549 - lr: 9.7656e-07\n",
      "Epoch 83/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0327 - accuracy: 0.9530 - val_loss: 0.0309 - val_accuracy: 0.9549 - lr: 9.7656e-07\n",
      "Epoch 84/250\n",
      "746/746 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9528 - val_loss: 0.0310 - val_accuracy: 0.9544 - lr: 9.7656e-07\n",
      "17756/17756 [==============================] - 14s 770us/step - loss: 0.0292 - accuracy: 0.9548\n",
      "0.954775869846344\n"
     ]
    }
   ],
   "source": [
    "#LOAD NEXT CELL INSTEAD, LOAD PRE-TRAINED NEURAL NET\n",
    "#This neural network takes about \n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "activation_type = 'relu'\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(128, activation=activation_type, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(128, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(64, activation=activation_type),\n",
    "    keras.layers.Dense(64, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(32, activation=activation_type),\n",
    "    keras.layers.Dense(32, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(32, activation=activation_type, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(32, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(16, activation=activation_type, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(16, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(8, activation=activation_type, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(8, activation=activation_type),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=keras.losses.BinaryFocalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "callbacks = []\n",
    "callbacks.append(keras.callbacks.EarlyStopping(monitor='val_loss', patience=25))\n",
    "callbacks.append(keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5))\n",
    "model.fit(X_train, y_train, epochs=250, batch_size=50, validation_split=0.1, callbacks=callbacks)\n",
    "\n",
    "evaluation = model.evaluate(X_test, y_test, batch_size = 1)\n",
    "print(evaluation[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33cf5523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 744us/step\n",
      "[[0.01867094]\n",
      " [0.04555651]\n",
      " [0.5582067 ]\n",
      " ...\n",
      " [0.03031788]\n",
      " [0.26265076]\n",
      " [0.15463142]]\n"
     ]
    }
   ],
   "source": [
    "#model.save('DanielNeuralNetworkModel.keras')\n",
    "loaded_model = keras.models.load_model('DanielNeuralNetworkModel.keras')\n",
    "\n",
    "predictions = loaded_model.predict(([X_check_ensemble]))\n",
    "probabilities = 1 / (1 + np.exp(-predictions))\n",
    "\n",
    "print(probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
