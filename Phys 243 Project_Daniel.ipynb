{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f6c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   gender               100000 non-null  object \n",
      " 1   age                  100000 non-null  float64\n",
      " 2   hypertension         100000 non-null  int64  \n",
      " 3   heart_disease        100000 non-null  int64  \n",
      " 4   smoking_history      100000 non-null  object \n",
      " 5   bmi                  100000 non-null  float64\n",
      " 6   HbA1c_level          100000 non-null  float64\n",
      " 7   blood_glucose_level  100000 non-null  int64  \n",
      " 8   diabetes             100000 non-null  int64  \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b970b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.2</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>17.37</td>\n",
       "      <td>6.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>former</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Female</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0      Female  80.0             0              1           never  25.19   \n",
       "1      Female  54.0             0              0         No Info  27.32   \n",
       "2        Male  28.0             0              0           never  27.32   \n",
       "3      Female  36.0             0              0         current  23.45   \n",
       "4        Male  76.0             1              1         current  20.14   \n",
       "...       ...   ...           ...            ...             ...    ...   \n",
       "99995  Female  80.0             0              0         No Info  27.32   \n",
       "99996  Female   2.0             0              0         No Info  17.37   \n",
       "99997    Male  66.0             0              0          former  27.83   \n",
       "99998  Female  24.0             0              0           never  35.42   \n",
       "99999  Female  57.0             0              0         current  22.43   \n",
       "\n",
       "       HbA1c_level  blood_glucose_level  diabetes  \n",
       "0              6.6                  140         0  \n",
       "1              6.6                   80         0  \n",
       "2              5.7                  158         0  \n",
       "3              5.0                  155         0  \n",
       "4              4.8                  155         0  \n",
       "...            ...                  ...       ...  \n",
       "99995          6.2                   90         0  \n",
       "99996          6.5                  100         0  \n",
       "99997          5.7                  155         0  \n",
       "99998          4.0                  100         0  \n",
       "99999          6.6                   90         0  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a8957",
   "metadata": {},
   "source": [
    "## Data cleaning:\n",
    "- Removal of gender \"other\" and smoking \"no info\" due to lack of clarity on actual values (e.g. transgender, decline to state, etc).  Entries would likely not provide insight for feature correlation to category outcome.\n",
    "- Conversion of gender and smoking history to numeric values using dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a660fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 64184 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   gender               64184 non-null  int64  \n",
      " 1   age                  64184 non-null  float64\n",
      " 2   hypertension         64184 non-null  int64  \n",
      " 3   heart_disease        64184 non-null  int64  \n",
      " 4   smoking_history      64184 non-null  int64  \n",
      " 5   bmi                  64184 non-null  float64\n",
      " 6   HbA1c_level          64184 non-null  float64\n",
      " 7   blood_glucose_level  64184 non-null  int64  \n",
      " 8   diabetes             64184 non-null  int64  \n",
      "dtypes: float64(3), int64(6)\n",
      "memory usage: 4.9 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99992</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.34</td>\n",
       "      <td>6.5</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99993</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.69</td>\n",
       "      <td>3.5</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64184 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease  smoking_history    bmi  \\\n",
       "0           1  80.0             0              1                0  25.19   \n",
       "2           0  28.0             0              0                0  27.32   \n",
       "3           1  36.0             0              0                1  23.45   \n",
       "4           0  76.0             1              1                1  20.14   \n",
       "5           1  20.0             0              0                0  27.32   \n",
       "...       ...   ...           ...            ...              ...    ...   \n",
       "99992       1  26.0             0              0                0  34.34   \n",
       "99993       1  40.0             0              0                0  40.69   \n",
       "99997       0  66.0             0              0                3  27.83   \n",
       "99998       1  24.0             0              0                0  35.42   \n",
       "99999       1  57.0             0              0                1  22.43   \n",
       "\n",
       "       HbA1c_level  blood_glucose_level  diabetes  \n",
       "0              6.6                  140         0  \n",
       "2              5.7                  158         0  \n",
       "3              5.0                  155         0  \n",
       "4              4.8                  155         0  \n",
       "5              6.6                   85         0  \n",
       "...            ...                  ...       ...  \n",
       "99992          6.5                  160         0  \n",
       "99993          3.5                  155         0  \n",
       "99997          5.7                  155         0  \n",
       "99998          4.0                  100         0  \n",
       "99999          6.6                   90         0  \n",
       "\n",
       "[64184 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataValDict = {'gender': {'Male': 0, 'Female': 1, 'Other': 3}, 'smoking_history': {'never': 0, 'current': 1, 'ever': 2, 'former': 3, 'not current': 4}}\n",
    "\n",
    "#Original file is saved as original data.  Df will be 'cleaned' file.\n",
    "df = data[data['gender'] != 'Other']\n",
    "df = data[data['smoking_history'] != 'No Info']\n",
    "\n",
    "df = df.replace(dataValDict)\n",
    "df['gender'] = pd.to_numeric(df['gender'])\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee9dec",
   "metadata": {},
   "source": [
    "## Training and Test set creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6a106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44928, 8), (19256, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split features from (diabetes) label\n",
    "\n",
    "features = ['gender','age','hypertension','heart_disease','smoking_history', 'bmi','HbA1c_level','blood_glucose_level']\n",
    "\n",
    "df_check_ensemble = df.sample(5000)\n",
    "df = df.drop(df_check_ensemble)\n",
    "\n",
    "\n",
    "X = df.loc[:, features]\n",
    "y = df.loc[:, ['diabetes']]\n",
    "\n",
    "X_check_ensemble = df_check_ensemble.loc[:, features]\n",
    "y_check_ensemble = df_check_ensemble.loc[:, ['diabetes']]\n",
    "#Data will be shuffled before split by default. No stratification. Test size = 30% of set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size = .70)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b3f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create np array versions of test and train data\n",
    "X_trn_np = X_train.to_numpy() \n",
    "X_tst_np = X_test.to_numpy() \n",
    "y_trn_np = y_train.to_numpy() \n",
    "y_tst_np = y_test.to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9980ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "809/809 [==============================] - 4s 2ms/step - loss: 0.1986 - accuracy: 0.9172 - val_loss: 0.0408 - val_accuracy: 0.9526 - lr: 0.0010\n",
      "Epoch 2/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0472 - accuracy: 0.9366 - val_loss: 0.0343 - val_accuracy: 0.9570 - lr: 0.0010\n",
      "Epoch 3/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0439 - accuracy: 0.9387 - val_loss: 0.0353 - val_accuracy: 0.9490 - lr: 0.0010\n",
      "Epoch 4/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0422 - accuracy: 0.9421 - val_loss: 0.0339 - val_accuracy: 0.9548 - lr: 0.0010\n",
      "Epoch 5/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0420 - accuracy: 0.9427 - val_loss: 0.0337 - val_accuracy: 0.9557 - lr: 0.0010\n",
      "Epoch 6/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0408 - accuracy: 0.9439 - val_loss: 0.0341 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 7/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0394 - accuracy: 0.9450 - val_loss: 0.0323 - val_accuracy: 0.9559 - lr: 0.0010\n",
      "Epoch 8/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0402 - accuracy: 0.9445 - val_loss: 0.0317 - val_accuracy: 0.9595 - lr: 0.0010\n",
      "Epoch 9/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0393 - accuracy: 0.9456 - val_loss: 0.0340 - val_accuracy: 0.9535 - lr: 0.0010\n",
      "Epoch 10/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0388 - accuracy: 0.9451 - val_loss: 0.0346 - val_accuracy: 0.9564 - lr: 0.0010\n",
      "Epoch 11/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0383 - accuracy: 0.9459 - val_loss: 0.0326 - val_accuracy: 0.9506 - lr: 0.0010\n",
      "Epoch 12/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0384 - accuracy: 0.9452 - val_loss: 0.0335 - val_accuracy: 0.9513 - lr: 0.0010\n",
      "Epoch 13/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0377 - accuracy: 0.9459 - val_loss: 0.0322 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 14/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0359 - accuracy: 0.9496 - val_loss: 0.0300 - val_accuracy: 0.9577 - lr: 5.0000e-04\n",
      "Epoch 15/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0353 - accuracy: 0.9492 - val_loss: 0.0300 - val_accuracy: 0.9626 - lr: 5.0000e-04\n",
      "Epoch 16/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0359 - accuracy: 0.9478 - val_loss: 0.0297 - val_accuracy: 0.9579 - lr: 5.0000e-04\n",
      "Epoch 17/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0356 - accuracy: 0.9490 - val_loss: 0.0289 - val_accuracy: 0.9644 - lr: 5.0000e-04\n",
      "Epoch 18/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0361 - accuracy: 0.9475 - val_loss: 0.0298 - val_accuracy: 0.9624 - lr: 5.0000e-04\n",
      "Epoch 19/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0357 - accuracy: 0.9485 - val_loss: 0.0290 - val_accuracy: 0.9597 - lr: 5.0000e-04\n",
      "Epoch 20/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0349 - accuracy: 0.9509 - val_loss: 0.0295 - val_accuracy: 0.9602 - lr: 5.0000e-04\n",
      "Epoch 21/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0353 - accuracy: 0.9488 - val_loss: 0.0290 - val_accuracy: 0.9606 - lr: 5.0000e-04\n",
      "Epoch 22/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0355 - accuracy: 0.9492 - val_loss: 0.0303 - val_accuracy: 0.9597 - lr: 5.0000e-04\n",
      "Epoch 23/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0342 - accuracy: 0.9511 - val_loss: 0.0292 - val_accuracy: 0.9582 - lr: 2.5000e-04\n",
      "Epoch 24/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0348 - accuracy: 0.9498 - val_loss: 0.0281 - val_accuracy: 0.9624 - lr: 2.5000e-04\n",
      "Epoch 25/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0335 - accuracy: 0.9522 - val_loss: 0.0284 - val_accuracy: 0.9617 - lr: 2.5000e-04\n",
      "Epoch 26/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0342 - accuracy: 0.9503 - val_loss: 0.0284 - val_accuracy: 0.9579 - lr: 2.5000e-04\n",
      "Epoch 27/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0343 - accuracy: 0.9504 - val_loss: 0.0282 - val_accuracy: 0.9617 - lr: 2.5000e-04\n",
      "Epoch 28/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0339 - accuracy: 0.9510 - val_loss: 0.0284 - val_accuracy: 0.9582 - lr: 2.5000e-04\n",
      "Epoch 29/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0341 - accuracy: 0.9495 - val_loss: 0.0286 - val_accuracy: 0.9602 - lr: 2.5000e-04\n",
      "Epoch 30/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0337 - accuracy: 0.9503 - val_loss: 0.0276 - val_accuracy: 0.9615 - lr: 1.2500e-04\n",
      "Epoch 31/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0333 - accuracy: 0.9526 - val_loss: 0.0282 - val_accuracy: 0.9617 - lr: 1.2500e-04\n",
      "Epoch 32/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0331 - accuracy: 0.9521 - val_loss: 0.0277 - val_accuracy: 0.9642 - lr: 1.2500e-04\n",
      "Epoch 33/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0330 - accuracy: 0.9522 - val_loss: 0.0282 - val_accuracy: 0.9611 - lr: 1.2500e-04\n",
      "Epoch 34/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0335 - accuracy: 0.9504 - val_loss: 0.0281 - val_accuracy: 0.9626 - lr: 1.2500e-04\n",
      "Epoch 35/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0330 - accuracy: 0.9524 - val_loss: 0.0276 - val_accuracy: 0.9648 - lr: 1.2500e-04\n",
      "Epoch 36/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0331 - accuracy: 0.9517 - val_loss: 0.0282 - val_accuracy: 0.9599 - lr: 6.2500e-05\n",
      "Epoch 37/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9522 - val_loss: 0.0280 - val_accuracy: 0.9597 - lr: 6.2500e-05\n",
      "Epoch 38/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0328 - accuracy: 0.9520 - val_loss: 0.0277 - val_accuracy: 0.9642 - lr: 6.2500e-05\n",
      "Epoch 39/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0330 - accuracy: 0.9518 - val_loss: 0.0279 - val_accuracy: 0.9637 - lr: 6.2500e-05\n",
      "Epoch 40/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9517 - val_loss: 0.0276 - val_accuracy: 0.9635 - lr: 6.2500e-05\n",
      "Epoch 41/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9524 - val_loss: 0.0280 - val_accuracy: 0.9626 - lr: 3.1250e-05\n",
      "Epoch 42/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0327 - accuracy: 0.9528 - val_loss: 0.0277 - val_accuracy: 0.9615 - lr: 3.1250e-05\n",
      "Epoch 43/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0327 - accuracy: 0.9513 - val_loss: 0.0280 - val_accuracy: 0.9602 - lr: 3.1250e-05\n",
      "Epoch 44/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9529 - val_loss: 0.0276 - val_accuracy: 0.9633 - lr: 3.1250e-05\n",
      "Epoch 45/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9525 - val_loss: 0.0275 - val_accuracy: 0.9635 - lr: 3.1250e-05\n",
      "Epoch 46/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9525 - val_loss: 0.0278 - val_accuracy: 0.9628 - lr: 1.5625e-05\n",
      "Epoch 47/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9523 - val_loss: 0.0276 - val_accuracy: 0.9631 - lr: 1.5625e-05\n",
      "Epoch 48/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9526 - val_loss: 0.0276 - val_accuracy: 0.9626 - lr: 1.5625e-05\n",
      "Epoch 49/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9523 - val_loss: 0.0276 - val_accuracy: 0.9631 - lr: 1.5625e-05\n",
      "Epoch 50/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9525 - val_loss: 0.0277 - val_accuracy: 0.9628 - lr: 1.5625e-05\n",
      "Epoch 51/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9529 - val_loss: 0.0277 - val_accuracy: 0.9628 - lr: 7.8125e-06\n",
      "Epoch 52/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9527 - val_loss: 0.0277 - val_accuracy: 0.9624 - lr: 7.8125e-06\n",
      "Epoch 53/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0328 - accuracy: 0.9517 - val_loss: 0.0275 - val_accuracy: 0.9633 - lr: 7.8125e-06\n",
      "Epoch 54/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9522 - val_loss: 0.0275 - val_accuracy: 0.9633 - lr: 7.8125e-06\n",
      "Epoch 55/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9523 - val_loss: 0.0275 - val_accuracy: 0.9639 - lr: 7.8125e-06\n",
      "Epoch 56/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9531 - val_loss: 0.0275 - val_accuracy: 0.9631 - lr: 7.8125e-06\n",
      "Epoch 57/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0321 - accuracy: 0.9533 - val_loss: 0.0275 - val_accuracy: 0.9635 - lr: 7.8125e-06\n",
      "Epoch 58/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9527 - val_loss: 0.0276 - val_accuracy: 0.9628 - lr: 7.8125e-06\n",
      "Epoch 59/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9525 - val_loss: 0.0276 - val_accuracy: 0.9626 - lr: 7.8125e-06\n",
      "Epoch 60/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0327 - accuracy: 0.9519 - val_loss: 0.0277 - val_accuracy: 0.9619 - lr: 7.8125e-06\n",
      "Epoch 61/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0320 - accuracy: 0.9527 - val_loss: 0.0275 - val_accuracy: 0.9637 - lr: 3.9063e-06\n",
      "Epoch 62/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9534 - val_loss: 0.0275 - val_accuracy: 0.9633 - lr: 3.9063e-06\n",
      "Epoch 63/250\n",
      "809/809 [==============================] - 1s 2ms/step - loss: 0.0324 - accuracy: 0.9529 - val_loss: 0.0277 - val_accuracy: 0.9622 - lr: 3.9063e-06\n",
      "Epoch 64/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9528 - val_loss: 0.0275 - val_accuracy: 0.9633 - lr: 3.9063e-06\n",
      "Epoch 65/250\n",
      "809/809 [==============================] - 1s 2ms/step - loss: 0.0323 - accuracy: 0.9530 - val_loss: 0.0276 - val_accuracy: 0.9628 - lr: 3.9063e-06\n",
      "Epoch 66/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0329 - accuracy: 0.9523 - val_loss: 0.0276 - val_accuracy: 0.9631 - lr: 1.9531e-06\n",
      "Epoch 67/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9525 - val_loss: 0.0275 - val_accuracy: 0.9631 - lr: 1.9531e-06\n",
      "Epoch 68/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0320 - accuracy: 0.9530 - val_loss: 0.0275 - val_accuracy: 0.9635 - lr: 1.9531e-06\n",
      "Epoch 69/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9530 - val_loss: 0.0275 - val_accuracy: 0.9635 - lr: 1.9531e-06\n",
      "Epoch 70/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9527 - val_loss: 0.0276 - val_accuracy: 0.9635 - lr: 1.9531e-06\n",
      "Epoch 71/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0321 - accuracy: 0.9528 - val_loss: 0.0275 - val_accuracy: 0.9633 - lr: 9.7656e-07\n",
      "Epoch 72/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9527 - val_loss: 0.0275 - val_accuracy: 0.9637 - lr: 9.7656e-07\n",
      "Epoch 73/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9523 - val_loss: 0.0277 - val_accuracy: 0.9624 - lr: 9.7656e-07\n",
      "Epoch 74/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9529 - val_loss: 0.0275 - val_accuracy: 0.9637 - lr: 9.7656e-07\n",
      "Epoch 75/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9523 - val_loss: 0.0276 - val_accuracy: 0.9633 - lr: 9.7656e-07\n",
      "Epoch 76/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9530 - val_loss: 0.0277 - val_accuracy: 0.9622 - lr: 4.8828e-07\n",
      "Epoch 77/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9531 - val_loss: 0.0277 - val_accuracy: 0.9628 - lr: 4.8828e-07\n",
      "Epoch 78/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0320 - accuracy: 0.9531 - val_loss: 0.0276 - val_accuracy: 0.9633 - lr: 4.8828e-07\n",
      "Epoch 79/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9531 - val_loss: 0.0275 - val_accuracy: 0.9635 - lr: 4.8828e-07\n",
      "Epoch 80/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0319 - accuracy: 0.9535 - val_loss: 0.0277 - val_accuracy: 0.9628 - lr: 4.8828e-07\n",
      "Epoch 81/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0320 - accuracy: 0.9534 - val_loss: 0.0274 - val_accuracy: 0.9635 - lr: 2.4414e-07\n",
      "Epoch 82/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9529 - val_loss: 0.0275 - val_accuracy: 0.9631 - lr: 2.4414e-07\n",
      "Epoch 83/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9530 - val_loss: 0.0275 - val_accuracy: 0.9633 - lr: 2.4414e-07\n",
      "Epoch 84/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9530 - val_loss: 0.0275 - val_accuracy: 0.9635 - lr: 2.4414e-07\n",
      "Epoch 85/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0318 - accuracy: 0.9533 - val_loss: 0.0274 - val_accuracy: 0.9635 - lr: 2.4414e-07\n",
      "Epoch 86/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0327 - accuracy: 0.9530 - val_loss: 0.0276 - val_accuracy: 0.9631 - lr: 1.2207e-07\n",
      "Epoch 87/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9533 - val_loss: 0.0274 - val_accuracy: 0.9642 - lr: 1.2207e-07\n",
      "Epoch 88/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9528 - val_loss: 0.0275 - val_accuracy: 0.9635 - lr: 1.2207e-07\n",
      "Epoch 89/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9536 - val_loss: 0.0274 - val_accuracy: 0.9637 - lr: 1.2207e-07\n",
      "Epoch 90/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9525 - val_loss: 0.0273 - val_accuracy: 0.9642 - lr: 1.2207e-07\n",
      "Epoch 91/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0321 - accuracy: 0.9532 - val_loss: 0.0273 - val_accuracy: 0.9644 - lr: 1.2207e-07\n",
      "Epoch 92/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0321 - accuracy: 0.9527 - val_loss: 0.0274 - val_accuracy: 0.9642 - lr: 1.2207e-07\n",
      "Epoch 93/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9523 - val_loss: 0.0276 - val_accuracy: 0.9628 - lr: 1.2207e-07\n",
      "Epoch 94/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0321 - accuracy: 0.9533 - val_loss: 0.0275 - val_accuracy: 0.9635 - lr: 1.2207e-07\n",
      "Epoch 95/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9533 - val_loss: 0.0274 - val_accuracy: 0.9635 - lr: 1.2207e-07\n",
      "Epoch 96/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9528 - val_loss: 0.0275 - val_accuracy: 0.9635 - lr: 6.1035e-08\n",
      "Epoch 97/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9528 - val_loss: 0.0275 - val_accuracy: 0.9635 - lr: 6.1035e-08\n",
      "Epoch 98/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9527 - val_loss: 0.0275 - val_accuracy: 0.9637 - lr: 6.1035e-08\n",
      "Epoch 99/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9529 - val_loss: 0.0276 - val_accuracy: 0.9631 - lr: 6.1035e-08\n",
      "Epoch 100/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9530 - val_loss: 0.0276 - val_accuracy: 0.9635 - lr: 6.1035e-08\n",
      "Epoch 101/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0322 - accuracy: 0.9531 - val_loss: 0.0275 - val_accuracy: 0.9635 - lr: 3.0518e-08\n",
      "Epoch 102/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0320 - accuracy: 0.9533 - val_loss: 0.0274 - val_accuracy: 0.9635 - lr: 3.0518e-08\n",
      "Epoch 103/250\n",
      "809/809 [==============================] - 1s 2ms/step - loss: 0.0322 - accuracy: 0.9529 - val_loss: 0.0276 - val_accuracy: 0.9633 - lr: 3.0518e-08\n",
      "Epoch 104/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9525 - val_loss: 0.0275 - val_accuracy: 0.9633 - lr: 3.0518e-08\n",
      "Epoch 105/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9522 - val_loss: 0.0276 - val_accuracy: 0.9628 - lr: 3.0518e-08\n",
      "Epoch 106/250\n",
      "809/809 [==============================] - 1s 2ms/step - loss: 0.0326 - accuracy: 0.9523 - val_loss: 0.0274 - val_accuracy: 0.9637 - lr: 1.5259e-08\n",
      "Epoch 107/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9528 - val_loss: 0.0275 - val_accuracy: 0.9639 - lr: 1.5259e-08\n",
      "Epoch 108/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9526 - val_loss: 0.0274 - val_accuracy: 0.9637 - lr: 1.5259e-08\n",
      "Epoch 109/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9535 - val_loss: 0.0275 - val_accuracy: 0.9635 - lr: 1.5259e-08\n",
      "Epoch 110/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9530 - val_loss: 0.0274 - val_accuracy: 0.9635 - lr: 1.5259e-08\n",
      "Epoch 111/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9532 - val_loss: 0.0276 - val_accuracy: 0.9633 - lr: 7.6294e-09\n",
      "Epoch 112/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9532 - val_loss: 0.0274 - val_accuracy: 0.9635 - lr: 7.6294e-09\n",
      "Epoch 113/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0321 - accuracy: 0.9529 - val_loss: 0.0276 - val_accuracy: 0.9628 - lr: 7.6294e-09\n",
      "Epoch 114/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0325 - accuracy: 0.9531 - val_loss: 0.0276 - val_accuracy: 0.9633 - lr: 7.6294e-09\n",
      "Epoch 115/250\n",
      "809/809 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9525 - val_loss: 0.0276 - val_accuracy: 0.9626 - lr: 7.6294e-09\n",
      "19256/19256 [==============================] - 15s 762us/step - loss: 0.0323 - accuracy: 0.9503\n",
      "0.9503012299537659\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "activation_type = 'relu'\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(128, activation=activation_type, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(128, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(64, activation=activation_type),\n",
    "    keras.layers.Dense(64, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(32, activation=activation_type),\n",
    "    keras.layers.Dense(32, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(32, activation=activation_type, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(32, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(16, activation=activation_type, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(16, activation=activation_type),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(8, activation=activation_type, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(8, activation=activation_type),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=keras.losses.BinaryFocalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "callbacks = []\n",
    "callbacks.append(keras.callbacks.EarlyStopping(monitor='val_loss', patience=25))\n",
    "callbacks.append(keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5))\n",
    "model.fit(X_train, y_train, epochs=250, batch_size=50, validation_split=0.1, callbacks=callbacks)\n",
    "\n",
    "evaluation = model.evaluate(X_test, y_test, batch_size = 1)\n",
    "print(evaluation[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33cf5523",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#model.save('DanielNeuralNetworkModel.keras')\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m loaded_model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39mDanielNeuralNetworkModel.keras\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m predictions \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39mpredict(([X_check_ensemble]))\n\u001b[0;32m      5\u001b[0m probabilities \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mpredictions))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "#model.save('DanielNeuralNetworkModel.keras')\n",
    "loaded_model = keras.models.load_model('DanielNeuralNetworkModel.keras')\n",
    "\n",
    "predictions = loaded_model.predict(([X_check_ensemble]))\n",
    "probabilities = 1 / (1 + np.exp(-predictions))\n",
    "\n",
    "print(probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
